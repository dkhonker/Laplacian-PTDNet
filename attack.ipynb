{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39moptim\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdeeprobust\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgraph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdefense\u001b[39;00m \u001b[39mimport\u001b[39;00m GCN\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdeeprobust\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgraph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mglobal_attack\u001b[39;00m \u001b[39mimport\u001b[39;00m MetaApprox, Metattack\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdeeprobust\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgraph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/deeprobust/graph/defense/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgcn\u001b[39;00m \u001b[39mimport\u001b[39;00m GCN, GraphConvolution\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgcn_preprocess\u001b[39;00m \u001b[39mimport\u001b[39;00m GCNSVD, GCNJaccard\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mr_gcn\u001b[39;00m \u001b[39mimport\u001b[39;00m RGCN, GGCL_F, GGCL_D\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/deeprobust/graph/defense/gcn.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparameter\u001b[39;00m \u001b[39mimport\u001b[39;00m Parameter\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodule\u001b[39;00m \u001b[39mimport\u001b[39;00m Module\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdeeprobust\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgraph\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcopy\u001b[39;00m \u001b[39mimport\u001b[39;00m deepcopy\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m f1_score\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/deeprobust/graph/utils.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/__init__.py:283\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_arrays\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    279\u001b[0m     csr_array, csc_array, lil_array, dok_array, coo_array, dia_array, bsr_array\n\u001b[1;32m    280\u001b[0m )\n\u001b[1;32m    282\u001b[0m \u001b[39m# For backward compatibility with v0.19.\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m csgraph\n\u001b[1;32m    285\u001b[0m \u001b[39m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    287\u001b[0m     base, bsr, compressed, construct, coo, csc, csr, data, dia, dok, extract,\n\u001b[1;32m    288\u001b[0m     lil, sparsetools, sputils\n\u001b[1;32m    289\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/csgraph/__init__.py:182\u001b[0m\n\u001b[1;32m    154\u001b[0m __docformat__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrestructuredtext en\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mconnected_components\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    157\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mlaplacian\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    158\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mshortest_path\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mcsgraph_to_masked\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    180\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mNegativeCycleError\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 182\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_laplacian\u001b[39;00m \u001b[39mimport\u001b[39;00m laplacian\n\u001b[1;32m    183\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_shortest_path\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    184\u001b[0m     shortest_path, floyd_warshall, dijkstra, bellman_ford, johnson,\n\u001b[1;32m    185\u001b[0m     NegativeCycleError\n\u001b[1;32m    186\u001b[0m )\n\u001b[1;32m    187\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_traversal\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    188\u001b[0m     breadth_first_order, depth_first_order, breadth_first_tree,\n\u001b[1;32m    189\u001b[0m     depth_first_tree, connected_components\n\u001b[1;32m    190\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/csgraph/_laplacian.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m isspmatrix\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinalg\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearOperator\n\u001b[1;32m     10\u001b[0m \u001b[39m###############################################################################\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# Graph laplacian\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlaplacian\u001b[39m(\n\u001b[1;32m     13\u001b[0m     csgraph,\n\u001b[1;32m     14\u001b[0m     normed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     symmetrized\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/linalg/__init__.py:120\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mSparse linear algebra (:mod:`scipy.sparse.linalg`)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m==================================================\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \n\u001b[1;32m    118\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_isolve\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_dsolve\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    122\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_interface\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/linalg/_isolve/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\u001b[39m\u001b[39mIterative Solvers for Sparse Linear Systems\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39m#from info import __doc__\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39miterative\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mminres\u001b[39;00m \u001b[39mimport\u001b[39;00m minres\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlgmres\u001b[39;00m \u001b[39mimport\u001b[39;00m lgmres\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/linalg/_isolve/iterative.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtextwrap\u001b[39;00m \u001b[39mimport\u001b[39;00m dedent\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _iterative\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinalg\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_interface\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearOperator\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m make_system\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.global_attack import MetaApprox, Metattack\n",
    "from deeprobust.graph.utils import *\n",
    "from deeprobust.graph.data import Dataset\n",
    "import argparse\n",
    "\n",
    "from config import *\n",
    "from utils import *\n",
    "from metrics import *\n",
    "###\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from models import GCN_dropedge\n",
    "\n",
    "\n",
    " # Settings\n",
    "len_tmp = labels.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if device != 'cpu':\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "data = Dataset(root='/tmp/', name=args.dataset, setting='nettack')\n",
    "adj, features, labels = data.adj, data.features, data.labels\n",
    "print(features.shape)\n",
    "idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "idx_unlabeled = np.union1d(idx_val, idx_test)\n",
    "\n",
    "ptb_rate = 0.01\n",
    "perturbations = int(ptb_rate * (adj.sum()//2))\n",
    "adj, features, labels = preprocess(adj, features, labels, preprocess_adj=False)\n",
    "print(features.shape)\n",
    "\n",
    "def test(adj):\n",
    "    ''' test on GCN '''\n",
    "\n",
    "    # adj = normalize_adj_tensor(adj)\n",
    "    gcn = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1, nhid=256,\n",
    "        dropout=0.0, with_relu=True, with_bias=False, weight_decay=0, device=device)\n",
    "    gcn = gcn.to(device)\n",
    "    gcn.fit(features, adj, labels, idx_train) # train without model picking\n",
    "    # gcn.fit(features, adj, labels, idx_train, idx_val) # train with validation model picking\n",
    "    output = gcn.output.cpu()\n",
    "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
    "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test.item()))\n",
    "\n",
    "    return acc_test.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.49987319111824036\n",
      "GCN acc on unlabled data: 0.8569512740277156\n",
      "attack loss: 0.2617972493171692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:   2%|▏         | 1/50 [00:09<07:39,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.4988565742969513\n",
      "GCN acc on unlabled data: 0.8582923558337059\n",
      "attack loss: 0.2586739659309387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:   4%|▍         | 2/50 [00:18<07:22,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5092517137527466\n",
      "GCN acc on unlabled data: 0.8524810013410818\n",
      "attack loss: 0.26840662956237793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:   6%|▌         | 3/50 [00:25<06:24,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5231226086616516\n",
      "GCN acc on unlabled data: 0.8511399195350916\n",
      "attack loss: 0.27679237723350525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:   8%|▊         | 4/50 [00:32<05:52,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5226290225982666\n",
      "GCN acc on unlabled data: 0.8506928922664283\n",
      "attack loss: 0.27846354246139526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  10%|█         | 5/50 [00:41<06:05,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5252869129180908\n",
      "GCN acc on unlabled data: 0.8529280286097451\n",
      "attack loss: 0.276610404253006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  12%|█▏        | 6/50 [00:50<06:12,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.530955970287323\n",
      "GCN acc on unlabled data: 0.8497988377291015\n",
      "attack loss: 0.2848435938358307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  14%|█▍        | 7/50 [00:59<06:18,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.528327465057373\n",
      "GCN acc on unlabled data: 0.8511399195350916\n",
      "attack loss: 0.2821969985961914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  16%|█▌        | 8/50 [01:51<15:36, 22.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5324933528900146\n",
      "GCN acc on unlabled data: 0.851586946803755\n",
      "attack loss: 0.2877604067325592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  18%|█▊        | 9/50 [02:33<19:29, 28.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.534060537815094\n",
      "GCN acc on unlabled data: 0.8520339740724184\n",
      "attack loss: 0.2940361499786377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  20%|██        | 10/50 [03:01<18:55, 28.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5442187786102295\n",
      "GCN acc on unlabled data: 0.8475637013857845\n",
      "attack loss: 0.30321604013442993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  22%|██▏       | 11/50 [03:45<21:29, 33.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5432174801826477\n",
      "GCN acc on unlabled data: 0.8462226195797944\n",
      "attack loss: 0.2983416020870209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  24%|██▍       | 12/50 [04:25<22:21, 35.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5399670600891113\n",
      "GCN acc on unlabled data: 0.845775592311131\n",
      "attack loss: 0.30239349603652954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  26%|██▌       | 13/50 [05:13<24:09, 39.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5439217686653137\n",
      "GCN acc on unlabled data: 0.8448815377738041\n",
      "attack loss: 0.30126509070396423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  28%|██▊       | 14/50 [05:47<22:35, 37.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5565455555915833\n",
      "GCN acc on unlabled data: 0.8462226195797944\n",
      "attack loss: 0.31246116757392883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  30%|███       | 15/50 [06:33<23:18, 39.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5540516972541809\n",
      "GCN acc on unlabled data: 0.8426464014304873\n",
      "attack loss: 0.3116917908191681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  32%|███▏      | 16/50 [07:09<22:02, 38.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.548148512840271\n",
      "GCN acc on unlabled data: 0.8462226195797944\n",
      "attack loss: 0.3143134117126465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  34%|███▍      | 17/50 [07:55<22:36, 41.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5547254681587219\n",
      "GCN acc on unlabled data: 0.8426464014304873\n",
      "attack loss: 0.31832852959632874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  36%|███▌      | 18/50 [08:25<20:08, 37.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5566093921661377\n",
      "GCN acc on unlabled data: 0.8413053196244971\n",
      "attack loss: 0.32247859239578247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  38%|███▊      | 19/50 [09:08<20:16, 39.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5526655316352844\n",
      "GCN acc on unlabled data: 0.8413053196244971\n",
      "attack loss: 0.3246949017047882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  40%|████      | 20/50 [09:47<19:36, 39.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5628324747085571\n",
      "GCN acc on unlabled data: 0.8408582923558338\n",
      "attack loss: 0.33063891530036926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  42%|████▏     | 21/50 [10:24<18:33, 38.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5697439312934875\n",
      "GCN acc on unlabled data: 0.8426464014304873\n",
      "attack loss: 0.33770951628685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  44%|████▍     | 22/50 [10:48<16:00, 34.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5702192783355713\n",
      "GCN acc on unlabled data: 0.8426464014304873\n",
      "attack loss: 0.3394838571548462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  46%|████▌     | 23/50 [11:00<12:25, 27.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5683210492134094\n",
      "GCN acc on unlabled data: 0.8426464014304873\n",
      "attack loss: 0.33527594804763794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  48%|████▊     | 24/50 [11:12<09:53, 22.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5815107226371765\n",
      "GCN acc on unlabled data: 0.8413053196244971\n",
      "attack loss: 0.34328493475914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  50%|█████     | 25/50 [12:02<12:54, 30.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5752321481704712\n",
      "GCN acc on unlabled data: 0.8413053196244971\n",
      "attack loss: 0.3489215075969696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  52%|█████▏    | 26/50 [12:21<11:00, 27.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5788125991821289\n",
      "GCN acc on unlabled data: 0.8399642378185069\n",
      "attack loss: 0.35380011796951294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  54%|█████▍    | 27/50 [12:45<10:09, 26.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5735634565353394\n",
      "GCN acc on unlabled data: 0.8408582923558338\n",
      "attack loss: 0.34825676679611206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  56%|█████▌    | 28/50 [13:38<12:34, 34.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5853952765464783\n",
      "GCN acc on unlabled data: 0.8372820742065266\n",
      "attack loss: 0.36046600341796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  58%|█████▊    | 29/50 [14:16<12:26, 35.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5855368971824646\n",
      "GCN acc on unlabled data: 0.8395172105498435\n",
      "attack loss: 0.36060014367103577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  60%|██████    | 30/50 [15:02<12:48, 38.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5914331078529358\n",
      "GCN acc on unlabled data: 0.8372820742065266\n",
      "attack loss: 0.3635765314102173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  62%|██████▏   | 31/50 [15:49<13:03, 41.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5798417925834656\n",
      "GCN acc on unlabled data: 0.8408582923558338\n",
      "attack loss: 0.35571563243865967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  64%|██████▍   | 32/50 [16:32<12:31, 41.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5876798629760742\n",
      "GCN acc on unlabled data: 0.8417523468931605\n",
      "attack loss: 0.3673661947250366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  66%|██████▌   | 33/50 [17:17<12:02, 42.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5787569284439087\n",
      "GCN acc on unlabled data: 0.8421993741618239\n",
      "attack loss: 0.36202114820480347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  68%|██████▊   | 34/50 [17:53<10:49, 40.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.5903906226158142\n",
      "GCN acc on unlabled data: 0.8399642378185069\n",
      "attack loss: 0.37824878096580505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  70%|███████   | 35/50 [18:31<09:59, 39.94s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_mask = np.zeros(len_tmp)\n",
    "train_mask[idx_train] = 1\n",
    "\n",
    "val_mask = np.zeros(len_tmp)\n",
    "val_mask[idx_val] = 1\n",
    "\n",
    "test_mask = np.zeros(len_tmp)\n",
    "test_mask[idx_test] = 1\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "\n",
    "#tuple_adj = sparse_to_tuple(adj.tocoo())\n",
    "features_tensor = tf.convert_to_tensor(features,dtype=dtype)\n",
    "#adj_tensor = tf.SparseTensor(*tuple_adj)\n",
    "\n",
    "labels_tmp = F.one_hot(labels)\n",
    "\n",
    "\n",
    "y_train_tensor = tf.convert_to_tensor(labels_tmp,dtype=dtype)\n",
    "train_mask_tensor = tf.convert_to_tensor(train_mask)\n",
    "y_test_tensor = tf.convert_to_tensor(labels_tmp,dtype=dtype)\n",
    "test_mask_tensor = tf.convert_to_tensor(test_mask)\n",
    "y_val_tensor = tf.convert_to_tensor(labels_tmp,dtype=dtype)\n",
    "val_mask_tensor = tf.convert_to_tensor(val_mask)\n",
    "\n",
    "best_test_acc = 0\n",
    "best_val_acc_trail = 0\n",
    "best_val_loss = 10000\n",
    "\n",
    "# Setup Surrogate model\n",
    "\n",
    "surrogate = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,weight_decay=0.0,\n",
    "                                nhid=256, dropout=0, with_relu=True, with_bias=False, device='cpu').to('cpu')\n",
    "surrogate.fit(features, adj, labels, idx_train, idx_val, patience=100)\n",
    "# Setup Attack Model\n",
    "model = Metattack(surrogate, nnodes=adj.shape[0], feature_shape=features.shape,\n",
    "        attack_structure=True, attack_features=False, device='cpu', lambda_=0).to('cpu')\n",
    "# Attack\n",
    "\n",
    "model.attack(features, adj, labels, idx_train, idx_unlabeled, n_perturbations=perturbations, ll_constraint=False)\n",
    "modified_adj = model.modified_adj\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "modified_adj=sp.csr_array(modified_adj.int())\n",
    "\n",
    "tuple_adj = sparse_to_tuple(modified_adj.tocoo())\n",
    "adj_tensor = tf.SparseTensor(*tuple_adj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Epoch: 0001 train_loss= 1.93524 val_loss= 1.89642 train_acc= 0.41365 val_acc= 0.41365 test_acc= 0.38984\n",
      "Epoch: 0002 train_loss= 1.87406 val_loss= 1.85383 train_acc= 0.49398 val_acc= 0.49398 test_acc= 0.47485\n",
      "Epoch: 0003 train_loss= 1.81402 val_loss= 1.81144 train_acc= 0.51004 val_acc= 0.51004 test_acc= 0.49799\n",
      "Epoch: 0004 train_loss= 1.75464 val_loss= 1.76905 train_acc= 0.50602 val_acc= 0.50602 test_acc= 0.49799\n",
      "Epoch: 0005 train_loss= 1.69535 val_loss= 1.72631 train_acc= 0.50602 val_acc= 0.50602 test_acc= 0.49799\n",
      "Epoch: 0006 train_loss= 1.63565 val_loss= 1.68287 train_acc= 0.50201 val_acc= 0.50201 test_acc= 0.49799\n",
      "Epoch: 0007 train_loss= 1.57523 val_loss= 1.63880 train_acc= 0.51004 val_acc= 0.51004 test_acc= 0.49799\n",
      "Epoch: 0008 train_loss= 1.51408 val_loss= 1.59434 train_acc= 0.52610 val_acc= 0.52610 test_acc= 0.56891\n",
      "Epoch: 0009 train_loss= 1.45231 val_loss= 1.54956 train_acc= 0.55020 val_acc= 0.55020 test_acc= 0.58400\n",
      "Epoch: 0010 train_loss= 1.39007 val_loss= 1.50448 train_acc= 0.57831 val_acc= 0.57831 test_acc= 0.59960\n",
      "Epoch: 0011 train_loss= 1.32754 val_loss= 1.45925 train_acc= 0.59036 val_acc= 0.59036 test_acc= 0.62123\n",
      "Epoch: 0012 train_loss= 1.26492 val_loss= 1.41402 train_acc= 0.61446 val_acc= 0.61446 test_acc= 0.63682\n",
      "Epoch: 0013 train_loss= 1.20253 val_loss= 1.36884 train_acc= 0.62651 val_acc= 0.62651 test_acc= 0.65342\n",
      "Epoch: 0014 train_loss= 1.14055 val_loss= 1.32377 train_acc= 0.66265 val_acc= 0.66265 test_acc= 0.67807\n",
      "Epoch: 0015 train_loss= 1.07923 val_loss= 1.27906 train_acc= 0.67871 val_acc= 0.67871 test_acc= 0.70775\n",
      "Epoch: 0016 train_loss= 1.01888 val_loss= 1.23495 train_acc= 0.69880 val_acc= 0.69880 test_acc= 0.72837\n",
      "Epoch: 0017 train_loss= 0.95976 val_loss= 1.19163 train_acc= 0.70683 val_acc= 0.70683 test_acc= 0.74899\n",
      "Epoch: 0018 train_loss= 0.90226 val_loss= 1.14933 train_acc= 0.70683 val_acc= 0.70683 test_acc= 0.76660\n",
      "Epoch: 0019 train_loss= 0.84669 val_loss= 1.10836 train_acc= 0.71486 val_acc= 0.71486 test_acc= 0.78873\n",
      "Epoch: 0020 train_loss= 0.79338 val_loss= 1.06895 train_acc= 0.74699 val_acc= 0.74699 test_acc= 0.80634\n",
      "Epoch: 0021 train_loss= 0.74253 val_loss= 1.03133 train_acc= 0.77108 val_acc= 0.77108 test_acc= 0.81187\n",
      "Epoch: 0022 train_loss= 0.69424 val_loss= 0.99555 train_acc= 0.77912 val_acc= 0.77912 test_acc= 0.81942\n",
      "Epoch: 0023 train_loss= 0.64864 val_loss= 0.96176 train_acc= 0.79518 val_acc= 0.79518 test_acc= 0.82746\n",
      "Epoch: 0024 train_loss= 0.60570 val_loss= 0.93002 train_acc= 0.79920 val_acc= 0.79920 test_acc= 0.82998\n",
      "Epoch: 0025 train_loss= 0.56538 val_loss= 0.90030 train_acc= 0.80321 val_acc= 0.80321 test_acc= 0.83400\n",
      "Epoch: 0026 train_loss= 0.52758 val_loss= 0.87261 train_acc= 0.80723 val_acc= 0.80723 test_acc= 0.83903\n",
      "Epoch: 0027 train_loss= 0.49220 val_loss= 0.84689 train_acc= 0.81125 val_acc= 0.81125 test_acc= 0.84356\n",
      "Epoch: 0028 train_loss= 0.45914 val_loss= 0.82315 train_acc= 0.81125 val_acc= 0.81125 test_acc= 0.84356\n",
      "Epoch: 0029 train_loss= 0.42834 val_loss= 0.80130 train_acc= 0.81125 val_acc= 0.81125 test_acc= 0.84356\n",
      "Epoch: 0030 train_loss= 0.39967 val_loss= 0.78128 train_acc= 0.81526 val_acc= 0.81526 test_acc= 0.84909\n",
      "Epoch: 0031 train_loss= 0.37304 val_loss= 0.76297 train_acc= 0.81526 val_acc= 0.81526 test_acc= 0.84909\n",
      "Epoch: 0032 train_loss= 0.34836 val_loss= 0.74626 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85312\n",
      "Epoch: 0033 train_loss= 0.32551 val_loss= 0.73104 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85312\n",
      "Epoch: 0034 train_loss= 0.30435 val_loss= 0.71717 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85513\n",
      "Epoch: 0035 train_loss= 0.28478 val_loss= 0.70454 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85513\n",
      "Epoch: 0036 train_loss= 0.26668 val_loss= 0.69301 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85614\n",
      "Epoch: 0037 train_loss= 0.24992 val_loss= 0.68249 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85614\n",
      "Epoch: 0038 train_loss= 0.23440 val_loss= 0.67291 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85614\n",
      "Epoch: 0039 train_loss= 0.22002 val_loss= 0.66422 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85614\n",
      "Epoch: 0040 train_loss= 0.20671 val_loss= 0.65633 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85614\n",
      "Epoch: 0041 train_loss= 0.19437 val_loss= 0.64920 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85614\n",
      "Epoch: 0042 train_loss= 0.18294 val_loss= 0.64278 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85614\n",
      "Epoch: 0043 train_loss= 0.17235 val_loss= 0.63706 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85614\n",
      "Epoch: 0044 train_loss= 0.16254 val_loss= 0.63199 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85614\n",
      "Epoch: 0045 train_loss= 0.15344 val_loss= 0.62751 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85614\n",
      "Epoch: 0046 train_loss= 0.14501 val_loss= 0.62359 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85614\n",
      "Epoch: 0047 train_loss= 0.13719 val_loss= 0.62020 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85614\n",
      "Epoch: 0048 train_loss= 0.12993 val_loss= 0.61727 train_acc= 0.82329 val_acc= 0.82329 test_acc= 0.85614\n",
      "Epoch: 0049 train_loss= 0.12319 val_loss= 0.61478 train_acc= 0.82329 val_acc= 0.82329 test_acc= 0.85614\n",
      "Epoch: 0050 train_loss= 0.11693 val_loss= 0.61268 train_acc= 0.82329 val_acc= 0.82329 test_acc= 0.85614\n",
      "Epoch: 0051 train_loss= 0.11110 val_loss= 0.61093 train_acc= 0.82329 val_acc= 0.82329 test_acc= 0.85614\n",
      "Epoch: 0052 train_loss= 0.10569 val_loss= 0.60948 train_acc= 0.82329 val_acc= 0.82329 test_acc= 0.85614\n",
      "Epoch: 0053 train_loss= 0.10064 val_loss= 0.60830 train_acc= 0.82329 val_acc= 0.82329 test_acc= 0.85614\n",
      "Epoch: 0054 train_loss= 0.09595 val_loss= 0.60736 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85614\n",
      "Epoch: 0055 train_loss= 0.09157 val_loss= 0.60660 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85614\n",
      "Epoch: 0056 train_loss= 0.08749 val_loss= 0.60602 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85614\n",
      "Epoch: 0057 train_loss= 0.08368 val_loss= 0.60556 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85614\n",
      "Epoch: 0058 train_loss= 0.08012 val_loss= 0.60522 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85614\n",
      "Epoch: 0059 train_loss= 0.07679 val_loss= 0.60496 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85614\n",
      "Epoch: 0060 train_loss= 0.07367 val_loss= 0.60478 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85614\n",
      "Epoch: 0061 train_loss= 0.07074 val_loss= 0.60465 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85614\n",
      "Epoch: 0062 train_loss= 0.06800 val_loss= 0.60456 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85614\n",
      "Epoch: 0063 train_loss= 0.06542 val_loss= 0.60452 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85614\n",
      "Epoch: 0064 train_loss= 0.06299 val_loss= 0.60451 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85614\n",
      "Epoch: 0065 train_loss= 0.06070 val_loss= 0.60454 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85614\n",
      "Epoch: 0066 train_loss= 0.05855 val_loss= 0.60461 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85614\n",
      "Epoch: 0067 train_loss= 0.05651 val_loss= 0.60471 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85614\n",
      "Epoch: 0068 train_loss= 0.05459 val_loss= 0.60485 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85966\n",
      "Epoch: 0069 train_loss= 0.05278 val_loss= 0.60503 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85966\n",
      "Epoch: 0070 train_loss= 0.05106 val_loss= 0.60525 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85966\n",
      "Epoch: 0071 train_loss= 0.04943 val_loss= 0.60552 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85966\n",
      "Epoch: 0072 train_loss= 0.04789 val_loss= 0.60583 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85966\n",
      "Epoch: 0073 train_loss= 0.04643 val_loss= 0.60618 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85966\n",
      "Epoch: 0074 train_loss= 0.04504 val_loss= 0.60657 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85966\n",
      "Epoch: 0075 train_loss= 0.04372 val_loss= 0.60701 train_acc= 0.83133 val_acc= 0.83133 test_acc= 0.85966\n",
      "Epoch: 0076 train_loss= 0.04247 val_loss= 0.60749 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0077 train_loss= 0.04128 val_loss= 0.60800 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0078 train_loss= 0.04014 val_loss= 0.60854 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0079 train_loss= 0.03906 val_loss= 0.60912 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0080 train_loss= 0.03802 val_loss= 0.60973 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0081 train_loss= 0.03703 val_loss= 0.61036 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0082 train_loss= 0.03609 val_loss= 0.61101 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0083 train_loss= 0.03518 val_loss= 0.61167 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0084 train_loss= 0.03432 val_loss= 0.61236 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0085 train_loss= 0.03349 val_loss= 0.61304 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0086 train_loss= 0.03270 val_loss= 0.61375 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0087 train_loss= 0.03193 val_loss= 0.61445 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0088 train_loss= 0.03120 val_loss= 0.61517 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0089 train_loss= 0.03050 val_loss= 0.61589 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0090 train_loss= 0.02983 val_loss= 0.61662 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0091 train_loss= 0.02918 val_loss= 0.61735 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0092 train_loss= 0.02855 val_loss= 0.61808 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0093 train_loss= 0.02795 val_loss= 0.61882 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0094 train_loss= 0.02737 val_loss= 0.61955 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0095 train_loss= 0.02681 val_loss= 0.62030 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0096 train_loss= 0.02627 val_loss= 0.62104 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0097 train_loss= 0.02575 val_loss= 0.62178 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0098 train_loss= 0.02525 val_loss= 0.62252 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0099 train_loss= 0.02476 val_loss= 0.62326 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0100 train_loss= 0.02429 val_loss= 0.62400 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0101 train_loss= 0.02384 val_loss= 0.62473 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0102 train_loss= 0.02339 val_loss= 0.62547 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0103 train_loss= 0.02297 val_loss= 0.62621 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0104 train_loss= 0.02255 val_loss= 0.62694 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0105 train_loss= 0.02215 val_loss= 0.62768 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0106 train_loss= 0.02176 val_loss= 0.62841 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0107 train_loss= 0.02138 val_loss= 0.62914 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0108 train_loss= 0.02102 val_loss= 0.62986 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0109 train_loss= 0.02066 val_loss= 0.63059 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0110 train_loss= 0.02032 val_loss= 0.63131 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0111 train_loss= 0.01998 val_loss= 0.63203 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0112 train_loss= 0.01965 val_loss= 0.63275 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0113 train_loss= 0.01933 val_loss= 0.63346 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0114 train_loss= 0.01902 val_loss= 0.63416 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0115 train_loss= 0.01872 val_loss= 0.63486 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0116 train_loss= 0.01843 val_loss= 0.63556 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0117 train_loss= 0.01814 val_loss= 0.63626 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0118 train_loss= 0.01786 val_loss= 0.63695 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0119 train_loss= 0.01759 val_loss= 0.63765 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0120 train_loss= 0.01732 val_loss= 0.63833 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0121 train_loss= 0.01706 val_loss= 0.63902 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0122 train_loss= 0.01681 val_loss= 0.63970 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0123 train_loss= 0.01656 val_loss= 0.64038 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0124 train_loss= 0.01632 val_loss= 0.64106 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0125 train_loss= 0.01609 val_loss= 0.64174 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0126 train_loss= 0.01586 val_loss= 0.64241 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0127 train_loss= 0.01564 val_loss= 0.64308 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0128 train_loss= 0.01542 val_loss= 0.64374 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0129 train_loss= 0.01520 val_loss= 0.64440 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0130 train_loss= 0.01499 val_loss= 0.64506 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0131 train_loss= 0.01479 val_loss= 0.64572 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0132 train_loss= 0.01459 val_loss= 0.64637 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0133 train_loss= 0.01439 val_loss= 0.64702 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0134 train_loss= 0.01420 val_loss= 0.64767 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0135 train_loss= 0.01401 val_loss= 0.64832 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0136 train_loss= 0.01383 val_loss= 0.64897 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0137 train_loss= 0.01365 val_loss= 0.64961 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0138 train_loss= 0.01347 val_loss= 0.65025 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0139 train_loss= 0.01330 val_loss= 0.65088 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0140 train_loss= 0.01313 val_loss= 0.65151 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0141 train_loss= 0.01296 val_loss= 0.65214 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0142 train_loss= 0.01280 val_loss= 0.65277 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0143 train_loss= 0.01264 val_loss= 0.65339 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0144 train_loss= 0.01248 val_loss= 0.65402 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0145 train_loss= 0.01233 val_loss= 0.65465 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0146 train_loss= 0.01218 val_loss= 0.65527 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0147 train_loss= 0.01203 val_loss= 0.65589 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0148 train_loss= 0.01189 val_loss= 0.65651 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0149 train_loss= 0.01174 val_loss= 0.65712 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0150 train_loss= 0.01160 val_loss= 0.65774 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0151 train_loss= 0.01147 val_loss= 0.65835 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0152 train_loss= 0.01133 val_loss= 0.65896 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0153 train_loss= 0.01120 val_loss= 0.65956 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0154 train_loss= 0.01107 val_loss= 0.66017 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0155 train_loss= 0.01094 val_loss= 0.66078 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0156 train_loss= 0.01082 val_loss= 0.66137 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0157 train_loss= 0.01069 val_loss= 0.66197 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0158 train_loss= 0.01057 val_loss= 0.66256 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0159 train_loss= 0.01045 val_loss= 0.66315 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0160 train_loss= 0.01034 val_loss= 0.66374 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0161 train_loss= 0.01022 val_loss= 0.66432 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0162 train_loss= 0.01011 val_loss= 0.66490 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0163 train_loss= 0.01000 val_loss= 0.66548 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0164 train_loss= 0.00989 val_loss= 0.66605 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0165 train_loss= 0.00978 val_loss= 0.66663 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0166 train_loss= 0.00968 val_loss= 0.66720 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0167 train_loss= 0.00957 val_loss= 0.66777 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Epoch: 0168 train_loss= 0.00947 val_loss= 0.66834 train_acc= 0.82731 val_acc= 0.82731 test_acc= 0.85966\n",
      "Early stopping...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Settings\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "model = GCN_dropedge(input_dim=features.shape[1], output_dim=labels.max().item()+1, adj=adj_tensor)\n",
    "\n",
    "\n",
    "best_test_acc = 0\n",
    "best_val_acc = 0\n",
    "best_val_loss = 10000\n",
    "\n",
    "\n",
    "curr_step = 0\n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        output = model.call((features_tensor),training=True)\n",
    "        cross_loss = masked_softmax_cross_entropy(output, y_train_tensor,train_mask_tensor)\n",
    "        lossL2 = tf.add_n([tf.nn.l2_loss(v) for v in model.trainable_variables])\n",
    "        loss = cross_loss #+ args.weight_decay*lossL2\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    output = model.call((features_tensor), training=False)\n",
    "    train_acc = masked_accuracy(output, y_train_tensor,train_mask_tensor)\n",
    "    val_acc  = masked_accuracy(output, y_val_tensor,val_mask_tensor)\n",
    "    val_loss = masked_softmax_cross_entropy(output, y_val_tensor, val_mask_tensor)\n",
    "    test_acc  = masked_accuracy(output, y_test_tensor,test_mask_tensor)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        curr_step = 0\n",
    "        best_test_acc = test_acc\n",
    "        best_val_acc = val_acc\n",
    "        best_val_loss= val_loss\n",
    "        # Print results\n",
    "\n",
    "    else:\n",
    "        curr_step +=1\n",
    "    if curr_step > args.early_stop:\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cross_loss),\"val_loss=\", \"{:.5f}\".format(val_loss),\n",
    "    \"train_acc=\", \"{:.5f}\".format(val_acc), \"val_acc=\", \"{:.5f}\".format(val_acc),\n",
    "    \"test_acc=\", \"{:.5f}\".format(best_test_acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
