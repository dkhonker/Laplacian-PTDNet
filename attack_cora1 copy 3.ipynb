{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zsp/ljx/PTDNet/utils.py:221: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n",
      "Perturbing graph:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.6932793855667114\n",
      "GCN acc on unlabled data: 0.67\n",
      "attack loss: 1.6872400045394897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:   5%|▌         | 1/20 [07:01<2:13:20, 421.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.69221830368042\n",
      "GCN acc on unlabled data: 0.678\n",
      "attack loss: 1.6853837966918945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  10%|█         | 2/20 [13:59<2:05:50, 419.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.6994142532348633\n",
      "GCN acc on unlabled data: 0.66\n",
      "attack loss: 1.6912951469421387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  15%|█▌        | 3/20 [20:57<1:58:42, 418.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.700310468673706\n",
      "GCN acc on unlabled data: 0.66\n",
      "attack loss: 1.6926970481872559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  20%|██        | 4/20 [27:54<1:51:26, 417.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7025173902511597\n",
      "GCN acc on unlabled data: 0.68\n",
      "attack loss: 1.6947219371795654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  25%|██▌       | 5/20 [34:57<1:44:58, 419.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7037962675094604\n",
      "GCN acc on unlabled data: 0.664\n",
      "attack loss: 1.6953074932098389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  30%|███       | 6/20 [42:05<1:38:38, 422.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7003886699676514\n",
      "GCN acc on unlabled data: 0.671\n",
      "attack loss: 1.692452311515808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  35%|███▌      | 7/20 [49:13<1:31:57, 424.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7045332193374634\n",
      "GCN acc on unlabled data: 0.682\n",
      "attack loss: 1.6967706680297852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  40%|████      | 8/20 [56:28<1:25:31, 427.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7064000368118286\n",
      "GCN acc on unlabled data: 0.661\n",
      "attack loss: 1.6995435953140259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  45%|████▌     | 9/20 [1:03:39<1:18:37, 428.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7036341428756714\n",
      "GCN acc on unlabled data: 0.672\n",
      "attack loss: 1.6964133977890015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  50%|█████     | 10/20 [1:10:42<1:11:10, 427.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7095935344696045\n",
      "GCN acc on unlabled data: 0.68\n",
      "attack loss: 1.703733205795288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  55%|█████▌    | 11/20 [1:17:05<1:02:01, 413.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7046587467193604\n",
      "GCN acc on unlabled data: 0.655\n",
      "attack loss: 1.6978565454483032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  60%|██████    | 12/20 [1:21:42<49:35, 372.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.709659457206726\n",
      "GCN acc on unlabled data: 0.679\n",
      "attack loss: 1.7035505771636963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  65%|██████▌   | 13/20 [1:26:05<39:32, 338.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7047163248062134\n",
      "GCN acc on unlabled data: 0.686\n",
      "attack loss: 1.69990074634552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  70%|███████   | 14/20 [1:30:29<31:37, 316.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7088505029678345\n",
      "GCN acc on unlabled data: 0.663\n",
      "attack loss: 1.702359676361084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  75%|███████▌  | 15/20 [1:34:54<25:04, 300.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7109454870224\n",
      "GCN acc on unlabled data: 0.671\n",
      "attack loss: 1.7046587467193604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  80%|████████  | 16/20 [1:39:12<19:11, 287.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7102171182632446\n",
      "GCN acc on unlabled data: 0.68\n",
      "attack loss: 1.7036700248718262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  85%|████████▌ | 17/20 [1:43:34<14:00, 280.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7061177492141724\n",
      "GCN acc on unlabled data: 0.678\n",
      "attack loss: 1.7001314163208008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  90%|█████████ | 18/20 [1:47:51<09:06, 273.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.712292194366455\n",
      "GCN acc on unlabled data: 0.661\n",
      "attack loss: 1.706063151359558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  95%|█████████▌| 19/20 [1:52:19<04:31, 271.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.714308261871338\n",
      "GCN acc on unlabled data: 0.67\n",
      "attack loss: 1.707374930381775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph: 100%|██████████| 20/20 [1:56:41<00:00, 350.10s/it]\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "from utils import *\n",
    "from models import GCN, PTDNetGCN\n",
    "from metrics import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "# Settings\n",
    "dataset_name='citeseer'\n",
    "args.dataset=dataset_name\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(args.dataset)\n",
    "all_labels = y_train + y_test+y_val\n",
    "single_label = np.argmax(all_labels,axis=-1)\n",
    "nodesize = features.shape[0]\n",
    "\n",
    "# Some preprocessing\n",
    "features_tmp=features.copy()\n",
    "features = preprocess_features(features).A\n",
    "support = preprocess_adj(adj)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "\n",
    "tuple_adj = sparse_to_tuple(adj.tocoo())\n",
    "features_tensor = tf.convert_to_tensor(features,dtype=dtype)\n",
    "adj_tensor = tf.SparseTensor(*tuple_adj)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train,dtype=dtype)\n",
    "train_mask_tensor = tf.convert_to_tensor(train_mask)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test,dtype=dtype)\n",
    "test_mask_tensor = tf.convert_to_tensor(test_mask)\n",
    "y_val_tensor = tf.convert_to_tensor(y_val,dtype=dtype)\n",
    "val_mask_tensor = tf.convert_to_tensor(val_mask)\n",
    "\n",
    "best_test_acc = 0\n",
    "best_val_acc_trail = 0\n",
    "best_val_loss = 10000\n",
    "\n",
    "from deeprobust.graph.data import Dataset\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.global_attack import Metattack\n",
    "# Setup Surrogate model\n",
    "idx_train=np.array(np.where(train_mask==1)).tolist()[0]\n",
    "idx_val=np.array(np.where(val_mask==1)).tolist()[0]\n",
    "idx_unlabeled=np.array(np.where(test_mask==1)).tolist()[0]\n",
    "surrogate = GCN(nfeat=features.shape[1], nclass=single_label.max().item()+1,\n",
    "                nhid=256, dropout=0, with_relu=False, with_bias=False, device='cpu').to('cpu')\n",
    "surrogate.fit(features, adj, single_label, idx_train, idx_val, patience=100)\n",
    "# Setup Attack Model\n",
    "model = Metattack(surrogate, nnodes=adj.shape[0], feature_shape=features.shape,\n",
    "        attack_structure=True, attack_features=False, device='cpu', lambda_=0).to('cpu')\n",
    "# Attack\n",
    "model.attack(features, adj, single_label, idx_train, idx_unlabeled, n_perturbations=20, ll_constraint=False)\n",
    "modified_adj = model.modified_adj\n",
    "# print(adj)\n",
    "# print(\"shiy\")\n",
    "# print(modified_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_adj=sp.csr_array(modified_adj.int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zsp/ljx/PTDNet/utils.py:221: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f1652ea6f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f1652ea6f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "edge_vol 4661.3887\n",
      "Epoch: 0001 train_loss= 1.79182 val_loss= 1.79108 train_acc= 0.40000 val_acc= 0.27000 best_val_acc_trail= 0.27000 test_acc= 0.26900\n",
      "time  6.624025106430054\n",
      "edge_vol 4649.8633\n",
      "Epoch: 0002 train_loss= 1.78954 val_loss= 1.79035 train_acc= 0.67500 val_acc= 0.33600 best_val_acc_trail= 0.33600 test_acc= 0.35000\n",
      "time  7.992251873016357\n",
      "edge_vol 4637.8774\n",
      "Epoch: 0003 train_loss= 1.78716 val_loss= 1.78960 train_acc= 0.82500 val_acc= 0.39800 best_val_acc_trail= 0.39800 test_acc= 0.41000\n",
      "time  9.131654262542725\n",
      "edge_vol 4625.4824\n",
      "Epoch: 0004 train_loss= 1.78475 val_loss= 1.78880 train_acc= 0.88333 val_acc= 0.44000 best_val_acc_trail= 0.44000 test_acc= 0.47800\n",
      "time  10.288454532623291\n",
      "edge_vol 4612.746\n",
      "Epoch: 0005 train_loss= 1.78233 val_loss= 1.78794 train_acc= 0.92500 val_acc= 0.47600 best_val_acc_trail= 0.47600 test_acc= 0.51900\n",
      "time  11.072489738464355\n",
      "edge_vol 4599.7676\n",
      "Epoch: 0006 train_loss= 1.77977 val_loss= 1.78700 train_acc= 0.91667 val_acc= 0.52800 best_val_acc_trail= 0.52800 test_acc= 0.55000\n",
      "time  12.440566539764404\n",
      "edge_vol 4586.5825\n",
      "Epoch: 0007 train_loss= 1.77710 val_loss= 1.78597 train_acc= 0.91667 val_acc= 0.53600 best_val_acc_trail= 0.53600 test_acc= 0.56500\n",
      "time  13.774302959442139\n",
      "edge_vol 4573.2617\n",
      "Epoch: 0008 train_loss= 1.77418 val_loss= 1.78486 train_acc= 0.91667 val_acc= 0.55600 best_val_acc_trail= 0.55600 test_acc= 0.58500\n",
      "time  14.988532543182373\n",
      "edge_vol 4559.8354\n",
      "Epoch: 0009 train_loss= 1.77118 val_loss= 1.78365 train_acc= 0.91667 val_acc= 0.57000 best_val_acc_trail= 0.57000 test_acc= 0.59500\n",
      "time  16.32466173171997\n",
      "edge_vol 4546.2656\n",
      "Epoch: 0010 train_loss= 1.76809 val_loss= 1.78236 train_acc= 0.91667 val_acc= 0.58400 best_val_acc_trail= 0.58400 test_acc= 0.60000\n",
      "time  17.66771388053894\n",
      "edge_vol 4532.5547\n",
      "Epoch: 0011 train_loss= 1.76481 val_loss= 1.78099 train_acc= 0.91667 val_acc= 0.60000 best_val_acc_trail= 0.60000 test_acc= 0.60300\n",
      "time  18.86140775680542\n",
      "edge_vol 4518.6895\n",
      "Epoch: 0012 train_loss= 1.76115 val_loss= 1.77954 train_acc= 0.91667 val_acc= 0.62000 best_val_acc_trail= 0.62000 test_acc= 0.61400\n",
      "time  19.914731740951538\n",
      "edge_vol 4504.666\n",
      "Epoch: 0013 train_loss= 1.75761 val_loss= 1.77801 train_acc= 0.91667 val_acc= 0.62800 best_val_acc_trail= 0.62800 test_acc= 0.61700\n",
      "time  21.272592306137085\n",
      "edge_vol 4490.4536\n",
      "Epoch: 0014 train_loss= 1.75356 val_loss= 1.77643 train_acc= 0.91667 val_acc= 0.63200 best_val_acc_trail= 0.63200 test_acc= 0.62200\n",
      "time  22.830331087112427\n",
      "edge_vol 4476.1064\n",
      "Epoch: 0015 train_loss= 1.74963 val_loss= 1.77478 train_acc= 0.91667 val_acc= 0.64400 best_val_acc_trail= 0.64400 test_acc= 0.63400\n",
      "time  24.162814378738403\n",
      "edge_vol 4461.589\n",
      "Epoch: 0016 train_loss= 1.74527 val_loss= 1.77308 train_acc= 0.92500 val_acc= 0.65200 best_val_acc_trail= 0.65200 test_acc= 0.64000\n",
      "time  25.456810474395752\n",
      "edge_vol 4446.871\n",
      "Epoch: 0017 train_loss= 1.74107 val_loss= 1.77133 train_acc= 0.92500 val_acc= 0.65400 best_val_acc_trail= 0.65400 test_acc= 0.64000\n",
      "time  26.741765022277832\n",
      "edge_vol 4431.9805\n",
      "Epoch: 0018 train_loss= 1.73635 val_loss= 1.76952 train_acc= 0.92500 val_acc= 0.65200 best_val_acc_trail= 0.65400 test_acc= 0.64000\n",
      "time  28.03655219078064\n",
      "edge_vol 4416.901\n",
      "Epoch: 0019 train_loss= 1.73109 val_loss= 1.76766 train_acc= 0.92500 val_acc= 0.65400 best_val_acc_trail= 0.65400 test_acc= 0.64000\n",
      "time  29.602463483810425\n",
      "edge_vol 4401.6533\n",
      "Epoch: 0020 train_loss= 1.72678 val_loss= 1.76575 train_acc= 0.92500 val_acc= 0.65800 best_val_acc_trail= 0.65800 test_acc= 0.65800\n",
      "time  31.176004648208618\n",
      "edge_vol 4386.24\n",
      "Epoch: 0021 train_loss= 1.72160 val_loss= 1.76378 train_acc= 0.92500 val_acc= 0.66200 best_val_acc_trail= 0.66200 test_acc= 0.66100\n",
      "time  32.54008913040161\n",
      "edge_vol 4370.6704\n",
      "Epoch: 0022 train_loss= 1.71611 val_loss= 1.76178 train_acc= 0.92500 val_acc= 0.66400 best_val_acc_trail= 0.66400 test_acc= 0.66300\n",
      "time  33.94403672218323\n",
      "edge_vol 4354.923\n",
      "Epoch: 0023 train_loss= 1.71065 val_loss= 1.75973 train_acc= 0.92500 val_acc= 0.66400 best_val_acc_trail= 0.66400 test_acc= 0.66300\n",
      "time  35.442206382751465\n",
      "edge_vol 4339.002\n",
      "Epoch: 0024 train_loss= 1.70538 val_loss= 1.75765 train_acc= 0.92500 val_acc= 0.66400 best_val_acc_trail= 0.66400 test_acc= 0.66300\n",
      "time  36.810956716537476\n",
      "edge_vol 4322.893\n",
      "Epoch: 0025 train_loss= 1.69970 val_loss= 1.75552 train_acc= 0.92500 val_acc= 0.66800 best_val_acc_trail= 0.66800 test_acc= 0.66700\n",
      "time  38.25270104408264\n",
      "edge_vol 4306.5615\n",
      "Epoch: 0026 train_loss= 1.69348 val_loss= 1.75335 train_acc= 0.92500 val_acc= 0.66600 best_val_acc_trail= 0.66800 test_acc= 0.66700\n",
      "time  39.70674276351929\n",
      "edge_vol 4290.0195\n",
      "Epoch: 0027 train_loss= 1.68823 val_loss= 1.75115 train_acc= 0.92500 val_acc= 0.66800 best_val_acc_trail= 0.66800 test_acc= 0.66700\n",
      "time  41.08165740966797\n",
      "edge_vol 4273.2837\n",
      "Epoch: 0028 train_loss= 1.68173 val_loss= 1.74892 train_acc= 0.93333 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.67200\n",
      "time  42.34302067756653\n",
      "edge_vol 4256.3604\n",
      "Epoch: 0029 train_loss= 1.67477 val_loss= 1.74665 train_acc= 0.93333 val_acc= 0.67200 best_val_acc_trail= 0.67200 test_acc= 0.67100\n",
      "time  43.821255922317505\n",
      "edge_vol 4239.27\n",
      "Epoch: 0030 train_loss= 1.66900 val_loss= 1.74436 train_acc= 0.93333 val_acc= 0.67200 best_val_acc_trail= 0.67200 test_acc= 0.67100\n",
      "time  45.2886483669281\n",
      "edge_vol 4221.914\n",
      "Epoch: 0031 train_loss= 1.66307 val_loss= 1.74204 train_acc= 0.93333 val_acc= 0.67200 best_val_acc_trail= 0.67200 test_acc= 0.67100\n",
      "time  46.797123670578\n",
      "edge_vol 4204.3667\n",
      "Epoch: 0032 train_loss= 1.65634 val_loss= 1.73969 train_acc= 0.93333 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.67600\n",
      "time  48.34031414985657\n",
      "edge_vol 4186.6396\n",
      "Epoch: 0033 train_loss= 1.65025 val_loss= 1.73731 train_acc= 0.93333 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.67600\n",
      "time  49.56731724739075\n",
      "edge_vol 4168.6875\n",
      "Epoch: 0034 train_loss= 1.64224 val_loss= 1.73489 train_acc= 0.92500 val_acc= 0.67600 best_val_acc_trail= 0.67600 test_acc= 0.67700\n",
      "time  51.09287452697754\n",
      "edge_vol 4150.5303\n",
      "Epoch: 0035 train_loss= 1.63662 val_loss= 1.73246 train_acc= 0.92500 val_acc= 0.67800 best_val_acc_trail= 0.67800 test_acc= 0.67600\n",
      "time  52.31065368652344\n",
      "edge_vol 4132.2617\n",
      "Epoch: 0036 train_loss= 1.63088 val_loss= 1.73002 train_acc= 0.93333 val_acc= 0.67800 best_val_acc_trail= 0.67800 test_acc= 0.67600\n",
      "time  53.68701696395874\n",
      "edge_vol 4113.7715\n",
      "Epoch: 0037 train_loss= 1.62153 val_loss= 1.72754 train_acc= 0.93333 val_acc= 0.68000 best_val_acc_trail= 0.68000 test_acc= 0.67500\n",
      "time  54.93561935424805\n",
      "edge_vol 4095.0417\n",
      "Epoch: 0038 train_loss= 1.61503 val_loss= 1.72504 train_acc= 0.93333 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.67700\n",
      "time  56.5348687171936\n",
      "edge_vol 4076.1333\n",
      "Epoch: 0039 train_loss= 1.60790 val_loss= 1.72251 train_acc= 0.93333 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.67700\n",
      "time  57.93248629570007\n",
      "edge_vol 4057.1045\n",
      "Epoch: 0040 train_loss= 1.60073 val_loss= 1.71997 train_acc= 0.93333 val_acc= 0.68000 best_val_acc_trail= 0.68200 test_acc= 0.67700\n",
      "time  59.36854386329651\n",
      "edge_vol 4037.88\n",
      "Epoch: 0041 train_loss= 1.59267 val_loss= 1.71741 train_acc= 0.94167 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.67700\n",
      "time  60.57788705825806\n",
      "edge_vol 4018.3906\n",
      "Epoch: 0042 train_loss= 1.58580 val_loss= 1.71484 train_acc= 0.95000 val_acc= 0.68400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  61.84053063392639\n",
      "edge_vol 3998.696\n",
      "Epoch: 0043 train_loss= 1.57850 val_loss= 1.71228 train_acc= 0.95000 val_acc= 0.68200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  63.06437397003174\n",
      "edge_vol 3978.8884\n",
      "Epoch: 0044 train_loss= 1.56854 val_loss= 1.70970 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  64.39263391494751\n",
      "edge_vol 3958.8286\n",
      "Epoch: 0045 train_loss= 1.56380 val_loss= 1.70711 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  65.84457874298096\n",
      "edge_vol 3938.6504\n",
      "Epoch: 0046 train_loss= 1.55614 val_loss= 1.70454 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  67.32277035713196\n",
      "edge_vol 3918.2056\n",
      "Epoch: 0047 train_loss= 1.54730 val_loss= 1.70195 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  68.48152828216553\n",
      "edge_vol 3897.4915\n",
      "Epoch: 0048 train_loss= 1.54046 val_loss= 1.69935 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  69.91828656196594\n",
      "edge_vol 3876.4944\n",
      "Epoch: 0049 train_loss= 1.53027 val_loss= 1.69677 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  71.29054737091064\n",
      "edge_vol 3855.3088\n",
      "Epoch: 0050 train_loss= 1.52332 val_loss= 1.69415 train_acc= 0.95833 val_acc= 0.68400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  72.64275765419006\n",
      "edge_vol 3833.8928\n",
      "Epoch: 0051 train_loss= 1.51453 val_loss= 1.69155 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  73.89660906791687\n",
      "edge_vol 3812.3325\n",
      "Epoch: 0052 train_loss= 1.50831 val_loss= 1.68897 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  75.42790246009827\n",
      "edge_vol 3790.5576\n",
      "Epoch: 0053 train_loss= 1.49983 val_loss= 1.68641 train_acc= 0.96667 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  76.74683499336243\n",
      "edge_vol 3768.611\n",
      "Epoch: 0054 train_loss= 1.49082 val_loss= 1.68386 train_acc= 0.96667 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  78.23452401161194\n",
      "edge_vol 3746.5527\n",
      "Epoch: 0055 train_loss= 1.48468 val_loss= 1.68132 train_acc= 0.97500 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  79.57897925376892\n",
      "edge_vol 3724.3813\n",
      "Epoch: 0056 train_loss= 1.47347 val_loss= 1.67880 train_acc= 0.97500 val_acc= 0.68200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  80.87403416633606\n",
      "edge_vol 3702.0825\n",
      "Epoch: 0057 train_loss= 1.46677 val_loss= 1.67638 train_acc= 0.98333 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  82.35490703582764\n",
      "edge_vol 3679.4656\n",
      "Epoch: 0058 train_loss= 1.45614 val_loss= 1.67402 train_acc= 0.98333 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  83.58794951438904\n",
      "edge_vol 3656.7974\n",
      "Epoch: 0059 train_loss= 1.45038 val_loss= 1.67173 train_acc= 0.98333 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  84.93450260162354\n",
      "edge_vol 3634.1387\n",
      "Epoch: 0060 train_loss= 1.44358 val_loss= 1.66951 train_acc= 0.98333 val_acc= 0.67800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  86.35376405715942\n",
      "edge_vol 3611.1824\n",
      "Epoch: 0061 train_loss= 1.43324 val_loss= 1.66737 train_acc= 0.98333 val_acc= 0.67800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  87.82171201705933\n",
      "edge_vol 3588.1245\n",
      "Epoch: 0062 train_loss= 1.42727 val_loss= 1.66524 train_acc= 0.98333 val_acc= 0.67600 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  89.05258584022522\n",
      "edge_vol 3564.624\n",
      "Epoch: 0063 train_loss= 1.41718 val_loss= 1.66323 train_acc= 0.98333 val_acc= 0.67600 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  90.4119975566864\n",
      "edge_vol 3541.0972\n",
      "Epoch: 0064 train_loss= 1.41044 val_loss= 1.66131 train_acc= 0.98333 val_acc= 0.67600 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  91.83403658866882\n",
      "edge_vol 3517.4177\n",
      "Epoch: 0065 train_loss= 1.39952 val_loss= 1.65948 train_acc= 0.98333 val_acc= 0.67800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  93.11259126663208\n",
      "edge_vol 3493.6829\n",
      "Epoch: 0066 train_loss= 1.39223 val_loss= 1.65774 train_acc= 0.98333 val_acc= 0.67400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  94.65076327323914\n",
      "edge_vol 3469.9238\n",
      "Epoch: 0067 train_loss= 1.38660 val_loss= 1.65607 train_acc= 0.98333 val_acc= 0.67600 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  95.86115550994873\n",
      "edge_vol 3445.9465\n",
      "Epoch: 0068 train_loss= 1.37392 val_loss= 1.65440 train_acc= 0.98333 val_acc= 0.67600 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  97.45458984375\n",
      "edge_vol 3422.0488\n",
      "Epoch: 0069 train_loss= 1.36819 val_loss= 1.65276 train_acc= 0.98333 val_acc= 0.67400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  99.26260590553284\n",
      "edge_vol 3398.337\n",
      "Epoch: 0070 train_loss= 1.36201 val_loss= 1.65119 train_acc= 0.98333 val_acc= 0.67200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  100.98517346382141\n",
      "edge_vol 3374.0664\n",
      "Epoch: 0071 train_loss= 1.35095 val_loss= 1.64971 train_acc= 0.98333 val_acc= 0.67200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  102.95593762397766\n",
      "edge_vol 3349.6624\n",
      "Epoch: 0072 train_loss= 1.34678 val_loss= 1.64836 train_acc= 0.98333 val_acc= 0.67000 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  104.33845901489258\n",
      "edge_vol 3325.5085\n",
      "Epoch: 0073 train_loss= 1.34446 val_loss= 1.64716 train_acc= 0.98333 val_acc= 0.66800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  106.07275724411011\n",
      "edge_vol 3301.1875\n",
      "Epoch: 0074 train_loss= 1.32649 val_loss= 1.64602 train_acc= 0.98333 val_acc= 0.67000 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  107.77677845954895\n",
      "edge_vol 3276.6794\n",
      "Epoch: 0075 train_loss= 1.32270 val_loss= 1.64499 train_acc= 0.98333 val_acc= 0.67000 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  108.99515175819397\n",
      "edge_vol 3251.7493\n",
      "Epoch: 0076 train_loss= 1.31810 val_loss= 1.64404 train_acc= 0.98333 val_acc= 0.67200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  110.32597851753235\n",
      "edge_vol 3226.2886\n",
      "Epoch: 0077 train_loss= 1.30852 val_loss= 1.64320 train_acc= 0.98333 val_acc= 0.67400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  111.92675566673279\n",
      "edge_vol 3200.6362\n",
      "Epoch: 0078 train_loss= 1.29871 val_loss= 1.64241 train_acc= 0.99167 val_acc= 0.66800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  113.54353833198547\n",
      "edge_vol 3174.4224\n",
      "Epoch: 0079 train_loss= 1.29794 val_loss= 1.64165 train_acc= 0.99167 val_acc= 0.66800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  115.38026905059814\n",
      "edge_vol 3147.4912\n",
      "Epoch: 0080 train_loss= 1.28965 val_loss= 1.64096 train_acc= 0.99167 val_acc= 0.67200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  116.95501375198364\n",
      "edge_vol 3120.0386\n",
      "Epoch: 0081 train_loss= 1.28275 val_loss= 1.64035 train_acc= 0.99167 val_acc= 0.67800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  118.61061429977417\n",
      "edge_vol 3092.301\n",
      "Epoch: 0082 train_loss= 1.27742 val_loss= 1.63982 train_acc= 0.99167 val_acc= 0.67800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  120.47683453559875\n",
      "edge_vol 3064.0625\n",
      "Epoch: 0083 train_loss= 1.26940 val_loss= 1.63935 train_acc= 0.99167 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  122.01450848579407\n",
      "edge_vol 3035.306\n",
      "Epoch: 0084 train_loss= 1.26454 val_loss= 1.63900 train_acc= 0.99167 val_acc= 0.67800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  124.23976922035217\n",
      "edge_vol 3005.9546\n",
      "Epoch: 0085 train_loss= 1.25921 val_loss= 1.63869 train_acc= 0.99167 val_acc= 0.68200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  126.0311450958252\n",
      "edge_vol 2976.1257\n",
      "Epoch: 0086 train_loss= 1.25448 val_loss= 1.63840 train_acc= 0.99167 val_acc= 0.68200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  127.69757843017578\n",
      "edge_vol 2945.853\n",
      "Epoch: 0087 train_loss= 1.25043 val_loss= 1.63827 train_acc= 0.99167 val_acc= 0.68200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  129.13064312934875\n",
      "edge_vol 2915.628\n",
      "Epoch: 0088 train_loss= 1.24047 val_loss= 1.63824 train_acc= 0.99167 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  130.7740399837494\n",
      "edge_vol 2885.4438\n",
      "Epoch: 0089 train_loss= 1.23335 val_loss= 1.63823 train_acc= 0.99167 val_acc= 0.67800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  132.3340458869934\n",
      "edge_vol 2855.0684\n",
      "Epoch: 0090 train_loss= 1.22623 val_loss= 1.63823 train_acc= 0.99167 val_acc= 0.67800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  133.71808695793152\n",
      "edge_vol 2824.4375\n",
      "Epoch: 0091 train_loss= 1.22174 val_loss= 1.63824 train_acc= 0.99167 val_acc= 0.67400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  135.56442427635193\n",
      "edge_vol 2793.3499\n",
      "Epoch: 0092 train_loss= 1.21795 val_loss= 1.63817 train_acc= 0.99167 val_acc= 0.67200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  136.9619722366333\n",
      "edge_vol 2762.0205\n",
      "Epoch: 0093 train_loss= 1.21364 val_loss= 1.63811 train_acc= 1.00000 val_acc= 0.67200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  138.31783318519592\n",
      "edge_vol 2729.9614\n",
      "Epoch: 0094 train_loss= 1.20604 val_loss= 1.63805 train_acc= 1.00000 val_acc= 0.67200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  140.0141978263855\n",
      "edge_vol 2697.276\n",
      "Epoch: 0095 train_loss= 1.20547 val_loss= 1.63790 train_acc= 1.00000 val_acc= 0.67400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  141.6878514289856\n",
      "edge_vol 2663.8518\n",
      "Epoch: 0096 train_loss= 1.20297 val_loss= 1.63770 train_acc= 1.00000 val_acc= 0.67800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  143.6185212135315\n",
      "edge_vol 2629.6587\n",
      "Epoch: 0097 train_loss= 1.19213 val_loss= 1.63743 train_acc= 1.00000 val_acc= 0.67800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  145.34583806991577\n",
      "edge_vol 2594.937\n",
      "Epoch: 0098 train_loss= 1.18952 val_loss= 1.63718 train_acc= 1.00000 val_acc= 0.67800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  146.98552989959717\n",
      "edge_vol 2559.5251\n",
      "Epoch: 0099 train_loss= 1.18465 val_loss= 1.63699 train_acc= 1.00000 val_acc= 0.67800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  148.5285668373108\n",
      "edge_vol 2523.0525\n",
      "Epoch: 0100 train_loss= 1.17293 val_loss= 1.63681 train_acc= 1.00000 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  149.8970398902893\n",
      "edge_vol 2486.707\n",
      "Epoch: 0101 train_loss= 1.17281 val_loss= 1.63659 train_acc= 1.00000 val_acc= 0.68200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  151.99045419692993\n",
      "edge_vol 2449.668\n",
      "Epoch: 0102 train_loss= 1.17282 val_loss= 1.63657 train_acc= 1.00000 val_acc= 0.68200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  153.2396457195282\n",
      "edge_vol 2412.9014\n",
      "Epoch: 0103 train_loss= 1.16445 val_loss= 1.63654 train_acc= 1.00000 val_acc= 0.67800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  155.2985143661499\n",
      "edge_vol 2374.9526\n",
      "Epoch: 0104 train_loss= 1.15484 val_loss= 1.63654 train_acc= 1.00000 val_acc= 0.67800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  157.54182243347168\n",
      "edge_vol 2336.5598\n",
      "Epoch: 0105 train_loss= 1.15458 val_loss= 1.63652 train_acc= 1.00000 val_acc= 0.67800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  158.9547882080078\n",
      "edge_vol 2297.5913\n",
      "Epoch: 0106 train_loss= 1.15315 val_loss= 1.63654 train_acc= 1.00000 val_acc= 0.67800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  160.67501831054688\n",
      "edge_vol 2257.9146\n",
      "Epoch: 0107 train_loss= 1.14289 val_loss= 1.63667 train_acc= 1.00000 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  162.41247510910034\n",
      "edge_vol 2218.065\n",
      "Epoch: 0108 train_loss= 1.14179 val_loss= 1.63681 train_acc= 1.00000 val_acc= 0.67600 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  164.2645881175995\n",
      "edge_vol 2177.7622\n",
      "Epoch: 0109 train_loss= 1.12936 val_loss= 1.63699 train_acc= 1.00000 val_acc= 0.67800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  165.84834384918213\n",
      "edge_vol 2137.1045\n",
      "Epoch: 0110 train_loss= 1.13125 val_loss= 1.63711 train_acc= 1.00000 val_acc= 0.67600 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  167.6267650127411\n",
      "edge_vol 2096.0527\n",
      "Epoch: 0111 train_loss= 1.12891 val_loss= 1.63724 train_acc= 1.00000 val_acc= 0.67400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  168.96642327308655\n",
      "edge_vol 2054.936\n",
      "Epoch: 0112 train_loss= 1.12124 val_loss= 1.63723 train_acc= 1.00000 val_acc= 0.67400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  170.7671685218811\n",
      "edge_vol 2013.0192\n",
      "Epoch: 0113 train_loss= 1.10681 val_loss= 1.63725 train_acc= 1.00000 val_acc= 0.66800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  172.40924906730652\n",
      "edge_vol 1970.9724\n",
      "Epoch: 0114 train_loss= 1.10986 val_loss= 1.63730 train_acc= 1.00000 val_acc= 0.66000 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  173.59284353256226\n",
      "edge_vol 1929.0369\n",
      "Epoch: 0115 train_loss= 1.11445 val_loss= 1.63723 train_acc= 1.00000 val_acc= 0.65800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  175.2064929008484\n",
      "edge_vol 1887.0956\n",
      "Epoch: 0116 train_loss= 1.10766 val_loss= 1.63720 train_acc= 1.00000 val_acc= 0.65400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  176.5388207435608\n",
      "edge_vol 1844.6099\n",
      "Epoch: 0117 train_loss= 1.10202 val_loss= 1.63705 train_acc= 1.00000 val_acc= 0.66400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  178.0555956363678\n",
      "edge_vol 1802.3391\n",
      "Epoch: 0118 train_loss= 1.10015 val_loss= 1.63687 train_acc= 1.00000 val_acc= 0.66400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  179.98114323616028\n",
      "edge_vol 1759.9324\n",
      "Epoch: 0119 train_loss= 1.08664 val_loss= 1.63672 train_acc= 1.00000 val_acc= 0.66400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  181.8295979499817\n",
      "edge_vol 1717.9249\n",
      "Epoch: 0120 train_loss= 1.08695 val_loss= 1.63669 train_acc= 1.00000 val_acc= 0.66400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  183.47689414024353\n",
      "edge_vol 1675.9111\n",
      "Epoch: 0121 train_loss= 1.08181 val_loss= 1.63666 train_acc= 1.00000 val_acc= 0.66600 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  184.88779735565186\n",
      "edge_vol 1633.9241\n",
      "Epoch: 0122 train_loss= 1.07445 val_loss= 1.63672 train_acc= 1.00000 val_acc= 0.66800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  186.32627177238464\n",
      "edge_vol 1592.2891\n",
      "Epoch: 0123 train_loss= 1.07718 val_loss= 1.63675 train_acc= 1.00000 val_acc= 0.66600 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  187.59152555465698\n",
      "edge_vol 1550.6736\n",
      "Epoch: 0124 train_loss= 1.07058 val_loss= 1.63672 train_acc= 1.00000 val_acc= 0.66600 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  189.02065324783325\n",
      "edge_vol 1509.4847\n",
      "Epoch: 0125 train_loss= 1.06121 val_loss= 1.63651 train_acc= 1.00000 val_acc= 0.66600 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  190.35284900665283\n",
      "edge_vol 1468.5131\n",
      "Epoch: 0126 train_loss= 1.05749 val_loss= 1.63634 train_acc= 1.00000 val_acc= 0.66200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  192.04662203788757\n",
      "edge_vol 1427.7644\n",
      "Epoch: 0127 train_loss= 1.04795 val_loss= 1.63621 train_acc= 1.00000 val_acc= 0.65800 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  193.70758271217346\n",
      "edge_vol 1387.3591\n",
      "Epoch: 0128 train_loss= 1.03999 val_loss= 1.63608 train_acc= 1.00000 val_acc= 0.65400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  195.0678904056549\n",
      "edge_vol 1347.0844\n",
      "Epoch: 0129 train_loss= 1.03864 val_loss= 1.63597 train_acc= 1.00000 val_acc= 0.65400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  196.41838479042053\n",
      "edge_vol 1307.0012\n",
      "Epoch: 0130 train_loss= 1.04715 val_loss= 1.63600 train_acc= 1.00000 val_acc= 0.65400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  198.591539144516\n",
      "edge_vol 1267.2031\n",
      "Epoch: 0131 train_loss= 1.03265 val_loss= 1.63587 train_acc= 1.00000 val_acc= 0.65400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  200.88349318504333\n",
      "edge_vol 1227.8615\n",
      "Epoch: 0132 train_loss= 1.03070 val_loss= 1.63578 train_acc= 1.00000 val_acc= 0.65400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  203.10681247711182\n",
      "edge_vol 1189.2839\n",
      "Epoch: 0133 train_loss= 1.02196 val_loss= 1.63571 train_acc= 1.00000 val_acc= 0.65200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  204.73975467681885\n",
      "edge_vol 1151.2592\n",
      "Epoch: 0134 train_loss= 1.01490 val_loss= 1.63557 train_acc= 1.00000 val_acc= 0.64600 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  207.28722834587097\n",
      "edge_vol 1113.7996\n",
      "Epoch: 0135 train_loss= 1.00603 val_loss= 1.63548 train_acc= 1.00000 val_acc= 0.64400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  211.60599780082703\n",
      "edge_vol 1077.2263\n",
      "Epoch: 0136 train_loss= 0.99899 val_loss= 1.63519 train_acc= 1.00000 val_acc= 0.64600 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  214.13785696029663\n",
      "edge_vol 1041.015\n",
      "Epoch: 0137 train_loss= 1.00460 val_loss= 1.63489 train_acc= 1.00000 val_acc= 0.64400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  217.18709683418274\n",
      "edge_vol 1005.4999\n",
      "Epoch: 0138 train_loss= 0.98827 val_loss= 1.63453 train_acc= 1.00000 val_acc= 0.64200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  218.72515201568604\n",
      "edge_vol 970.4758\n",
      "Epoch: 0139 train_loss= 0.98425 val_loss= 1.63421 train_acc= 1.00000 val_acc= 0.64200 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  220.23341464996338\n",
      "edge_vol 935.9048\n",
      "Epoch: 0140 train_loss= 0.97833 val_loss= 1.63398 train_acc= 1.00000 val_acc= 0.64400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  223.46353268623352\n",
      "edge_vol 902.0014\n",
      "Epoch: 0141 train_loss= 0.97318 val_loss= 1.63361 train_acc= 1.00000 val_acc= 0.64400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  225.90370655059814\n",
      "edge_vol 868.89795\n",
      "Epoch: 0142 train_loss= 0.96334 val_loss= 1.63294 train_acc= 1.00000 val_acc= 0.64400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "time  227.71085596084595\n",
      "edge_vol 836.703\n",
      "Epoch: 0143 train_loss= 0.95405 val_loss= 1.63210 train_acc= 1.00000 val_acc= 0.64400 best_val_acc_trail= 0.68400 test_acc= 0.67800\n",
      "Early stopping...\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "from utils import *\n",
    "from models import GCN, PTDNetGCN\n",
    "from metrics import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "# Settings\n",
    "args.dataset=dataset_name\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(args.dataset)\n",
    "adj=modified_adj\n",
    "all_labels = y_train + y_test+y_val\n",
    "single_label = np.argmax(all_labels,axis=-1)\n",
    "\n",
    "nodesize = features.shape[0]\n",
    "\n",
    "# Some preprocessing\n",
    "features = preprocess_features(features)\n",
    "support = preprocess_adj(adj)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "\n",
    "tuple_adj = sparse_to_tuple(adj.tocoo())\n",
    "features_tensor = tf.convert_to_tensor(features,dtype=dtype)\n",
    "adj_tensor = tf.SparseTensor(*tuple_adj)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train,dtype=dtype)\n",
    "train_mask_tensor = tf.convert_to_tensor(train_mask)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test,dtype=dtype)\n",
    "test_mask_tensor = tf.convert_to_tensor(test_mask)\n",
    "y_val_tensor = tf.convert_to_tensor(y_val,dtype=dtype)\n",
    "val_mask_tensor = tf.convert_to_tensor(val_mask)\n",
    "\n",
    "\n",
    "\n",
    "best_test_acc = 0\n",
    "best_val_acc_trail = 0\n",
    "best_val_loss = 10000\n",
    "import time\n",
    "begin = time.time()\n",
    "\n",
    "model = PTDNetGCN(input_dim=features.shape[1], output_dim=y_train.shape[1])\n",
    "model.set_fea_adj(np.array(range(adj.shape[0])), features_tensor, adj_tensor)\n",
    "\n",
    "best_epoch = 0\n",
    "curr_step = 0\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    temperature = max(0.05,args.init_temperature * pow(args.temperature_decay, epoch))\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = []\n",
    "        for l in range(args.outL):\n",
    "            output = model.call(temperature,training=True)\n",
    "            preds.append(tf.expand_dims(output,0))\n",
    "        all_preds = tf.concat(preds,axis=0)\n",
    "        mean_preds = tf.reduce_mean(preds,axis=0)\n",
    "        consistency_loss = tf.nn.l2_loss(mean_preds-all_preds)\n",
    "\n",
    "        cross_loss = masked_softmax_cross_entropy(mean_preds, y_train_tensor,train_mask_tensor)\n",
    "        lossL2 = tf.add_n([tf.nn.l2_loss(v) for v in model.trainable_variables])\n",
    "        lossl0 = model.lossl0(temperature)\n",
    "        #nuclear = model.my_nuclear()\n",
    "        nuclear = model.nuclear()\n",
    "        loss = cross_loss + args.weight_decay*lossL2 + args.lambda1*lossl0 + args.lambda3*nuclear + args.coff_consis*consistency_loss\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    output = model.call(None, training=False)\n",
    "    edges_volumn = tf.reduce_sum(model.maskes[0])\n",
    "    print('edge_vol',edges_volumn.numpy())\n",
    "\n",
    "    train_acc = masked_accuracy(output, y_train_tensor,train_mask_tensor)\n",
    "    val_acc  = masked_accuracy(output, y_val_tensor,val_mask_tensor)\n",
    "    val_loss = masked_softmax_cross_entropy(output, y_val_tensor, val_mask_tensor)\n",
    "    test_acc  = masked_accuracy(output, y_test_tensor,test_mask_tensor)\n",
    "    if val_acc > best_val_acc:\n",
    "        curr_step = 0\n",
    "        best_epoch = epoch\n",
    "        best_val_acc = val_acc\n",
    "        best_val_loss= val_loss\n",
    "        if val_acc>best_val_acc_trail:\n",
    "            best_test_acc = test_acc\n",
    "            best_val_acc_trail = val_acc\n",
    "    else:\n",
    "        curr_step +=1\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cross_loss),\"val_loss=\", \"{:.5f}\".format(val_loss),\n",
    "      \"train_acc=\", \"{:.5f}\".format(train_acc), \"val_acc=\", \"{:.5f}\".format(val_acc),\"best_val_acc_trail=\", \"{:.5f}\".format(best_val_acc_trail),\n",
    "      \"test_acc=\", \"{:.5f}\".format(best_test_acc))\n",
    "\n",
    "    if curr_step > args.early_stop:\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "    end = time.time()\n",
    "    print('time ',(end-begin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_vol 4682.702\n",
      "Epoch: 0001 train_loss= 1.79186 val_loss= 1.79155 train_acc= 0.40833 val_acc= 0.21000 best_val_acc_trail= 0.21000 test_acc= 0.19300\n",
      "time  3.4570846557617188\n",
      "edge_vol 4688.2783\n",
      "Epoch: 0002 train_loss= 1.78976 val_loss= 1.79092 train_acc= 0.64167 val_acc= 0.29800 best_val_acc_trail= 0.29800 test_acc= 0.26500\n",
      "time  4.128012418746948\n",
      "edge_vol 4689.879\n",
      "Epoch: 0003 train_loss= 1.78762 val_loss= 1.79027 train_acc= 0.79167 val_acc= 0.35400 best_val_acc_trail= 0.35400 test_acc= 0.32400\n",
      "time  4.78596568107605\n",
      "edge_vol 4687.903\n",
      "Epoch: 0004 train_loss= 1.78541 val_loss= 1.78959 train_acc= 0.83333 val_acc= 0.38600 best_val_acc_trail= 0.38600 test_acc= 0.37500\n",
      "time  5.555476903915405\n",
      "edge_vol 4683.5527\n",
      "Epoch: 0005 train_loss= 1.78323 val_loss= 1.78885 train_acc= 0.88333 val_acc= 0.43600 best_val_acc_trail= 0.43600 test_acc= 0.42400\n",
      "time  6.323407411575317\n",
      "edge_vol 4677.861\n",
      "Epoch: 0006 train_loss= 1.78096 val_loss= 1.78805 train_acc= 0.90000 val_acc= 0.47000 best_val_acc_trail= 0.47000 test_acc= 0.46200\n",
      "time  7.040981769561768\n",
      "edge_vol 4671.295\n",
      "Epoch: 0007 train_loss= 1.77856 val_loss= 1.78718 train_acc= 0.93333 val_acc= 0.50400 best_val_acc_trail= 0.50400 test_acc= 0.48600\n",
      "time  7.899088382720947\n",
      "edge_vol 4664.109\n",
      "Epoch: 0008 train_loss= 1.77607 val_loss= 1.78621 train_acc= 0.93333 val_acc= 0.51800 best_val_acc_trail= 0.51800 test_acc= 0.51800\n",
      "time  8.850077390670776\n",
      "edge_vol 4656.506\n",
      "Epoch: 0009 train_loss= 1.77318 val_loss= 1.78517 train_acc= 0.93333 val_acc= 0.53000 best_val_acc_trail= 0.53000 test_acc= 0.53300\n",
      "time  9.762374639511108\n",
      "edge_vol 4648.513\n",
      "Epoch: 0010 train_loss= 1.77050 val_loss= 1.78403 train_acc= 0.93333 val_acc= 0.54600 best_val_acc_trail= 0.54600 test_acc= 0.54800\n",
      "time  10.636640071868896\n",
      "edge_vol 4640.17\n",
      "Epoch: 0011 train_loss= 1.76739 val_loss= 1.78282 train_acc= 0.93333 val_acc= 0.56800 best_val_acc_trail= 0.56800 test_acc= 0.55700\n",
      "time  11.291118383407593\n",
      "edge_vol 4631.458\n",
      "Epoch: 0012 train_loss= 1.76404 val_loss= 1.78153 train_acc= 0.93333 val_acc= 0.58600 best_val_acc_trail= 0.58600 test_acc= 0.56300\n",
      "time  11.992979526519775\n",
      "edge_vol 4622.407\n",
      "Epoch: 0013 train_loss= 1.76089 val_loss= 1.78017 train_acc= 0.93333 val_acc= 0.58800 best_val_acc_trail= 0.58800 test_acc= 0.57500\n",
      "time  12.7622811794281\n",
      "edge_vol 4613.0693\n",
      "Epoch: 0014 train_loss= 1.75711 val_loss= 1.77875 train_acc= 0.93333 val_acc= 0.59600 best_val_acc_trail= 0.59600 test_acc= 0.58000\n",
      "time  13.47406268119812\n",
      "edge_vol 4603.4116\n",
      "Epoch: 0015 train_loss= 1.75347 val_loss= 1.77727 train_acc= 0.94167 val_acc= 0.59800 best_val_acc_trail= 0.59800 test_acc= 0.58500\n",
      "time  14.27954649925232\n",
      "edge_vol 4593.539\n",
      "Epoch: 0016 train_loss= 1.74912 val_loss= 1.77573 train_acc= 0.94167 val_acc= 0.60000 best_val_acc_trail= 0.60000 test_acc= 0.58900\n",
      "time  15.09744644165039\n",
      "edge_vol 4583.4404\n",
      "Epoch: 0017 train_loss= 1.74530 val_loss= 1.77413 train_acc= 0.93333 val_acc= 0.60800 best_val_acc_trail= 0.60800 test_acc= 0.59600\n",
      "time  15.890945196151733\n",
      "edge_vol 4573.1685\n",
      "Epoch: 0018 train_loss= 1.74096 val_loss= 1.77247 train_acc= 0.93333 val_acc= 0.61200 best_val_acc_trail= 0.61200 test_acc= 0.59400\n",
      "time  16.609554052352905\n",
      "edge_vol 4562.7295\n",
      "Epoch: 0019 train_loss= 1.73628 val_loss= 1.77077 train_acc= 0.94167 val_acc= 0.62000 best_val_acc_trail= 0.62000 test_acc= 0.59900\n",
      "time  17.324739456176758\n",
      "edge_vol 4552.1377\n",
      "Epoch: 0020 train_loss= 1.73152 val_loss= 1.76903 train_acc= 0.94167 val_acc= 0.62400 best_val_acc_trail= 0.62400 test_acc= 0.60100\n",
      "time  17.982733726501465\n",
      "edge_vol 4541.3906\n",
      "Epoch: 0021 train_loss= 1.72671 val_loss= 1.76724 train_acc= 0.94167 val_acc= 0.62800 best_val_acc_trail= 0.62800 test_acc= 0.60100\n",
      "time  18.70023012161255\n",
      "edge_vol 4530.501\n",
      "Epoch: 0022 train_loss= 1.72242 val_loss= 1.76542 train_acc= 0.94167 val_acc= 0.62800 best_val_acc_trail= 0.62800 test_acc= 0.60100\n",
      "time  19.581265449523926\n",
      "edge_vol 4519.5\n",
      "Epoch: 0023 train_loss= 1.71658 val_loss= 1.76354 train_acc= 0.94167 val_acc= 0.62600 best_val_acc_trail= 0.62800 test_acc= 0.60100\n",
      "time  20.38041067123413\n",
      "edge_vol 4508.3535\n",
      "Epoch: 0024 train_loss= 1.71138 val_loss= 1.76162 train_acc= 0.95000 val_acc= 0.62600 best_val_acc_trail= 0.62800 test_acc= 0.60100\n",
      "time  21.196409940719604\n",
      "edge_vol 4497.1084\n",
      "Epoch: 0025 train_loss= 1.70604 val_loss= 1.75967 train_acc= 0.95833 val_acc= 0.62600 best_val_acc_trail= 0.62800 test_acc= 0.60100\n",
      "time  21.998263120651245\n",
      "edge_vol 4485.7676\n",
      "Epoch: 0026 train_loss= 1.70059 val_loss= 1.75769 train_acc= 0.95833 val_acc= 0.62800 best_val_acc_trail= 0.62800 test_acc= 0.60100\n",
      "time  22.838942050933838\n",
      "edge_vol 4474.335\n",
      "Epoch: 0027 train_loss= 1.69445 val_loss= 1.75568 train_acc= 0.95833 val_acc= 0.63400 best_val_acc_trail= 0.63400 test_acc= 0.61800\n",
      "time  23.62874984741211\n",
      "edge_vol 4462.8164\n",
      "Epoch: 0028 train_loss= 1.68910 val_loss= 1.75364 train_acc= 0.95833 val_acc= 0.63200 best_val_acc_trail= 0.63400 test_acc= 0.61800\n",
      "time  24.396435976028442\n",
      "edge_vol 4451.1465\n",
      "Epoch: 0029 train_loss= 1.68290 val_loss= 1.75157 train_acc= 0.95833 val_acc= 0.63400 best_val_acc_trail= 0.63400 test_acc= 0.61800\n",
      "time  25.044517040252686\n",
      "edge_vol 4439.439\n",
      "Epoch: 0030 train_loss= 1.67789 val_loss= 1.74946 train_acc= 0.95833 val_acc= 0.63400 best_val_acc_trail= 0.63400 test_acc= 0.61800\n",
      "time  25.767930269241333\n",
      "edge_vol 4427.6\n",
      "Epoch: 0031 train_loss= 1.67130 val_loss= 1.74733 train_acc= 0.95833 val_acc= 0.63600 best_val_acc_trail= 0.63600 test_acc= 0.62900\n",
      "time  26.531602144241333\n",
      "edge_vol 4415.7236\n",
      "Epoch: 0032 train_loss= 1.66538 val_loss= 1.74518 train_acc= 0.95833 val_acc= 0.63600 best_val_acc_trail= 0.63600 test_acc= 0.62900\n",
      "time  27.417081117630005\n",
      "edge_vol 4403.7764\n",
      "Epoch: 0033 train_loss= 1.65870 val_loss= 1.74301 train_acc= 0.95833 val_acc= 0.63400 best_val_acc_trail= 0.63600 test_acc= 0.62900\n",
      "time  28.215543746948242\n",
      "edge_vol 4391.683\n",
      "Epoch: 0034 train_loss= 1.65076 val_loss= 1.74081 train_acc= 0.95833 val_acc= 0.63200 best_val_acc_trail= 0.63600 test_acc= 0.62900\n",
      "time  28.935417652130127\n",
      "edge_vol 4379.5117\n",
      "Epoch: 0035 train_loss= 1.64529 val_loss= 1.73857 train_acc= 0.95833 val_acc= 0.63600 best_val_acc_trail= 0.63600 test_acc= 0.62900\n",
      "time  29.75046944618225\n",
      "edge_vol 4367.333\n",
      "Epoch: 0036 train_loss= 1.63946 val_loss= 1.73631 train_acc= 0.95833 val_acc= 0.63600 best_val_acc_trail= 0.63600 test_acc= 0.62900\n",
      "time  30.566279649734497\n",
      "edge_vol 4355.177\n",
      "Epoch: 0037 train_loss= 1.63341 val_loss= 1.73402 train_acc= 0.95833 val_acc= 0.64400 best_val_acc_trail= 0.64400 test_acc= 0.63900\n",
      "time  31.23843264579773\n",
      "edge_vol 4343.112\n",
      "Epoch: 0038 train_loss= 1.62638 val_loss= 1.73172 train_acc= 0.95833 val_acc= 0.64600 best_val_acc_trail= 0.64600 test_acc= 0.64100\n",
      "time  32.040297985076904\n",
      "edge_vol 4331.076\n",
      "Epoch: 0039 train_loss= 1.61938 val_loss= 1.72941 train_acc= 0.95833 val_acc= 0.64600 best_val_acc_trail= 0.64600 test_acc= 0.64100\n",
      "time  32.66723322868347\n",
      "edge_vol 4318.874\n",
      "Epoch: 0040 train_loss= 1.61201 val_loss= 1.72707 train_acc= 0.95833 val_acc= 0.64800 best_val_acc_trail= 0.64800 test_acc= 0.63900\n",
      "time  33.48659133911133\n",
      "edge_vol 4306.545\n",
      "Epoch: 0041 train_loss= 1.60453 val_loss= 1.72471 train_acc= 0.96667 val_acc= 0.65000 best_val_acc_trail= 0.65000 test_acc= 0.64000\n",
      "time  34.13092923164368\n",
      "edge_vol 4294.0615\n",
      "Epoch: 0042 train_loss= 1.59835 val_loss= 1.72232 train_acc= 0.96667 val_acc= 0.65000 best_val_acc_trail= 0.65000 test_acc= 0.64000\n",
      "time  34.829853534698486\n",
      "edge_vol 4281.5107\n",
      "Epoch: 0043 train_loss= 1.59108 val_loss= 1.71991 train_acc= 0.96667 val_acc= 0.65400 best_val_acc_trail= 0.65400 test_acc= 0.64300\n",
      "time  35.632012128829956\n",
      "edge_vol 4269.075\n",
      "Epoch: 0044 train_loss= 1.58403 val_loss= 1.71748 train_acc= 0.96667 val_acc= 0.65400 best_val_acc_trail= 0.65400 test_acc= 0.64300\n",
      "time  36.444915533065796\n",
      "edge_vol 4256.5425\n",
      "Epoch: 0045 train_loss= 1.57527 val_loss= 1.71505 train_acc= 0.96667 val_acc= 0.65200 best_val_acc_trail= 0.65400 test_acc= 0.64300\n",
      "time  37.2427704334259\n",
      "edge_vol 4244.1753\n",
      "Epoch: 0046 train_loss= 1.57049 val_loss= 1.71262 train_acc= 0.96667 val_acc= 0.65200 best_val_acc_trail= 0.65400 test_acc= 0.64300\n",
      "time  38.060824394226074\n",
      "edge_vol 4231.866\n",
      "Epoch: 0047 train_loss= 1.56294 val_loss= 1.71018 train_acc= 0.96667 val_acc= 0.65600 best_val_acc_trail= 0.65600 test_acc= 0.64300\n",
      "time  38.88819622993469\n",
      "edge_vol 4219.756\n",
      "Epoch: 0048 train_loss= 1.55878 val_loss= 1.70773 train_acc= 0.96667 val_acc= 0.65600 best_val_acc_trail= 0.65600 test_acc= 0.64300\n",
      "time  39.75730228424072\n",
      "edge_vol 4207.958\n",
      "Epoch: 0049 train_loss= 1.55098 val_loss= 1.70530 train_acc= 0.96667 val_acc= 0.65600 best_val_acc_trail= 0.65600 test_acc= 0.64300\n",
      "time  40.65833234786987\n",
      "edge_vol 4196.1875\n",
      "Epoch: 0050 train_loss= 1.54110 val_loss= 1.70287 train_acc= 0.96667 val_acc= 0.65600 best_val_acc_trail= 0.65600 test_acc= 0.64300\n",
      "time  41.368311166763306\n",
      "edge_vol 4184.636\n",
      "Epoch: 0051 train_loss= 1.53454 val_loss= 1.70042 train_acc= 0.96667 val_acc= 0.65600 best_val_acc_trail= 0.65600 test_acc= 0.64300\n",
      "time  42.13510203361511\n",
      "edge_vol 4172.9165\n",
      "Epoch: 0052 train_loss= 1.52593 val_loss= 1.69796 train_acc= 0.96667 val_acc= 0.65800 best_val_acc_trail= 0.65800 test_acc= 0.65600\n",
      "time  42.96681618690491\n",
      "edge_vol 4161.994\n",
      "Epoch: 0053 train_loss= 1.52041 val_loss= 1.69550 train_acc= 0.96667 val_acc= 0.66400 best_val_acc_trail= 0.66400 test_acc= 0.65700\n",
      "time  43.87977385520935\n",
      "edge_vol 4151.4824\n",
      "Epoch: 0054 train_loss= 1.51227 val_loss= 1.69307 train_acc= 0.96667 val_acc= 0.66200 best_val_acc_trail= 0.66400 test_acc= 0.65700\n",
      "time  44.619529008865356\n",
      "edge_vol 4141.1875\n",
      "Epoch: 0055 train_loss= 1.50434 val_loss= 1.69066 train_acc= 0.96667 val_acc= 0.66200 best_val_acc_trail= 0.66400 test_acc= 0.65700\n",
      "time  45.38540005683899\n",
      "edge_vol 4131.721\n",
      "Epoch: 0056 train_loss= 1.49776 val_loss= 1.68825 train_acc= 0.97500 val_acc= 0.66000 best_val_acc_trail= 0.66400 test_acc= 0.65700\n",
      "time  46.10625743865967\n",
      "edge_vol 4121.883\n",
      "Epoch: 0057 train_loss= 1.48854 val_loss= 1.68586 train_acc= 0.97500 val_acc= 0.66000 best_val_acc_trail= 0.66400 test_acc= 0.65700\n",
      "time  46.812960624694824\n",
      "edge_vol 4112.8604\n",
      "Epoch: 0058 train_loss= 1.48065 val_loss= 1.68348 train_acc= 0.97500 val_acc= 0.66400 best_val_acc_trail= 0.66400 test_acc= 0.65700\n",
      "time  47.57083058357239\n",
      "edge_vol 4104.471\n",
      "Epoch: 0059 train_loss= 1.47382 val_loss= 1.68112 train_acc= 0.97500 val_acc= 0.66800 best_val_acc_trail= 0.66800 test_acc= 0.67100\n",
      "time  48.292261838912964\n",
      "edge_vol 4096.015\n",
      "Epoch: 0060 train_loss= 1.46740 val_loss= 1.67883 train_acc= 0.97500 val_acc= 0.66800 best_val_acc_trail= 0.66800 test_acc= 0.67100\n",
      "time  49.08047914505005\n",
      "edge_vol 4087.5813\n",
      "Epoch: 0061 train_loss= 1.45677 val_loss= 1.67657 train_acc= 0.97500 val_acc= 0.67200 best_val_acc_trail= 0.67200 test_acc= 0.67100\n",
      "time  49.86982250213623\n",
      "edge_vol 4080.524\n",
      "Epoch: 0062 train_loss= 1.45197 val_loss= 1.67432 train_acc= 0.97500 val_acc= 0.67200 best_val_acc_trail= 0.67200 test_acc= 0.67100\n",
      "time  50.707361459732056\n",
      "edge_vol 4075.0273\n",
      "Epoch: 0063 train_loss= 1.44341 val_loss= 1.67208 train_acc= 0.97500 val_acc= 0.67200 best_val_acc_trail= 0.67200 test_acc= 0.67100\n",
      "time  51.373499393463135\n",
      "edge_vol 4069.6638\n",
      "Epoch: 0064 train_loss= 1.43781 val_loss= 1.66983 train_acc= 0.97500 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.66900\n",
      "time  52.08575201034546\n",
      "edge_vol 4063.3022\n",
      "Epoch: 0065 train_loss= 1.42955 val_loss= 1.66761 train_acc= 0.97500 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.66900\n",
      "time  52.93372106552124\n",
      "edge_vol 4059.0845\n",
      "Epoch: 0066 train_loss= 1.42369 val_loss= 1.66542 train_acc= 0.97500 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.66900\n",
      "time  53.862117290496826\n",
      "edge_vol 4056.1804\n",
      "Epoch: 0067 train_loss= 1.41747 val_loss= 1.66327 train_acc= 0.97500 val_acc= 0.67200 best_val_acc_trail= 0.67400 test_acc= 0.66900\n",
      "time  54.93026328086853\n",
      "edge_vol 4054.3477\n",
      "Epoch: 0068 train_loss= 1.41116 val_loss= 1.66120 train_acc= 0.97500 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.67300\n",
      "time  55.770010471343994\n",
      "edge_vol 4055.1729\n",
      "Epoch: 0069 train_loss= 1.40425 val_loss= 1.65916 train_acc= 0.97500 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.67300\n",
      "time  56.5971200466156\n",
      "edge_vol 4056.8123\n",
      "Epoch: 0070 train_loss= 1.39706 val_loss= 1.65718 train_acc= 0.97500 val_acc= 0.67200 best_val_acc_trail= 0.67400 test_acc= 0.67300\n",
      "time  57.29934310913086\n",
      "edge_vol 4060.2153\n",
      "Epoch: 0071 train_loss= 1.39165 val_loss= 1.65530 train_acc= 0.97500 val_acc= 0.67200 best_val_acc_trail= 0.67400 test_acc= 0.67300\n",
      "time  57.945435523986816\n",
      "edge_vol 4065.609\n",
      "Epoch: 0072 train_loss= 1.38160 val_loss= 1.65351 train_acc= 0.97500 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.67300\n",
      "time  58.5740692615509\n",
      "edge_vol 4073.6013\n",
      "Epoch: 0073 train_loss= 1.37511 val_loss= 1.65179 train_acc= 0.97500 val_acc= 0.67600 best_val_acc_trail= 0.67600 test_acc= 0.67400\n",
      "time  59.21117067337036\n",
      "edge_vol 4081.6387\n",
      "Epoch: 0074 train_loss= 1.37193 val_loss= 1.65014 train_acc= 0.97500 val_acc= 0.67400 best_val_acc_trail= 0.67600 test_acc= 0.67400\n",
      "time  59.854201555252075\n",
      "edge_vol 4092.1846\n",
      "Epoch: 0075 train_loss= 1.36510 val_loss= 1.64853 train_acc= 0.97500 val_acc= 0.67600 best_val_acc_trail= 0.67600 test_acc= 0.67400\n",
      "time  60.57350540161133\n",
      "edge_vol 4105.001\n",
      "Epoch: 0076 train_loss= 1.35918 val_loss= 1.64700 train_acc= 0.97500 val_acc= 0.67800 best_val_acc_trail= 0.67800 test_acc= 0.67300\n",
      "time  61.44171357154846\n",
      "edge_vol 4119.1304\n",
      "Epoch: 0077 train_loss= 1.35278 val_loss= 1.64551 train_acc= 0.97500 val_acc= 0.67800 best_val_acc_trail= 0.67800 test_acc= 0.67300\n",
      "time  62.217716455459595\n",
      "edge_vol 4134.949\n",
      "Epoch: 0078 train_loss= 1.34772 val_loss= 1.64404 train_acc= 0.97500 val_acc= 0.67800 best_val_acc_trail= 0.67800 test_acc= 0.67300\n",
      "time  62.973212003707886\n",
      "edge_vol 4151.8\n",
      "Epoch: 0079 train_loss= 1.34296 val_loss= 1.64268 train_acc= 0.97500 val_acc= 0.68000 best_val_acc_trail= 0.68000 test_acc= 0.67400\n",
      "time  63.6424560546875\n",
      "edge_vol 4169.977\n",
      "Epoch: 0080 train_loss= 1.33898 val_loss= 1.64139 train_acc= 0.98333 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.67400\n",
      "time  64.41062521934509\n",
      "edge_vol 4189.324\n",
      "Epoch: 0081 train_loss= 1.33672 val_loss= 1.64015 train_acc= 0.97500 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.67400\n",
      "time  65.06892013549805\n",
      "edge_vol 4209.6367\n",
      "Epoch: 0082 train_loss= 1.32809 val_loss= 1.63895 train_acc= 0.97500 val_acc= 0.68000 best_val_acc_trail= 0.68200 test_acc= 0.67400\n",
      "time  65.85167813301086\n",
      "edge_vol 4230.221\n",
      "Epoch: 0083 train_loss= 1.32406 val_loss= 1.63778 train_acc= 0.97500 val_acc= 0.68000 best_val_acc_trail= 0.68200 test_acc= 0.67400\n",
      "time  66.65160894393921\n",
      "edge_vol 4251.0015\n",
      "Epoch: 0084 train_loss= 1.31230 val_loss= 1.63666 train_acc= 0.97500 val_acc= 0.68000 best_val_acc_trail= 0.68200 test_acc= 0.67400\n",
      "time  67.2996175289154\n",
      "edge_vol 4272.5586\n",
      "Epoch: 0085 train_loss= 1.30909 val_loss= 1.63560 train_acc= 0.97500 val_acc= 0.68400 best_val_acc_trail= 0.68400 test_acc= 0.67600\n",
      "time  68.0961663722992\n",
      "edge_vol 4294.7754\n",
      "Epoch: 0086 train_loss= 1.30853 val_loss= 1.63459 train_acc= 0.97500 val_acc= 0.68200 best_val_acc_trail= 0.68400 test_acc= 0.67600\n",
      "time  68.75137114524841\n",
      "edge_vol 4317.156\n",
      "Epoch: 0087 train_loss= 1.30458 val_loss= 1.63361 train_acc= 0.97500 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67600\n",
      "time  69.66317987442017\n",
      "edge_vol 4339.9585\n",
      "Epoch: 0088 train_loss= 1.30322 val_loss= 1.63258 train_acc= 0.97500 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67600\n",
      "time  70.38819432258606\n",
      "edge_vol 4363.032\n",
      "Epoch: 0089 train_loss= 1.29316 val_loss= 1.63152 train_acc= 0.97500 val_acc= 0.68200 best_val_acc_trail= 0.68400 test_acc= 0.67600\n",
      "time  71.0835030078888\n",
      "edge_vol 4386.2\n",
      "Epoch: 0090 train_loss= 1.29014 val_loss= 1.63041 train_acc= 0.97500 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67600\n",
      "time  71.89764618873596\n",
      "edge_vol 4409.537\n",
      "Epoch: 0091 train_loss= 1.28863 val_loss= 1.62937 train_acc= 0.97500 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67600\n",
      "time  72.56770372390747\n",
      "edge_vol 4432.6816\n",
      "Epoch: 0092 train_loss= 1.28366 val_loss= 1.62837 train_acc= 0.97500 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67600\n",
      "time  73.20087218284607\n",
      "edge_vol 4455.9414\n",
      "Epoch: 0093 train_loss= 1.27914 val_loss= 1.62742 train_acc= 0.97500 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.67600\n",
      "time  74.12460398674011\n",
      "edge_vol 4479.549\n",
      "Epoch: 0094 train_loss= 1.27413 val_loss= 1.62659 train_acc= 0.97500 val_acc= 0.68400 best_val_acc_trail= 0.68400 test_acc= 0.67600\n",
      "time  75.14762592315674\n",
      "edge_vol 4503.508\n",
      "Epoch: 0095 train_loss= 1.27115 val_loss= 1.62584 train_acc= 0.97500 val_acc= 0.68400 best_val_acc_trail= 0.68400 test_acc= 0.67600\n",
      "time  75.89666771888733\n",
      "edge_vol 4527.8843\n",
      "Epoch: 0096 train_loss= 1.26638 val_loss= 1.62515 train_acc= 0.96667 val_acc= 0.68400 best_val_acc_trail= 0.68400 test_acc= 0.67600\n",
      "time  76.662588596344\n",
      "edge_vol 4551.7095\n",
      "Epoch: 0097 train_loss= 1.25762 val_loss= 1.62437 train_acc= 0.96667 val_acc= 0.68400 best_val_acc_trail= 0.68400 test_acc= 0.67600\n",
      "time  77.45583486557007\n",
      "edge_vol 4574.956\n",
      "Epoch: 0098 train_loss= 1.25692 val_loss= 1.62364 train_acc= 0.96667 val_acc= 0.68600 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  78.34607744216919\n",
      "edge_vol 4598.5605\n",
      "Epoch: 0099 train_loss= 1.25420 val_loss= 1.62301 train_acc= 0.96667 val_acc= 0.68600 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  79.15893125534058\n",
      "edge_vol 4622.444\n",
      "Epoch: 0100 train_loss= 1.24701 val_loss= 1.62235 train_acc= 0.96667 val_acc= 0.68600 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  79.96895289421082\n",
      "edge_vol 4646.6084\n",
      "Epoch: 0101 train_loss= 1.24515 val_loss= 1.62171 train_acc= 0.96667 val_acc= 0.68400 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  80.82977199554443\n",
      "edge_vol 4671.252\n",
      "Epoch: 0102 train_loss= 1.24160 val_loss= 1.62107 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  81.59684896469116\n",
      "edge_vol 4696.134\n",
      "Epoch: 0103 train_loss= 1.24329 val_loss= 1.62040 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  82.58552861213684\n",
      "edge_vol 4720.8564\n",
      "Epoch: 0104 train_loss= 1.23399 val_loss= 1.61972 train_acc= 0.96667 val_acc= 0.67800 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  83.26536512374878\n",
      "edge_vol 4745.7993\n",
      "Epoch: 0105 train_loss= 1.23352 val_loss= 1.61908 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  84.04053473472595\n",
      "edge_vol 4771.1533\n",
      "Epoch: 0106 train_loss= 1.23786 val_loss= 1.61843 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  84.82232594490051\n",
      "edge_vol 4797.073\n",
      "Epoch: 0107 train_loss= 1.22552 val_loss= 1.61779 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  85.76950168609619\n",
      "edge_vol 4823.3535\n",
      "Epoch: 0108 train_loss= 1.22907 val_loss= 1.61711 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  86.52283239364624\n",
      "edge_vol 4849.6646\n",
      "Epoch: 0109 train_loss= 1.22808 val_loss= 1.61652 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  87.3057267665863\n",
      "edge_vol 4876.1504\n",
      "Epoch: 0110 train_loss= 1.22908 val_loss= 1.61604 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  88.01183748245239\n",
      "edge_vol 4900.8804\n",
      "Epoch: 0111 train_loss= 1.21566 val_loss= 1.61557 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  88.8516173362732\n",
      "edge_vol 4923.7314\n",
      "Epoch: 0112 train_loss= 1.21508 val_loss= 1.61521 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  89.65973281860352\n",
      "edge_vol 4945.667\n",
      "Epoch: 0113 train_loss= 1.21852 val_loss= 1.61486 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  90.43817186355591\n",
      "edge_vol 4965.8774\n",
      "Epoch: 0114 train_loss= 1.21343 val_loss= 1.61446 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  91.06283378601074\n",
      "edge_vol 4985.711\n",
      "Epoch: 0115 train_loss= 1.21040 val_loss= 1.61405 train_acc= 0.96667 val_acc= 0.68400 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  91.8319890499115\n",
      "edge_vol 5005.5312\n",
      "Epoch: 0116 train_loss= 1.21674 val_loss= 1.61357 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  92.59154224395752\n",
      "edge_vol 5025.959\n",
      "Epoch: 0117 train_loss= 1.20551 val_loss= 1.61309 train_acc= 0.96667 val_acc= 0.68000 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  93.3890974521637\n",
      "edge_vol 5046.996\n",
      "Epoch: 0118 train_loss= 1.20748 val_loss= 1.61256 train_acc= 0.96667 val_acc= 0.68000 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  93.99928665161133\n",
      "edge_vol 5068.231\n",
      "Epoch: 0119 train_loss= 1.20145 val_loss= 1.61204 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  94.9010055065155\n",
      "edge_vol 5089.617\n",
      "Epoch: 0120 train_loss= 1.19815 val_loss= 1.61140 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  95.62845802307129\n",
      "edge_vol 5111.416\n",
      "Epoch: 0121 train_loss= 1.19522 val_loss= 1.61065 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  96.27129650115967\n",
      "edge_vol 5133.4316\n",
      "Epoch: 0122 train_loss= 1.19425 val_loss= 1.60983 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  96.89582443237305\n",
      "edge_vol 5155.62\n",
      "Epoch: 0123 train_loss= 1.19034 val_loss= 1.60898 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  97.55195426940918\n",
      "edge_vol 5178.53\n",
      "Epoch: 0124 train_loss= 1.19013 val_loss= 1.60811 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  98.51116871833801\n",
      "edge_vol 5201.6826\n",
      "Epoch: 0125 train_loss= 1.19026 val_loss= 1.60719 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  99.49703240394592\n",
      "edge_vol 5225.329\n",
      "Epoch: 0126 train_loss= 1.17929 val_loss= 1.60620 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  100.11362719535828\n",
      "edge_vol 5249.3594\n",
      "Epoch: 0127 train_loss= 1.18003 val_loss= 1.60512 train_acc= 0.96667 val_acc= 0.67800 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  100.9116780757904\n",
      "edge_vol 5273.957\n",
      "Epoch: 0128 train_loss= 1.17628 val_loss= 1.60397 train_acc= 0.96667 val_acc= 0.67800 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  101.84495830535889\n",
      "edge_vol 5298.821\n",
      "Epoch: 0129 train_loss= 1.17280 val_loss= 1.60281 train_acc= 0.96667 val_acc= 0.67800 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  102.57612180709839\n",
      "edge_vol 5324.056\n",
      "Epoch: 0130 train_loss= 1.17128 val_loss= 1.60154 train_acc= 0.96667 val_acc= 0.67600 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  103.26260614395142\n",
      "edge_vol 5349.2773\n",
      "Epoch: 0131 train_loss= 1.16610 val_loss= 1.60013 train_acc= 0.96667 val_acc= 0.67400 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  103.97861075401306\n",
      "edge_vol 5374.4463\n",
      "Epoch: 0132 train_loss= 1.17193 val_loss= 1.59865 train_acc= 0.96667 val_acc= 0.67600 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  104.95217394828796\n",
      "edge_vol 5399.8945\n",
      "Epoch: 0133 train_loss= 1.16535 val_loss= 1.59714 train_acc= 0.96667 val_acc= 0.67600 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  105.73774290084839\n",
      "edge_vol 5426.0264\n",
      "Epoch: 0134 train_loss= 1.16272 val_loss= 1.59552 train_acc= 0.96667 val_acc= 0.67600 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  106.47943329811096\n",
      "edge_vol 5452.391\n",
      "Epoch: 0135 train_loss= 1.15307 val_loss= 1.59386 train_acc= 0.96667 val_acc= 0.67600 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  107.2854106426239\n",
      "edge_vol 5479.5684\n",
      "Epoch: 0136 train_loss= 1.14934 val_loss= 1.59219 train_acc= 0.97500 val_acc= 0.67600 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  108.1105477809906\n",
      "edge_vol 5506.865\n",
      "Epoch: 0137 train_loss= 1.14922 val_loss= 1.59039 train_acc= 0.97500 val_acc= 0.67600 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  108.86524868011475\n",
      "edge_vol 5534.3984\n",
      "Epoch: 0138 train_loss= 1.14566 val_loss= 1.58848 train_acc= 0.97500 val_acc= 0.67600 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  109.6885917186737\n",
      "edge_vol 5562.4805\n",
      "Epoch: 0139 train_loss= 1.14386 val_loss= 1.58656 train_acc= 0.97500 val_acc= 0.67800 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  110.52910566329956\n",
      "edge_vol 5590.577\n",
      "Epoch: 0140 train_loss= 1.13408 val_loss= 1.58456 train_acc= 0.97500 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  111.16351056098938\n",
      "edge_vol 5619.007\n",
      "Epoch: 0141 train_loss= 1.12846 val_loss= 1.58244 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  111.87878942489624\n",
      "edge_vol 5648.3154\n",
      "Epoch: 0142 train_loss= 1.12786 val_loss= 1.58017 train_acc= 0.96667 val_acc= 0.68000 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  112.63671827316284\n",
      "edge_vol 5677.915\n",
      "Epoch: 0143 train_loss= 1.12271 val_loss= 1.57781 train_acc= 0.97500 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  113.3561270236969\n",
      "edge_vol 5707.921\n",
      "Epoch: 0144 train_loss= 1.12401 val_loss= 1.57538 train_acc= 0.97500 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  113.96885895729065\n",
      "edge_vol 5738.1025\n",
      "Epoch: 0145 train_loss= 1.11158 val_loss= 1.57291 train_acc= 0.97500 val_acc= 0.68400 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  114.66434288024902\n",
      "edge_vol 5769.1187\n",
      "Epoch: 0146 train_loss= 1.10687 val_loss= 1.57042 train_acc= 0.97500 val_acc= 0.68400 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  115.3226900100708\n",
      "edge_vol 5800.932\n",
      "Epoch: 0147 train_loss= 1.10115 val_loss= 1.56788 train_acc= 0.97500 val_acc= 0.68200 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  116.07831501960754\n",
      "edge_vol 5833.3374\n",
      "Epoch: 0148 train_loss= 1.09790 val_loss= 1.56525 train_acc= 0.97500 val_acc= 0.68400 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  116.78712797164917\n",
      "edge_vol 5866.3335\n",
      "Epoch: 0149 train_loss= 1.09266 val_loss= 1.56256 train_acc= 0.97500 val_acc= 0.68400 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  117.52923464775085\n",
      "edge_vol 5899.711\n",
      "Epoch: 0150 train_loss= 1.08753 val_loss= 1.55988 train_acc= 0.97500 val_acc= 0.68400 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  118.17759990692139\n",
      "edge_vol 5933.5776\n",
      "Epoch: 0151 train_loss= 1.08087 val_loss= 1.55710 train_acc= 0.97500 val_acc= 0.68400 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  119.02285599708557\n",
      "edge_vol 5968.3135\n",
      "Epoch: 0152 train_loss= 1.08186 val_loss= 1.55426 train_acc= 0.97500 val_acc= 0.68400 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  119.82311677932739\n",
      "edge_vol 6003.3916\n",
      "Epoch: 0153 train_loss= 1.06751 val_loss= 1.55136 train_acc= 0.97500 val_acc= 0.68400 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  120.47480797767639\n",
      "edge_vol 6038.7314\n",
      "Epoch: 0154 train_loss= 1.06605 val_loss= 1.54844 train_acc= 0.97500 val_acc= 0.68400 best_val_acc_trail= 0.68600 test_acc= 0.66800\n",
      "time  121.13742232322693\n",
      "edge_vol 6074.5957\n",
      "Epoch: 0155 train_loss= 1.06362 val_loss= 1.54549 train_acc= 0.97500 val_acc= 0.68800 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  121.87994122505188\n",
      "edge_vol 6110.826\n",
      "Epoch: 0156 train_loss= 1.05936 val_loss= 1.54254 train_acc= 0.97500 val_acc= 0.68600 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  122.62912487983704\n",
      "edge_vol 6147.336\n",
      "Epoch: 0157 train_loss= 1.05131 val_loss= 1.53964 train_acc= 0.97500 val_acc= 0.68600 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  123.34993958473206\n",
      "edge_vol 6185.153\n",
      "Epoch: 0158 train_loss= 1.04638 val_loss= 1.53681 train_acc= 0.97500 val_acc= 0.68200 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  124.13697910308838\n",
      "edge_vol 6223.891\n",
      "Epoch: 0159 train_loss= 1.03752 val_loss= 1.53400 train_acc= 0.97500 val_acc= 0.68200 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  124.86430191993713\n",
      "edge_vol 6263.307\n",
      "Epoch: 0160 train_loss= 1.03656 val_loss= 1.53123 train_acc= 0.97500 val_acc= 0.68200 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  125.49959826469421\n",
      "edge_vol 6303.225\n",
      "Epoch: 0161 train_loss= 1.02748 val_loss= 1.52844 train_acc= 0.97500 val_acc= 0.68600 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  126.26576638221741\n",
      "edge_vol 6343.9893\n",
      "Epoch: 0162 train_loss= 1.02828 val_loss= 1.52568 train_acc= 0.97500 val_acc= 0.68600 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  127.08175086975098\n",
      "edge_vol 6385.407\n",
      "Epoch: 0163 train_loss= 1.01849 val_loss= 1.52289 train_acc= 0.97500 val_acc= 0.68600 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  127.73443627357483\n",
      "edge_vol 6427.618\n",
      "Epoch: 0164 train_loss= 1.01845 val_loss= 1.52012 train_acc= 0.97500 val_acc= 0.68600 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  128.39081811904907\n",
      "edge_vol 6469.992\n",
      "Epoch: 0165 train_loss= 1.01001 val_loss= 1.51747 train_acc= 0.97500 val_acc= 0.68600 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  129.1449613571167\n",
      "edge_vol 6512.7314\n",
      "Epoch: 0166 train_loss= 1.00687 val_loss= 1.51485 train_acc= 0.97500 val_acc= 0.68600 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  129.87230968475342\n",
      "edge_vol 6555.7686\n",
      "Epoch: 0167 train_loss= 0.99908 val_loss= 1.51221 train_acc= 0.97500 val_acc= 0.68400 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  130.52797317504883\n",
      "edge_vol 6599.0493\n",
      "Epoch: 0168 train_loss= 0.99484 val_loss= 1.50956 train_acc= 0.97500 val_acc= 0.68600 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  131.32224678993225\n",
      "edge_vol 6642.466\n",
      "Epoch: 0169 train_loss= 0.99214 val_loss= 1.50699 train_acc= 0.97500 val_acc= 0.68600 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  132.0080761909485\n",
      "edge_vol 6686.1514\n",
      "Epoch: 0170 train_loss= 0.98919 val_loss= 1.50450 train_acc= 0.97500 val_acc= 0.68800 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  132.92422199249268\n",
      "edge_vol 6730.3184\n",
      "Epoch: 0171 train_loss= 0.98618 val_loss= 1.50197 train_acc= 0.97500 val_acc= 0.68600 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  133.65779066085815\n",
      "edge_vol 6774.931\n",
      "Epoch: 0172 train_loss= 0.97969 val_loss= 1.49949 train_acc= 0.97500 val_acc= 0.68600 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  134.32623171806335\n",
      "edge_vol 6819.3726\n",
      "Epoch: 0173 train_loss= 0.97665 val_loss= 1.49701 train_acc= 0.97500 val_acc= 0.68600 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  134.97172379493713\n",
      "edge_vol 6863.478\n",
      "Epoch: 0174 train_loss= 0.96969 val_loss= 1.49446 train_acc= 0.97500 val_acc= 0.68600 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  135.70319199562073\n",
      "edge_vol 6907.922\n",
      "Epoch: 0175 train_loss= 0.96961 val_loss= 1.49197 train_acc= 0.97500 val_acc= 0.68600 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  136.41907167434692\n",
      "edge_vol 6952.274\n",
      "Epoch: 0176 train_loss= 0.96520 val_loss= 1.48950 train_acc= 0.97500 val_acc= 0.68600 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  137.18801856040955\n",
      "edge_vol 6996.355\n",
      "Epoch: 0177 train_loss= 0.96055 val_loss= 1.48723 train_acc= 0.97500 val_acc= 0.68800 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  138.10580921173096\n",
      "edge_vol 7040.5684\n",
      "Epoch: 0178 train_loss= 0.95223 val_loss= 1.48495 train_acc= 0.97500 val_acc= 0.68800 best_val_acc_trail= 0.68800 test_acc= 0.68200\n",
      "time  138.9722707271576\n",
      "edge_vol 7084.208\n",
      "Epoch: 0179 train_loss= 0.95270 val_loss= 1.48271 train_acc= 0.97500 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.68800\n",
      "time  139.74218845367432\n",
      "edge_vol 7127.2993\n",
      "Epoch: 0180 train_loss= 0.95362 val_loss= 1.48055 train_acc= 0.97500 val_acc= 0.69400 best_val_acc_trail= 0.69400 test_acc= 0.69000\n",
      "time  140.48221969604492\n",
      "edge_vol 7170.3877\n",
      "Epoch: 0181 train_loss= 0.94435 val_loss= 1.47835 train_acc= 0.97500 val_acc= 0.69400 best_val_acc_trail= 0.69400 test_acc= 0.69000\n",
      "time  141.09734630584717\n",
      "edge_vol 7213.382\n",
      "Epoch: 0182 train_loss= 0.93975 val_loss= 1.47617 train_acc= 0.97500 val_acc= 0.69200 best_val_acc_trail= 0.69400 test_acc= 0.69000\n",
      "time  141.82211685180664\n",
      "edge_vol 7256.0703\n",
      "Epoch: 0183 train_loss= 0.93820 val_loss= 1.47388 train_acc= 0.97500 val_acc= 0.69400 best_val_acc_trail= 0.69400 test_acc= 0.69000\n",
      "time  142.58361148834229\n",
      "edge_vol 7298.0957\n",
      "Epoch: 0184 train_loss= 0.93207 val_loss= 1.47155 train_acc= 0.97500 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.69200\n",
      "time  143.24766182899475\n",
      "edge_vol 7340.1943\n",
      "Epoch: 0185 train_loss= 0.93139 val_loss= 1.46925 train_acc= 0.97500 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.69200\n",
      "time  144.00384736061096\n",
      "edge_vol 7382.259\n",
      "Epoch: 0186 train_loss= 0.92982 val_loss= 1.46709 train_acc= 0.97500 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.69200\n",
      "time  144.74157524108887\n",
      "edge_vol 7423.8315\n",
      "Epoch: 0187 train_loss= 0.92026 val_loss= 1.46489 train_acc= 0.97500 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.69200\n",
      "time  145.5894844532013\n",
      "edge_vol 7465.5684\n",
      "Epoch: 0188 train_loss= 0.91697 val_loss= 1.46279 train_acc= 0.97500 val_acc= 0.69400 best_val_acc_trail= 0.69600 test_acc= 0.69200\n",
      "time  146.27527165412903\n",
      "edge_vol 7506.911\n",
      "Epoch: 0189 train_loss= 0.91264 val_loss= 1.46070 train_acc= 0.97500 val_acc= 0.69400 best_val_acc_trail= 0.69600 test_acc= 0.69200\n",
      "time  146.9318346977234\n",
      "edge_vol 7547.842\n",
      "Epoch: 0190 train_loss= 0.91238 val_loss= 1.45863 train_acc= 0.97500 val_acc= 0.69400 best_val_acc_trail= 0.69600 test_acc= 0.69200\n",
      "time  147.62734293937683\n",
      "edge_vol 7588.6807\n",
      "Epoch: 0191 train_loss= 0.90550 val_loss= 1.45646 train_acc= 0.97500 val_acc= 0.69400 best_val_acc_trail= 0.69600 test_acc= 0.69200\n",
      "time  148.28600430488586\n",
      "edge_vol 7629.0103\n",
      "Epoch: 0192 train_loss= 0.90194 val_loss= 1.45427 train_acc= 0.97500 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68900\n",
      "time  149.04749703407288\n",
      "edge_vol 7668.6685\n",
      "Epoch: 0193 train_loss= 0.89718 val_loss= 1.45201 train_acc= 0.97500 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68900\n",
      "time  149.84151148796082\n",
      "edge_vol 7708.1577\n",
      "Epoch: 0194 train_loss= 0.89820 val_loss= 1.44970 train_acc= 0.97500 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68900\n",
      "time  150.55195784568787\n",
      "edge_vol 7746.4805\n",
      "Epoch: 0195 train_loss= 0.89517 val_loss= 1.44739 train_acc= 0.97500 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68900\n",
      "time  151.21986436843872\n",
      "edge_vol 7784.542\n",
      "Epoch: 0196 train_loss= 0.88736 val_loss= 1.44502 train_acc= 0.97500 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68900\n",
      "time  152.00962376594543\n",
      "edge_vol 7822.23\n",
      "Epoch: 0197 train_loss= 0.88662 val_loss= 1.44262 train_acc= 0.97500 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68900\n",
      "time  152.67049527168274\n",
      "edge_vol 7859.251\n",
      "Epoch: 0198 train_loss= 0.88077 val_loss= 1.44016 train_acc= 0.97500 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68900\n",
      "time  153.33316040039062\n",
      "edge_vol 7895.7124\n",
      "Epoch: 0199 train_loss= 0.87479 val_loss= 1.43772 train_acc= 0.97500 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68900\n",
      "time  154.2201747894287\n",
      "edge_vol 7931.445\n",
      "Epoch: 0200 train_loss= 0.87095 val_loss= 1.43530 train_acc= 0.97500 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68900\n",
      "time  155.12853527069092\n",
      "edge_vol 7966.7056\n",
      "Epoch: 0201 train_loss= 0.87012 val_loss= 1.43290 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.69800 test_acc= 0.69200\n",
      "time  155.8832380771637\n",
      "edge_vol 8001.226\n",
      "Epoch: 0202 train_loss= 0.86425 val_loss= 1.43052 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.69800 test_acc= 0.69200\n",
      "time  156.58225297927856\n",
      "edge_vol 8035.541\n",
      "Epoch: 0203 train_loss= 0.86542 val_loss= 1.42810 train_acc= 0.97500 val_acc= 0.70000 best_val_acc_trail= 0.70000 test_acc= 0.69200\n",
      "time  157.23426628112793\n",
      "edge_vol 8069.26\n",
      "Epoch: 0204 train_loss= 0.85737 val_loss= 1.42573 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.70000 test_acc= 0.69200\n",
      "time  157.9301540851593\n",
      "edge_vol 8102.731\n",
      "Epoch: 0205 train_loss= 0.85450 val_loss= 1.42340 train_acc= 0.97500 val_acc= 0.70000 best_val_acc_trail= 0.70000 test_acc= 0.69200\n",
      "time  158.68904399871826\n",
      "edge_vol 8135.508\n",
      "Epoch: 0206 train_loss= 0.84736 val_loss= 1.42106 train_acc= 0.97500 val_acc= 0.70000 best_val_acc_trail= 0.70000 test_acc= 0.69200\n",
      "time  159.4038531780243\n",
      "edge_vol 8167.931\n",
      "Epoch: 0207 train_loss= 0.84472 val_loss= 1.41867 train_acc= 0.97500 val_acc= 0.70200 best_val_acc_trail= 0.70200 test_acc= 0.69500\n",
      "time  160.13507628440857\n",
      "edge_vol 8199.665\n",
      "Epoch: 0208 train_loss= 0.84260 val_loss= 1.41633 train_acc= 0.97500 val_acc= 0.70200 best_val_acc_trail= 0.70200 test_acc= 0.69500\n",
      "time  160.84710502624512\n",
      "edge_vol 8230.6875\n",
      "Epoch: 0209 train_loss= 0.83924 val_loss= 1.41403 train_acc= 0.97500 val_acc= 0.70200 best_val_acc_trail= 0.70200 test_acc= 0.69500\n",
      "time  161.56063866615295\n",
      "edge_vol 8260.981\n",
      "Epoch: 0210 train_loss= 0.83280 val_loss= 1.41167 train_acc= 0.97500 val_acc= 0.70200 best_val_acc_trail= 0.70200 test_acc= 0.69500\n",
      "time  162.27050399780273\n",
      "edge_vol 8290.872\n",
      "Epoch: 0211 train_loss= 0.83569 val_loss= 1.40926 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.70400 test_acc= 0.69600\n",
      "time  162.99619126319885\n",
      "edge_vol 8320.307\n",
      "Epoch: 0212 train_loss= 0.82961 val_loss= 1.40681 train_acc= 0.97500 val_acc= 0.70200 best_val_acc_trail= 0.70400 test_acc= 0.69600\n",
      "time  163.75926685333252\n",
      "edge_vol 8348.6455\n",
      "Epoch: 0213 train_loss= 0.82289 val_loss= 1.40428 train_acc= 0.97500 val_acc= 0.70200 best_val_acc_trail= 0.70400 test_acc= 0.69600\n",
      "time  164.50499820709229\n",
      "edge_vol 8376.494\n",
      "Epoch: 0214 train_loss= 0.82100 val_loss= 1.40174 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.70400 test_acc= 0.69600\n",
      "time  165.33392333984375\n",
      "edge_vol 8403.922\n",
      "Epoch: 0215 train_loss= 0.81288 val_loss= 1.39923 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.70400 test_acc= 0.69600\n",
      "time  166.16784000396729\n",
      "edge_vol 8430.6\n",
      "Epoch: 0216 train_loss= 0.80817 val_loss= 1.39666 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70600 test_acc= 0.69700\n",
      "time  166.95593643188477\n",
      "edge_vol 8456.629\n",
      "Epoch: 0217 train_loss= 0.80683 val_loss= 1.39416 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70600 test_acc= 0.69700\n",
      "time  167.8652675151825\n",
      "edge_vol 8481.753\n",
      "Epoch: 0218 train_loss= 0.80039 val_loss= 1.39164 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.70600 test_acc= 0.69700\n",
      "time  168.72169995307922\n",
      "edge_vol 8506.406\n",
      "Epoch: 0219 train_loss= 0.79774 val_loss= 1.38898 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70600 test_acc= 0.69700\n",
      "time  169.51084208488464\n",
      "edge_vol 8530.444\n",
      "Epoch: 0220 train_loss= 0.79578 val_loss= 1.38626 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70600 test_acc= 0.69700\n",
      "time  170.20463061332703\n",
      "edge_vol 8553.808\n",
      "Epoch: 0221 train_loss= 0.78860 val_loss= 1.38355 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70600 test_acc= 0.69700\n",
      "time  170.91412806510925\n",
      "edge_vol 8576.57\n",
      "Epoch: 0222 train_loss= 0.78598 val_loss= 1.38086 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70600 test_acc= 0.69700\n",
      "time  171.5335144996643\n",
      "edge_vol 8598.528\n",
      "Epoch: 0223 train_loss= 0.77991 val_loss= 1.37815 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70600 test_acc= 0.69700\n",
      "time  172.14232397079468\n",
      "edge_vol 8619.654\n",
      "Epoch: 0224 train_loss= 0.77924 val_loss= 1.37537 train_acc= 0.97500 val_acc= 0.71000 best_val_acc_trail= 0.71000 test_acc= 0.69600\n",
      "time  172.78898310661316\n",
      "edge_vol 8639.996\n",
      "Epoch: 0225 train_loss= 0.77103 val_loss= 1.37253 train_acc= 0.97500 val_acc= 0.71200 best_val_acc_trail= 0.71200 test_acc= 0.69600\n",
      "time  173.51198053359985\n",
      "edge_vol 8660.197\n",
      "Epoch: 0226 train_loss= 0.76666 val_loss= 1.36964 train_acc= 0.97500 val_acc= 0.71400 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  174.28037309646606\n",
      "edge_vol 8680.059\n",
      "Epoch: 0227 train_loss= 0.76460 val_loss= 1.36672 train_acc= 0.97500 val_acc= 0.71200 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  174.980486869812\n",
      "edge_vol 8698.879\n",
      "Epoch: 0228 train_loss= 0.75811 val_loss= 1.36382 train_acc= 0.97500 val_acc= 0.71200 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  175.739275932312\n",
      "edge_vol 8717.086\n",
      "Epoch: 0229 train_loss= 0.75429 val_loss= 1.36107 train_acc= 0.97500 val_acc= 0.71200 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  176.5938515663147\n",
      "edge_vol 8735.091\n",
      "Epoch: 0230 train_loss= 0.74996 val_loss= 1.35836 train_acc= 0.97500 val_acc= 0.71200 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  177.32016563415527\n",
      "edge_vol 8752.342\n",
      "Epoch: 0231 train_loss= 0.74500 val_loss= 1.35563 train_acc= 0.97500 val_acc= 0.71000 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  178.10155057907104\n",
      "edge_vol 8768.934\n",
      "Epoch: 0232 train_loss= 0.74321 val_loss= 1.35290 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  178.8414785861969\n",
      "edge_vol 8785.396\n",
      "Epoch: 0233 train_loss= 0.73969 val_loss= 1.35027 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  179.75603222846985\n",
      "edge_vol 8801.41\n",
      "Epoch: 0234 train_loss= 0.73530 val_loss= 1.34755 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  180.40476846694946\n",
      "edge_vol 8816.812\n",
      "Epoch: 0235 train_loss= 0.73049 val_loss= 1.34480 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  181.25307869911194\n",
      "edge_vol 8832.181\n",
      "Epoch: 0236 train_loss= 0.72626 val_loss= 1.34194 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  182.12872529029846\n",
      "edge_vol 8846.869\n",
      "Epoch: 0237 train_loss= 0.72174 val_loss= 1.33906 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  182.80598831176758\n",
      "edge_vol 8861.171\n",
      "Epoch: 0238 train_loss= 0.71959 val_loss= 1.33628 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  183.45053005218506\n",
      "edge_vol 8875.114\n",
      "Epoch: 0239 train_loss= 0.71638 val_loss= 1.33358 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  184.5103304386139\n",
      "edge_vol 8888.474\n",
      "Epoch: 0240 train_loss= 0.70967 val_loss= 1.33077 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  185.27610278129578\n",
      "edge_vol 8901.697\n",
      "Epoch: 0241 train_loss= 0.70670 val_loss= 1.32795 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  185.9576394557953\n",
      "edge_vol 8914.323\n",
      "Epoch: 0242 train_loss= 0.70232 val_loss= 1.32509 train_acc= 0.97500 val_acc= 0.70200 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  186.74586176872253\n",
      "edge_vol 8926.522\n",
      "Epoch: 0243 train_loss= 0.69994 val_loss= 1.32220 train_acc= 0.97500 val_acc= 0.70200 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  187.38181042671204\n",
      "edge_vol 8938.241\n",
      "Epoch: 0244 train_loss= 0.69502 val_loss= 1.31925 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  188.28139567375183\n",
      "edge_vol 8949.7705\n",
      "Epoch: 0245 train_loss= 0.69074 val_loss= 1.31632 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  188.98445391654968\n",
      "edge_vol 8961.088\n",
      "Epoch: 0246 train_loss= 0.68661 val_loss= 1.31349 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  189.63116312026978\n",
      "edge_vol 8972.004\n",
      "Epoch: 0247 train_loss= 0.68527 val_loss= 1.31083 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  190.3735420703888\n",
      "edge_vol 8982.564\n",
      "Epoch: 0248 train_loss= 0.67942 val_loss= 1.30824 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  191.22589302062988\n",
      "edge_vol 8993.031\n",
      "Epoch: 0249 train_loss= 0.67582 val_loss= 1.30555 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  191.97497391700745\n",
      "edge_vol 9003.206\n",
      "Epoch: 0250 train_loss= 0.67160 val_loss= 1.30291 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  192.6849205493927\n",
      "edge_vol 9012.87\n",
      "Epoch: 0251 train_loss= 0.66731 val_loss= 1.30036 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  193.6292963027954\n",
      "edge_vol 9022.158\n",
      "Epoch: 0252 train_loss= 0.66662 val_loss= 1.29784 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  194.31062769889832\n",
      "edge_vol 9031.042\n",
      "Epoch: 0253 train_loss= 0.66075 val_loss= 1.29521 train_acc= 0.97500 val_acc= 0.71000 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  195.08193469047546\n",
      "edge_vol 9039.8125\n",
      "Epoch: 0254 train_loss= 0.65624 val_loss= 1.29263 train_acc= 0.98333 val_acc= 0.71000 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  195.85647916793823\n",
      "edge_vol 9048.399\n",
      "Epoch: 0255 train_loss= 0.65599 val_loss= 1.29004 train_acc= 0.98333 val_acc= 0.71000 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  196.5961208343506\n",
      "edge_vol 9056.621\n",
      "Epoch: 0256 train_loss= 0.64859 val_loss= 1.28743 train_acc= 0.98333 val_acc= 0.71000 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  197.2926366329193\n",
      "edge_vol 9064.604\n",
      "Epoch: 0257 train_loss= 0.64590 val_loss= 1.28475 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  198.2662787437439\n",
      "edge_vol 9072.432\n",
      "Epoch: 0258 train_loss= 0.64190 val_loss= 1.28208 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  199.01920294761658\n",
      "edge_vol 9080.212\n",
      "Epoch: 0259 train_loss= 0.63846 val_loss= 1.27949 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  199.9679069519043\n",
      "edge_vol 9087.904\n",
      "Epoch: 0260 train_loss= 0.63528 val_loss= 1.27699 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  200.7389521598816\n",
      "edge_vol 9095.613\n",
      "Epoch: 0261 train_loss= 0.63135 val_loss= 1.27459 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  201.4904818534851\n",
      "edge_vol 9103.134\n",
      "Epoch: 0262 train_loss= 0.62903 val_loss= 1.27217 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  202.21460223197937\n",
      "edge_vol 9110.057\n",
      "Epoch: 0263 train_loss= 0.62374 val_loss= 1.26957 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  203.08530712127686\n",
      "edge_vol 9116.709\n",
      "Epoch: 0264 train_loss= 0.62019 val_loss= 1.26699 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  203.95302486419678\n",
      "edge_vol 9123.129\n",
      "Epoch: 0265 train_loss= 0.61922 val_loss= 1.26436 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  204.86048793792725\n",
      "edge_vol 9129.355\n",
      "Epoch: 0266 train_loss= 0.61502 val_loss= 1.26169 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  205.71485471725464\n",
      "edge_vol 9135.178\n",
      "Epoch: 0267 train_loss= 0.60910 val_loss= 1.25901 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  206.59517884254456\n",
      "edge_vol 9140.906\n",
      "Epoch: 0268 train_loss= 0.60955 val_loss= 1.25630 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  207.33444046974182\n",
      "edge_vol 9146.539\n",
      "Epoch: 0269 train_loss= 0.60277 val_loss= 1.25368 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  208.02158546447754\n",
      "edge_vol 9151.922\n",
      "Epoch: 0270 train_loss= 0.60172 val_loss= 1.25115 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  208.73101806640625\n",
      "edge_vol 9157.211\n",
      "Epoch: 0271 train_loss= 0.59794 val_loss= 1.24869 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71400 test_acc= 0.69600\n",
      "time  209.61752486228943\n",
      "edge_vol 9162.353\n",
      "Epoch: 0272 train_loss= 0.59628 val_loss= 1.24622 train_acc= 0.98333 val_acc= 0.71600 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  210.4667568206787\n",
      "edge_vol 9167.42\n",
      "Epoch: 0273 train_loss= 0.59140 val_loss= 1.24375 train_acc= 0.98333 val_acc= 0.71600 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  211.28161239624023\n",
      "edge_vol 9172.35\n",
      "Epoch: 0274 train_loss= 0.58994 val_loss= 1.24128 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  212.11903285980225\n",
      "edge_vol 9177.212\n",
      "Epoch: 0275 train_loss= 0.58689 val_loss= 1.23882 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  212.95836424827576\n",
      "edge_vol 9181.811\n",
      "Epoch: 0276 train_loss= 0.58371 val_loss= 1.23635 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  213.7675426006317\n",
      "edge_vol 9186.121\n",
      "Epoch: 0277 train_loss= 0.57993 val_loss= 1.23384 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  214.59444451332092\n",
      "edge_vol 9190.225\n",
      "Epoch: 0278 train_loss= 0.57553 val_loss= 1.23135 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  215.32403016090393\n",
      "edge_vol 9194.349\n",
      "Epoch: 0279 train_loss= 0.57401 val_loss= 1.22898 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  216.06033182144165\n",
      "edge_vol 9198.532\n",
      "Epoch: 0280 train_loss= 0.56905 val_loss= 1.22662 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  216.69644331932068\n",
      "edge_vol 9202.596\n",
      "Epoch: 0281 train_loss= 0.56869 val_loss= 1.22428 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  217.3313591480255\n",
      "edge_vol 9206.596\n",
      "Epoch: 0282 train_loss= 0.56532 val_loss= 1.22207 train_acc= 0.98333 val_acc= 0.71000 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  217.9554624557495\n",
      "edge_vol 9210.492\n",
      "Epoch: 0283 train_loss= 0.56155 val_loss= 1.21993 train_acc= 0.98333 val_acc= 0.71000 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  218.6157672405243\n",
      "edge_vol 9214.364\n",
      "Epoch: 0284 train_loss= 0.55819 val_loss= 1.21774 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  219.4125053882599\n",
      "edge_vol 9218.066\n",
      "Epoch: 0285 train_loss= 0.55569 val_loss= 1.21548 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  220.15109634399414\n",
      "edge_vol 9221.64\n",
      "Epoch: 0286 train_loss= 0.55305 val_loss= 1.21328 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  220.90780186653137\n",
      "edge_vol 9225.188\n",
      "Epoch: 0287 train_loss= 0.55128 val_loss= 1.21108 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  221.61463570594788\n",
      "edge_vol 9228.566\n",
      "Epoch: 0288 train_loss= 0.54686 val_loss= 1.20905 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  222.46482944488525\n",
      "edge_vol 9231.868\n",
      "Epoch: 0289 train_loss= 0.54532 val_loss= 1.20698 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  223.19850087165833\n",
      "edge_vol 9235.005\n",
      "Epoch: 0290 train_loss= 0.54371 val_loss= 1.20497 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  223.82358145713806\n",
      "edge_vol 9237.998\n",
      "Epoch: 0291 train_loss= 0.54143 val_loss= 1.20288 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  224.50345969200134\n",
      "edge_vol 9240.992\n",
      "Epoch: 0292 train_loss= 0.53769 val_loss= 1.20078 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  225.1677587032318\n",
      "edge_vol 9243.815\n",
      "Epoch: 0293 train_loss= 0.53583 val_loss= 1.19875 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  226.020845413208\n",
      "edge_vol 9246.65\n",
      "Epoch: 0294 train_loss= 0.53271 val_loss= 1.19685 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  226.87994813919067\n",
      "edge_vol 9249.556\n",
      "Epoch: 0295 train_loss= 0.53047 val_loss= 1.19485 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  227.56929230690002\n",
      "edge_vol 9252.244\n",
      "Epoch: 0296 train_loss= 0.52862 val_loss= 1.19299 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  228.2248077392578\n",
      "edge_vol 9254.991\n",
      "Epoch: 0297 train_loss= 0.52395 val_loss= 1.19131 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  229.08845496177673\n",
      "edge_vol 9257.555\n",
      "Epoch: 0298 train_loss= 0.52446 val_loss= 1.18953 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  229.84071898460388\n",
      "edge_vol 9259.801\n",
      "Epoch: 0299 train_loss= 0.52058 val_loss= 1.18767 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  230.59547758102417\n",
      "edge_vol 9261.818\n",
      "Epoch: 0300 train_loss= 0.51901 val_loss= 1.18584 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  231.2834508419037\n",
      "edge_vol 9263.506\n",
      "Epoch: 0301 train_loss= 0.51641 val_loss= 1.18398 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  232.01703763008118\n",
      "edge_vol 9264.837\n",
      "Epoch: 0302 train_loss= 0.51367 val_loss= 1.18216 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  232.7782838344574\n",
      "edge_vol 9265.848\n",
      "Epoch: 0303 train_loss= 0.51148 val_loss= 1.18040 train_acc= 0.98333 val_acc= 0.71000 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  233.5479428768158\n",
      "edge_vol 9266.598\n",
      "Epoch: 0304 train_loss= 0.50957 val_loss= 1.17861 train_acc= 0.98333 val_acc= 0.71000 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  234.23803758621216\n",
      "edge_vol 9267.119\n",
      "Epoch: 0305 train_loss= 0.50730 val_loss= 1.17676 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  235.0080497264862\n",
      "edge_vol 9267.459\n",
      "Epoch: 0306 train_loss= 0.50359 val_loss= 1.17477 train_acc= 0.98333 val_acc= 0.71000 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  235.84118390083313\n",
      "edge_vol 9267.675\n",
      "Epoch: 0307 train_loss= 0.50312 val_loss= 1.17289 train_acc= 0.98333 val_acc= 0.71000 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  236.58662819862366\n",
      "edge_vol 9267.814\n",
      "Epoch: 0308 train_loss= 0.50045 val_loss= 1.17114 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  237.37731385231018\n",
      "edge_vol 9267.893\n",
      "Epoch: 0309 train_loss= 0.49817 val_loss= 1.16947 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  238.22374725341797\n",
      "edge_vol 9267.932\n",
      "Epoch: 0310 train_loss= 0.49618 val_loss= 1.16775 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  238.93835425376892\n",
      "edge_vol 9267.954\n",
      "Epoch: 0311 train_loss= 0.49500 val_loss= 1.16604 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  239.60013937950134\n",
      "edge_vol 9267.967\n",
      "Epoch: 0312 train_loss= 0.49193 val_loss= 1.16433 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  240.3898413181305\n",
      "edge_vol 9267.976\n",
      "Epoch: 0313 train_loss= 0.49048 val_loss= 1.16264 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  241.11124682426453\n",
      "edge_vol 9267.981\n",
      "Epoch: 0314 train_loss= 0.48758 val_loss= 1.16096 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  241.8888454437256\n",
      "edge_vol 9267.986\n",
      "Epoch: 0315 train_loss= 0.48694 val_loss= 1.15934 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  242.64664244651794\n",
      "edge_vol 9267.99\n",
      "Epoch: 0316 train_loss= 0.48251 val_loss= 1.15771 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  243.3861608505249\n",
      "edge_vol 9267.994\n",
      "Epoch: 0317 train_loss= 0.48196 val_loss= 1.15599 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  244.1059639453888\n",
      "edge_vol 9267.996\n",
      "Epoch: 0318 train_loss= 0.48013 val_loss= 1.15427 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  244.82300448417664\n",
      "edge_vol 9267.998\n",
      "Epoch: 0319 train_loss= 0.47782 val_loss= 1.15254 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  245.7149407863617\n",
      "edge_vol 9268.0\n",
      "Epoch: 0320 train_loss= 0.47457 val_loss= 1.15091 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  246.51689434051514\n",
      "edge_vol 9268.0\n",
      "Epoch: 0321 train_loss= 0.47363 val_loss= 1.14931 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  247.37770080566406\n",
      "edge_vol 9268.0\n",
      "Epoch: 0322 train_loss= 0.47246 val_loss= 1.14785 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  248.19039726257324\n",
      "edge_vol 9268.0\n",
      "Epoch: 0323 train_loss= 0.47073 val_loss= 1.14640 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  248.81624293327332\n",
      "edge_vol 9268.0\n",
      "Epoch: 0324 train_loss= 0.46920 val_loss= 1.14500 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  249.73440861701965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zsp/ljx/PTDNet/models.py:14: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_vol 9268.0\n",
      "Epoch: 0325 train_loss= 0.46772 val_loss= 1.14369 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  250.66522645950317\n",
      "edge_vol 9268.0\n",
      "Epoch: 0326 train_loss= 0.46618 val_loss= 1.14243 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  251.54175186157227\n",
      "edge_vol 9268.0\n",
      "Epoch: 0327 train_loss= 0.46366 val_loss= 1.14110 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  252.39025378227234\n",
      "edge_vol 9268.0\n",
      "Epoch: 0328 train_loss= 0.46169 val_loss= 1.13987 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  253.1144242286682\n",
      "edge_vol 9268.0\n",
      "Epoch: 0329 train_loss= 0.46017 val_loss= 1.13860 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  253.8023030757904\n",
      "edge_vol 9268.0\n",
      "Epoch: 0330 train_loss= 0.45894 val_loss= 1.13738 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  254.48651695251465\n",
      "edge_vol 9268.0\n",
      "Epoch: 0331 train_loss= 0.45706 val_loss= 1.13616 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  255.2570309638977\n",
      "edge_vol 9268.0\n",
      "Epoch: 0332 train_loss= 0.45393 val_loss= 1.13497 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  256.0519468784332\n",
      "edge_vol 9268.0\n",
      "Epoch: 0333 train_loss= 0.45391 val_loss= 1.13381 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  256.82698011398315\n",
      "edge_vol 9268.0\n",
      "Epoch: 0334 train_loss= 0.45210 val_loss= 1.13260 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  257.55416226387024\n",
      "edge_vol 9268.0\n",
      "Epoch: 0335 train_loss= 0.45102 val_loss= 1.13136 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  258.1746401786804\n",
      "edge_vol 9268.0\n",
      "Epoch: 0336 train_loss= 0.44892 val_loss= 1.13008 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  258.872309923172\n",
      "edge_vol 9268.0\n",
      "Epoch: 0337 train_loss= 0.44719 val_loss= 1.12890 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  259.4908969402313\n",
      "edge_vol 9268.0\n",
      "Epoch: 0338 train_loss= 0.44540 val_loss= 1.12762 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  260.1390423774719\n",
      "edge_vol 9268.0\n",
      "Epoch: 0339 train_loss= 0.44431 val_loss= 1.12631 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  260.7926104068756\n",
      "edge_vol 9268.0\n",
      "Epoch: 0340 train_loss= 0.44241 val_loss= 1.12497 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  261.5816926956177\n",
      "edge_vol 9268.0\n",
      "Epoch: 0341 train_loss= 0.44187 val_loss= 1.12361 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  262.2869966030121\n",
      "edge_vol 9268.0\n",
      "Epoch: 0342 train_loss= 0.43921 val_loss= 1.12212 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  263.12861013412476\n",
      "edge_vol 9268.0\n",
      "Epoch: 0343 train_loss= 0.43809 val_loss= 1.12062 train_acc= 0.99167 val_acc= 0.71000 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  263.83714962005615\n",
      "edge_vol 9268.0\n",
      "Epoch: 0344 train_loss= 0.43698 val_loss= 1.11909 train_acc= 0.99167 val_acc= 0.71000 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  264.63280606269836\n",
      "edge_vol 9268.0\n",
      "Epoch: 0345 train_loss= 0.43482 val_loss= 1.11766 train_acc= 0.99167 val_acc= 0.71000 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  265.3231432437897\n",
      "edge_vol 9268.0\n",
      "Epoch: 0346 train_loss= 0.43279 val_loss= 1.11624 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  266.00006222724915\n",
      "edge_vol 9268.0\n",
      "Epoch: 0347 train_loss= 0.43214 val_loss= 1.11486 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  266.99935030937195\n",
      "edge_vol 9268.0\n",
      "Epoch: 0348 train_loss= 0.43002 val_loss= 1.11359 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  267.6332607269287\n",
      "edge_vol 9268.0\n",
      "Epoch: 0349 train_loss= 0.42853 val_loss= 1.11227 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  268.50600957870483\n",
      "edge_vol 9268.0\n",
      "Epoch: 0350 train_loss= 0.42683 val_loss= 1.11097 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  269.2027499675751\n",
      "edge_vol 9268.0\n",
      "Epoch: 0351 train_loss= 0.42502 val_loss= 1.10972 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  270.00142002105713\n",
      "edge_vol 9268.0\n",
      "Epoch: 0352 train_loss= 0.42396 val_loss= 1.10849 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  270.7707939147949\n",
      "edge_vol 9268.0\n",
      "Epoch: 0353 train_loss= 0.42256 val_loss= 1.10723 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  271.6393668651581\n",
      "edge_vol 9268.0\n",
      "Epoch: 0354 train_loss= 0.42101 val_loss= 1.10596 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  272.51056599617004\n",
      "edge_vol 9268.0\n",
      "Epoch: 0355 train_loss= 0.41947 val_loss= 1.10470 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  273.26199197769165\n",
      "edge_vol 9268.0\n",
      "Epoch: 0356 train_loss= 0.41855 val_loss= 1.10355 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  274.1553053855896\n",
      "edge_vol 9268.0\n",
      "Epoch: 0357 train_loss= 0.41584 val_loss= 1.10245 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  274.9945979118347\n",
      "edge_vol 9268.0\n",
      "Epoch: 0358 train_loss= 0.41466 val_loss= 1.10129 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  275.6938648223877\n",
      "edge_vol 9268.0\n",
      "Epoch: 0359 train_loss= 0.41441 val_loss= 1.10026 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71600 test_acc= 0.71000\n",
      "time  276.5906994342804\n",
      "edge_vol 9268.0\n",
      "Epoch: 0360 train_loss= 0.41160 val_loss= 1.09927 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  277.33914256095886\n",
      "edge_vol 9268.0\n",
      "Epoch: 0361 train_loss= 0.41115 val_loss= 1.09836 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  278.1092188358307\n",
      "edge_vol 9268.0\n",
      "Epoch: 0362 train_loss= 0.41026 val_loss= 1.09746 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  278.9048402309418\n",
      "edge_vol 9268.0\n",
      "Epoch: 0363 train_loss= 0.40875 val_loss= 1.09662 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  279.6192841529846\n",
      "edge_vol 9268.0\n",
      "Epoch: 0364 train_loss= 0.40746 val_loss= 1.09576 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  280.3569984436035\n",
      "edge_vol 9268.0\n",
      "Epoch: 0365 train_loss= 0.40596 val_loss= 1.09488 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  281.2104563713074\n",
      "edge_vol 9268.0\n",
      "Epoch: 0366 train_loss= 0.40516 val_loss= 1.09411 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  281.8523712158203\n",
      "edge_vol 9268.0\n",
      "Epoch: 0367 train_loss= 0.40399 val_loss= 1.09333 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  282.52354741096497\n",
      "edge_vol 9268.0\n",
      "Epoch: 0368 train_loss= 0.40462 val_loss= 1.09258 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  283.3099830150604\n",
      "edge_vol 9268.0\n",
      "Epoch: 0369 train_loss= 0.40264 val_loss= 1.09186 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  284.1373302936554\n",
      "edge_vol 9268.0\n",
      "Epoch: 0370 train_loss= 0.40163 val_loss= 1.09113 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  284.83959317207336\n",
      "edge_vol 9268.0\n",
      "Epoch: 0371 train_loss= 0.40107 val_loss= 1.09042 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  285.61627650260925\n",
      "edge_vol 9268.0\n",
      "Epoch: 0372 train_loss= 0.39960 val_loss= 1.08968 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  286.40512561798096\n",
      "edge_vol 9268.0\n",
      "Epoch: 0373 train_loss= 0.39898 val_loss= 1.08885 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  287.11982703208923\n",
      "edge_vol 9268.0\n",
      "Epoch: 0374 train_loss= 0.39773 val_loss= 1.08801 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  287.8646569252014\n",
      "edge_vol 9268.0\n",
      "Epoch: 0375 train_loss= 0.39621 val_loss= 1.08711 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  288.6729781627655\n",
      "edge_vol 9268.0\n",
      "Epoch: 0376 train_loss= 0.39555 val_loss= 1.08624 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  289.39371395111084\n",
      "edge_vol 9268.0\n",
      "Epoch: 0377 train_loss= 0.39395 val_loss= 1.08550 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  290.1628665924072\n",
      "edge_vol 9268.0\n",
      "Epoch: 0378 train_loss= 0.39318 val_loss= 1.08477 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  290.9297204017639\n",
      "edge_vol 9268.0\n",
      "Epoch: 0379 train_loss= 0.39213 val_loss= 1.08398 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  291.6062080860138\n",
      "edge_vol 9268.0\n",
      "Epoch: 0380 train_loss= 0.39133 val_loss= 1.08324 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  292.40570998191833\n",
      "edge_vol 9268.0\n",
      "Epoch: 0381 train_loss= 0.38997 val_loss= 1.08248 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  293.25944423675537\n",
      "edge_vol 9268.0\n",
      "Epoch: 0382 train_loss= 0.38914 val_loss= 1.08173 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  294.0141804218292\n",
      "edge_vol 9268.0\n",
      "Epoch: 0383 train_loss= 0.38804 val_loss= 1.08105 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  294.7214548587799\n",
      "edge_vol 9268.0\n",
      "Epoch: 0384 train_loss= 0.38680 val_loss= 1.08028 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  295.35760283470154\n",
      "edge_vol 9268.0\n",
      "Epoch: 0385 train_loss= 0.38545 val_loss= 1.07953 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  295.99900579452515\n",
      "edge_vol 9268.0\n",
      "Epoch: 0386 train_loss= 0.38365 val_loss= 1.07883 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  296.6671943664551\n",
      "edge_vol 9268.0\n",
      "Epoch: 0387 train_loss= 0.38312 val_loss= 1.07812 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  297.4066483974457\n",
      "edge_vol 9268.0\n",
      "Epoch: 0388 train_loss= 0.38291 val_loss= 1.07731 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  298.17652797698975\n",
      "edge_vol 9268.0\n",
      "Epoch: 0389 train_loss= 0.38095 val_loss= 1.07654 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  298.97946548461914\n",
      "edge_vol 9268.0\n",
      "Epoch: 0390 train_loss= 0.38123 val_loss= 1.07579 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  299.74669456481934\n",
      "edge_vol 9268.0\n",
      "Epoch: 0391 train_loss= 0.37898 val_loss= 1.07502 train_acc= 0.99167 val_acc= 0.70800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  300.4418692588806\n",
      "edge_vol 9268.0\n",
      "Epoch: 0392 train_loss= 0.37848 val_loss= 1.07429 train_acc= 0.99167 val_acc= 0.70800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  301.1747372150421\n",
      "edge_vol 9268.0\n",
      "Epoch: 0393 train_loss= 0.37721 val_loss= 1.07352 train_acc= 0.99167 val_acc= 0.70800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  301.8197240829468\n",
      "edge_vol 9268.0\n",
      "Epoch: 0394 train_loss= 0.37595 val_loss= 1.07279 train_acc= 0.99167 val_acc= 0.70800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  302.6283345222473\n",
      "edge_vol 9268.0\n",
      "Epoch: 0395 train_loss= 0.37529 val_loss= 1.07206 train_acc= 0.99167 val_acc= 0.70800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  303.35009145736694\n",
      "edge_vol 9268.0\n",
      "Epoch: 0396 train_loss= 0.37408 val_loss= 1.07132 train_acc= 0.99167 val_acc= 0.70800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  304.06273317337036\n",
      "edge_vol 9268.0\n",
      "Epoch: 0397 train_loss= 0.37300 val_loss= 1.07056 train_acc= 0.99167 val_acc= 0.70800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  304.7622621059418\n",
      "edge_vol 9268.0\n",
      "Epoch: 0398 train_loss= 0.37217 val_loss= 1.06977 train_acc= 0.99167 val_acc= 0.70800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  305.58948802948\n",
      "edge_vol 9268.0\n",
      "Epoch: 0399 train_loss= 0.37112 val_loss= 1.06893 train_acc= 0.99167 val_acc= 0.70800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  306.2865128517151\n",
      "edge_vol 9268.0\n",
      "Epoch: 0400 train_loss= 0.37076 val_loss= 1.06812 train_acc= 0.99167 val_acc= 0.71000 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  306.96417570114136\n",
      "edge_vol 9268.0\n",
      "Epoch: 0401 train_loss= 0.36941 val_loss= 1.06736 train_acc= 0.99167 val_acc= 0.71000 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  307.67247009277344\n",
      "edge_vol 9268.0\n",
      "Epoch: 0402 train_loss= 0.36876 val_loss= 1.06655 train_acc= 0.99167 val_acc= 0.71000 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  308.46884202957153\n",
      "edge_vol 9268.0\n",
      "Epoch: 0403 train_loss= 0.36709 val_loss= 1.06580 train_acc= 0.99167 val_acc= 0.71000 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  309.15787267684937\n",
      "edge_vol 9268.0\n",
      "Epoch: 0404 train_loss= 0.36629 val_loss= 1.06510 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  310.1621642112732\n",
      "edge_vol 9268.0\n",
      "Epoch: 0405 train_loss= 0.36532 val_loss= 1.06438 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  311.08077335357666\n",
      "edge_vol 9268.0\n",
      "Epoch: 0406 train_loss= 0.36429 val_loss= 1.06369 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  311.76080989837646\n",
      "edge_vol 9268.0\n",
      "Epoch: 0407 train_loss= 0.36352 val_loss= 1.06305 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  312.60864067077637\n",
      "edge_vol 9268.0\n",
      "Epoch: 0408 train_loss= 0.36248 val_loss= 1.06238 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  313.43584394454956\n",
      "edge_vol 9268.0\n",
      "Epoch: 0409 train_loss= 0.36195 val_loss= 1.06168 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  314.1829471588135\n",
      "edge_vol 9268.0\n",
      "Epoch: 0410 train_loss= 0.36078 val_loss= 1.06091 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  314.84164357185364\n",
      "edge_vol 9268.0\n",
      "Epoch: 0411 train_loss= 0.36017 val_loss= 1.06014 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  315.5095467567444\n",
      "edge_vol 9268.0\n",
      "Epoch: 0412 train_loss= 0.35876 val_loss= 1.05944 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  316.3831593990326\n",
      "edge_vol 9268.0\n",
      "Epoch: 0413 train_loss= 0.35823 val_loss= 1.05884 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  317.12287068367004\n",
      "edge_vol 9268.0\n",
      "Epoch: 0414 train_loss= 0.35728 val_loss= 1.05828 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  317.86626148223877\n",
      "edge_vol 9268.0\n",
      "Epoch: 0415 train_loss= 0.35736 val_loss= 1.05777 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  318.76901412010193\n",
      "edge_vol 9268.0\n",
      "Epoch: 0416 train_loss= 0.35622 val_loss= 1.05732 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  319.56405377388\n",
      "edge_vol 9268.0\n",
      "Epoch: 0417 train_loss= 0.35549 val_loss= 1.05682 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  320.2935457229614\n",
      "edge_vol 9268.0\n",
      "Epoch: 0418 train_loss= 0.35543 val_loss= 1.05629 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  321.04702258110046\n",
      "edge_vol 9268.0\n",
      "Epoch: 0419 train_loss= 0.35339 val_loss= 1.05569 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  321.8814277648926\n",
      "edge_vol 9268.0\n",
      "Epoch: 0420 train_loss= 0.35327 val_loss= 1.05514 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  322.6814787387848\n",
      "edge_vol 9268.0\n",
      "Epoch: 0421 train_loss= 0.35249 val_loss= 1.05471 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  323.4454185962677\n",
      "edge_vol 9268.0\n",
      "Epoch: 0422 train_loss= 0.35185 val_loss= 1.05426 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  324.0993502140045\n",
      "edge_vol 9268.0\n",
      "Epoch: 0423 train_loss= 0.35131 val_loss= 1.05387 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  324.7635848522186\n",
      "edge_vol 9268.0\n",
      "Epoch: 0424 train_loss= 0.35059 val_loss= 1.05346 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  325.55293917655945\n",
      "edge_vol 9268.0\n",
      "Epoch: 0425 train_loss= 0.34983 val_loss= 1.05304 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  326.3114445209503\n",
      "edge_vol 9268.0\n",
      "Epoch: 0426 train_loss= 0.34956 val_loss= 1.05250 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  326.9669532775879\n",
      "edge_vol 9268.0\n",
      "Epoch: 0427 train_loss= 0.34840 val_loss= 1.05204 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  327.7540512084961\n",
      "edge_vol 9268.0\n",
      "Epoch: 0428 train_loss= 0.34768 val_loss= 1.05156 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  328.5026412010193\n",
      "edge_vol 9268.0\n",
      "Epoch: 0429 train_loss= 0.34664 val_loss= 1.05095 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  329.35436272621155\n",
      "edge_vol 9268.0\n",
      "Epoch: 0430 train_loss= 0.34622 val_loss= 1.05027 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  330.1386077404022\n",
      "edge_vol 9268.0\n",
      "Epoch: 0431 train_loss= 0.34576 val_loss= 1.04961 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  330.97755694389343\n",
      "edge_vol 9268.0\n",
      "Epoch: 0432 train_loss= 0.34491 val_loss= 1.04889 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  331.59343457221985\n",
      "edge_vol 9268.0\n",
      "Epoch: 0433 train_loss= 0.34402 val_loss= 1.04823 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  332.3098158836365\n",
      "edge_vol 9268.0\n",
      "Epoch: 0434 train_loss= 0.34388 val_loss= 1.04761 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  333.1811773777008\n",
      "edge_vol 9268.0\n",
      "Epoch: 0435 train_loss= 0.34256 val_loss= 1.04706 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  334.0856761932373\n",
      "edge_vol 9268.0\n",
      "Epoch: 0436 train_loss= 0.34182 val_loss= 1.04647 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  334.82609939575195\n",
      "edge_vol 9268.0\n",
      "Epoch: 0437 train_loss= 0.34104 val_loss= 1.04586 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  335.5382580757141\n",
      "edge_vol 9268.0\n",
      "Epoch: 0438 train_loss= 0.34040 val_loss= 1.04527 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  336.3390645980835\n",
      "edge_vol 9268.0\n",
      "Epoch: 0439 train_loss= 0.33983 val_loss= 1.04470 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  337.1494297981262\n",
      "edge_vol 9268.0\n",
      "Epoch: 0440 train_loss= 0.33889 val_loss= 1.04415 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  337.82154512405396\n",
      "edge_vol 9268.0\n",
      "Epoch: 0441 train_loss= 0.33786 val_loss= 1.04360 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  338.53423500061035\n",
      "edge_vol 9268.0\n",
      "Epoch: 0442 train_loss= 0.33800 val_loss= 1.04306 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  339.3424446582794\n",
      "edge_vol 9268.0\n",
      "Epoch: 0443 train_loss= 0.33750 val_loss= 1.04248 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  340.05290246009827\n",
      "edge_vol 9268.0\n",
      "Epoch: 0444 train_loss= 0.33736 val_loss= 1.04187 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  340.7065694332123\n",
      "edge_vol 9268.0\n",
      "Epoch: 0445 train_loss= 0.33641 val_loss= 1.04130 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  341.3635640144348\n",
      "edge_vol 9268.0\n",
      "Epoch: 0446 train_loss= 0.33553 val_loss= 1.04074 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  342.19627833366394\n",
      "edge_vol 9268.0\n",
      "Epoch: 0447 train_loss= 0.33436 val_loss= 1.04022 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  342.98940563201904\n",
      "edge_vol 9268.0\n",
      "Epoch: 0448 train_loss= 0.33385 val_loss= 1.03979 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  343.6915850639343\n",
      "edge_vol 9268.0\n",
      "Epoch: 0449 train_loss= 0.33325 val_loss= 1.03932 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  344.75429344177246\n",
      "edge_vol 9268.0\n",
      "Epoch: 0450 train_loss= 0.33273 val_loss= 1.03893 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  345.43258261680603\n",
      "edge_vol 9268.0\n",
      "Epoch: 0451 train_loss= 0.33285 val_loss= 1.03858 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  346.1888885498047\n",
      "edge_vol 9268.0\n",
      "Epoch: 0452 train_loss= 0.33163 val_loss= 1.03816 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  346.84999799728394\n",
      "edge_vol 9268.0\n",
      "Epoch: 0453 train_loss= 0.33125 val_loss= 1.03764 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  347.606591463089\n",
      "edge_vol 9268.0\n",
      "Epoch: 0454 train_loss= 0.33055 val_loss= 1.03706 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  348.4946451187134\n",
      "edge_vol 9268.0\n",
      "Epoch: 0455 train_loss= 0.32995 val_loss= 1.03647 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  349.2810161113739\n",
      "edge_vol 9268.0\n",
      "Epoch: 0456 train_loss= 0.32899 val_loss= 1.03589 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  350.09194707870483\n",
      "edge_vol 9268.0\n",
      "Epoch: 0457 train_loss= 0.32879 val_loss= 1.03523 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  350.86105608940125\n",
      "edge_vol 9268.0\n",
      "Epoch: 0458 train_loss= 0.32852 val_loss= 1.03463 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  351.61434626579285\n",
      "edge_vol 9268.0\n",
      "Epoch: 0459 train_loss= 0.32788 val_loss= 1.03411 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  352.4370379447937\n",
      "edge_vol 9268.0\n",
      "Epoch: 0460 train_loss= 0.32734 val_loss= 1.03373 train_acc= 0.99167 val_acc= 0.71000 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "time  353.1789309978485\n",
      "edge_vol 9268.0\n",
      "Epoch: 0461 train_loss= 0.32694 val_loss= 1.03334 train_acc= 0.99167 val_acc= 0.71000 best_val_acc_trail= 0.71800 test_acc= 0.70900\n",
      "Early stopping...\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "from utils import *\n",
    "from models import GCN, PTDNetGCN\n",
    "from metrics import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "# Settings\n",
    "args.dataset=dataset_name\n",
    "\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(args.dataset)\n",
    "adj=modified_adj\n",
    "all_labels = y_train + y_test+y_val\n",
    "single_label = np.argmax(all_labels,axis=-1)\n",
    "\n",
    "nodesize = features.shape[0]\n",
    "\n",
    "# Some preprocessing\n",
    "features = preprocess_features(features)\n",
    "support = preprocess_adj(adj)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "\n",
    "tuple_adj = sparse_to_tuple(adj.tocoo())\n",
    "features_tensor = tf.convert_to_tensor(features,dtype=dtype)\n",
    "adj_tensor = tf.SparseTensor(*tuple_adj)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train,dtype=dtype)\n",
    "train_mask_tensor = tf.convert_to_tensor(train_mask)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test,dtype=dtype)\n",
    "test_mask_tensor = tf.convert_to_tensor(test_mask)\n",
    "y_val_tensor = tf.convert_to_tensor(y_val,dtype=dtype)\n",
    "val_mask_tensor = tf.convert_to_tensor(val_mask)\n",
    "\n",
    "\n",
    "\n",
    "best_test_acc = 0\n",
    "best_val_acc_trail = 0\n",
    "best_val_loss = 10000\n",
    "import time\n",
    "begin = time.time()\n",
    "\n",
    "model = PTDNetGCN(input_dim=features.shape[1], output_dim=y_train.shape[1])\n",
    "model.set_fea_adj(np.array(range(adj.shape[0])), features_tensor, adj_tensor)\n",
    "\n",
    "best_epoch = 0\n",
    "curr_step = 0\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    temperature = max(0.05,args.init_temperature * pow(args.temperature_decay, epoch))\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = []\n",
    "        for l in range(args.outL):\n",
    "            output = model.call(temperature,training=True)\n",
    "            preds.append(tf.expand_dims(output,0))\n",
    "        all_preds = tf.concat(preds,axis=0)\n",
    "        mean_preds = tf.reduce_mean(preds,axis=0)\n",
    "        consistency_loss = tf.nn.l2_loss(mean_preds-all_preds)\n",
    "\n",
    "        cross_loss = masked_softmax_cross_entropy(mean_preds, y_train_tensor,train_mask_tensor)\n",
    "        lossL2 = tf.add_n([tf.nn.l2_loss(v) for v in model.trainable_variables])\n",
    "        lossl0 = model.lossl0(temperature)\n",
    "        nuclear = model.my_nuclear()\n",
    "        #nuclear = model.nuclear()\n",
    "        loss = cross_loss + args.weight_decay*lossL2 + args.lambda1*lossl0 + args.lambda3*nuclear + args.coff_consis*consistency_loss\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    output = model.call(None, training=False)\n",
    "    edges_volumn = tf.reduce_sum(model.maskes[0])\n",
    "    print('edge_vol',edges_volumn.numpy())\n",
    "\n",
    "    train_acc = masked_accuracy(output, y_train_tensor,train_mask_tensor)\n",
    "    val_acc  = masked_accuracy(output, y_val_tensor,val_mask_tensor)\n",
    "    val_loss = masked_softmax_cross_entropy(output, y_val_tensor, val_mask_tensor)\n",
    "    test_acc  = masked_accuracy(output, y_test_tensor,test_mask_tensor)\n",
    "    if val_acc > best_val_acc:\n",
    "        curr_step = 0\n",
    "        best_epoch = epoch\n",
    "        best_val_acc = val_acc\n",
    "        best_val_loss= val_loss\n",
    "        if val_acc>best_val_acc_trail:\n",
    "            best_test_acc = test_acc\n",
    "            best_val_acc_trail = val_acc\n",
    "    else:\n",
    "        curr_step +=1\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cross_loss),\"val_loss=\", \"{:.5f}\".format(val_loss),\n",
    "      \"train_acc=\", \"{:.5f}\".format(train_acc), \"val_acc=\", \"{:.5f}\".format(val_acc),\"best_val_acc_trail=\", \"{:.5f}\".format(best_val_acc_trail),\n",
    "      \"test_acc=\", \"{:.5f}\".format(best_test_acc))\n",
    "\n",
    "    if curr_step > args.early_stop:\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "    end = time.time()\n",
    "    print('time ',(end-begin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.79135 val_loss= 1.79116 train_acc= 0.19800 val_acc= 0.19800 test_acc= 0.22600\n",
      "Epoch: 0002 train_loss= 1.78920 val_loss= 1.79046 train_acc= 0.33000 val_acc= 0.33000 test_acc= 0.35700\n",
      "Epoch: 0003 train_loss= 1.78704 val_loss= 1.78973 train_acc= 0.44600 val_acc= 0.44600 test_acc= 0.46900\n",
      "Epoch: 0004 train_loss= 1.78487 val_loss= 1.78897 train_acc= 0.51200 val_acc= 0.51200 test_acc= 0.53500\n",
      "Epoch: 0005 train_loss= 1.78265 val_loss= 1.78815 train_acc= 0.56000 val_acc= 0.56000 test_acc= 0.56900\n",
      "Epoch: 0006 train_loss= 1.78035 val_loss= 1.78726 train_acc= 0.60200 val_acc= 0.60200 test_acc= 0.59800\n",
      "Epoch: 0007 train_loss= 1.77793 val_loss= 1.78630 train_acc= 0.62400 val_acc= 0.62400 test_acc= 0.61500\n",
      "Epoch: 0008 train_loss= 1.77536 val_loss= 1.78526 train_acc= 0.64400 val_acc= 0.64400 test_acc= 0.63000\n",
      "Epoch: 0009 train_loss= 1.77264 val_loss= 1.78413 train_acc= 0.65600 val_acc= 0.65600 test_acc= 0.64100\n",
      "Epoch: 0010 train_loss= 1.76974 val_loss= 1.78292 train_acc= 0.66000 val_acc= 0.66000 test_acc= 0.64400\n",
      "Epoch: 0011 train_loss= 1.76666 val_loss= 1.78164 train_acc= 0.66800 val_acc= 0.66800 test_acc= 0.65300\n",
      "Epoch: 0012 train_loss= 1.76342 val_loss= 1.78028 train_acc= 0.67000 val_acc= 0.67000 test_acc= 0.65400\n",
      "Epoch: 0013 train_loss= 1.76002 val_loss= 1.77886 train_acc= 0.68000 val_acc= 0.68000 test_acc= 0.65600\n",
      "Epoch: 0014 train_loss= 1.75643 val_loss= 1.77736 train_acc= 0.68000 val_acc= 0.68000 test_acc= 0.65600\n",
      "Epoch: 0015 train_loss= 1.75267 val_loss= 1.77580 train_acc= 0.68200 val_acc= 0.68200 test_acc= 0.66500\n",
      "Epoch: 0016 train_loss= 1.74873 val_loss= 1.77419 train_acc= 0.68600 val_acc= 0.68600 test_acc= 0.66700\n",
      "Epoch: 0017 train_loss= 1.74462 val_loss= 1.77251 train_acc= 0.68200 val_acc= 0.68200 test_acc= 0.66700\n",
      "Epoch: 0018 train_loss= 1.74036 val_loss= 1.77077 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0019 train_loss= 1.73595 val_loss= 1.76898 train_acc= 0.67600 val_acc= 0.67600 test_acc= 0.66700\n",
      "Epoch: 0020 train_loss= 1.73137 val_loss= 1.76714 train_acc= 0.68000 val_acc= 0.68000 test_acc= 0.66700\n",
      "Epoch: 0021 train_loss= 1.72664 val_loss= 1.76525 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0022 train_loss= 1.72178 val_loss= 1.76332 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0023 train_loss= 1.71677 val_loss= 1.76135 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0024 train_loss= 1.71164 val_loss= 1.75933 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0025 train_loss= 1.70639 val_loss= 1.75727 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0026 train_loss= 1.70102 val_loss= 1.75518 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0027 train_loss= 1.69552 val_loss= 1.75304 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0028 train_loss= 1.68992 val_loss= 1.75087 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0029 train_loss= 1.68420 val_loss= 1.74867 train_acc= 0.68000 val_acc= 0.68000 test_acc= 0.66700\n",
      "Epoch: 0030 train_loss= 1.67838 val_loss= 1.74642 train_acc= 0.68000 val_acc= 0.68000 test_acc= 0.66700\n",
      "Epoch: 0031 train_loss= 1.67245 val_loss= 1.74414 train_acc= 0.68000 val_acc= 0.68000 test_acc= 0.66700\n",
      "Epoch: 0032 train_loss= 1.66642 val_loss= 1.74182 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0033 train_loss= 1.66029 val_loss= 1.73946 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0034 train_loss= 1.65407 val_loss= 1.73706 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0035 train_loss= 1.64774 val_loss= 1.73461 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0036 train_loss= 1.64132 val_loss= 1.73213 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0037 train_loss= 1.63481 val_loss= 1.72961 train_acc= 0.68000 val_acc= 0.68000 test_acc= 0.66700\n",
      "Epoch: 0038 train_loss= 1.62821 val_loss= 1.72705 train_acc= 0.68000 val_acc= 0.68000 test_acc= 0.66700\n",
      "Epoch: 0039 train_loss= 1.62151 val_loss= 1.72445 train_acc= 0.68000 val_acc= 0.68000 test_acc= 0.66700\n",
      "Epoch: 0040 train_loss= 1.61473 val_loss= 1.72180 train_acc= 0.68000 val_acc= 0.68000 test_acc= 0.66700\n",
      "Epoch: 0041 train_loss= 1.60786 val_loss= 1.71911 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0042 train_loss= 1.60091 val_loss= 1.71639 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0043 train_loss= 1.59387 val_loss= 1.71362 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0044 train_loss= 1.58675 val_loss= 1.71082 train_acc= 0.67600 val_acc= 0.67600 test_acc= 0.66700\n",
      "Epoch: 0045 train_loss= 1.57955 val_loss= 1.70798 train_acc= 0.67600 val_acc= 0.67600 test_acc= 0.66700\n",
      "Epoch: 0046 train_loss= 1.57227 val_loss= 1.70509 train_acc= 0.67600 val_acc= 0.67600 test_acc= 0.66700\n",
      "Epoch: 0047 train_loss= 1.56491 val_loss= 1.70217 train_acc= 0.67600 val_acc= 0.67600 test_acc= 0.66700\n",
      "Epoch: 0048 train_loss= 1.55747 val_loss= 1.69920 train_acc= 0.67600 val_acc= 0.67600 test_acc= 0.66700\n",
      "Epoch: 0049 train_loss= 1.54995 val_loss= 1.69620 train_acc= 0.67600 val_acc= 0.67600 test_acc= 0.66700\n",
      "Epoch: 0050 train_loss= 1.54237 val_loss= 1.69315 train_acc= 0.67600 val_acc= 0.67600 test_acc= 0.66700\n",
      "Epoch: 0051 train_loss= 1.53470 val_loss= 1.69007 train_acc= 0.67600 val_acc= 0.67600 test_acc= 0.66700\n",
      "Epoch: 0052 train_loss= 1.52697 val_loss= 1.68694 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.66700\n",
      "Epoch: 0053 train_loss= 1.51916 val_loss= 1.68378 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.66700\n",
      "Epoch: 0054 train_loss= 1.51130 val_loss= 1.68057 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.66700\n",
      "Epoch: 0055 train_loss= 1.50336 val_loss= 1.67734 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.66700\n",
      "Epoch: 0056 train_loss= 1.49536 val_loss= 1.67407 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.66700\n",
      "Epoch: 0057 train_loss= 1.48729 val_loss= 1.67076 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.66700\n",
      "Epoch: 0058 train_loss= 1.47917 val_loss= 1.66742 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.66700\n",
      "Epoch: 0059 train_loss= 1.47099 val_loss= 1.66403 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.66700\n",
      "Epoch: 0060 train_loss= 1.46275 val_loss= 1.66061 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.66700\n",
      "Epoch: 0061 train_loss= 1.45447 val_loss= 1.65716 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.66700\n",
      "Epoch: 0062 train_loss= 1.44612 val_loss= 1.65369 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.66700\n",
      "Epoch: 0063 train_loss= 1.43774 val_loss= 1.65018 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.66700\n",
      "Epoch: 0064 train_loss= 1.42931 val_loss= 1.64663 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.66700\n",
      "Epoch: 0065 train_loss= 1.42084 val_loss= 1.64306 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.66700\n",
      "Epoch: 0066 train_loss= 1.41231 val_loss= 1.63945 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.66700\n",
      "Epoch: 0067 train_loss= 1.40377 val_loss= 1.63581 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.66700\n",
      "Epoch: 0068 train_loss= 1.39518 val_loss= 1.63214 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.66700\n",
      "Epoch: 0069 train_loss= 1.38657 val_loss= 1.62846 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0070 train_loss= 1.37792 val_loss= 1.62475 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0071 train_loss= 1.36925 val_loss= 1.62101 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0072 train_loss= 1.36056 val_loss= 1.61725 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.66700\n",
      "Epoch: 0073 train_loss= 1.35185 val_loss= 1.61348 train_acc= 0.68000 val_acc= 0.68000 test_acc= 0.66700\n",
      "Epoch: 0074 train_loss= 1.34313 val_loss= 1.60967 train_acc= 0.68000 val_acc= 0.68000 test_acc= 0.66700\n",
      "Epoch: 0075 train_loss= 1.33439 val_loss= 1.60585 train_acc= 0.68000 val_acc= 0.68000 test_acc= 0.66700\n",
      "Epoch: 0076 train_loss= 1.32565 val_loss= 1.60202 train_acc= 0.68200 val_acc= 0.68200 test_acc= 0.66700\n",
      "Epoch: 0077 train_loss= 1.31689 val_loss= 1.59816 train_acc= 0.68200 val_acc= 0.68200 test_acc= 0.66700\n",
      "Epoch: 0078 train_loss= 1.30813 val_loss= 1.59428 train_acc= 0.68200 val_acc= 0.68200 test_acc= 0.66700\n",
      "Epoch: 0079 train_loss= 1.29937 val_loss= 1.59039 train_acc= 0.68200 val_acc= 0.68200 test_acc= 0.66700\n",
      "Epoch: 0080 train_loss= 1.29063 val_loss= 1.58648 train_acc= 0.68200 val_acc= 0.68200 test_acc= 0.66700\n",
      "Epoch: 0081 train_loss= 1.28187 val_loss= 1.58256 train_acc= 0.68400 val_acc= 0.68400 test_acc= 0.66700\n",
      "Epoch: 0082 train_loss= 1.27314 val_loss= 1.57865 train_acc= 0.68400 val_acc= 0.68400 test_acc= 0.66700\n",
      "Epoch: 0083 train_loss= 1.26442 val_loss= 1.57471 train_acc= 0.68400 val_acc= 0.68400 test_acc= 0.66700\n",
      "Epoch: 0084 train_loss= 1.25571 val_loss= 1.57076 train_acc= 0.68400 val_acc= 0.68400 test_acc= 0.66700\n",
      "Epoch: 0085 train_loss= 1.24702 val_loss= 1.56682 train_acc= 0.68400 val_acc= 0.68400 test_acc= 0.66700\n",
      "Epoch: 0086 train_loss= 1.23836 val_loss= 1.56286 train_acc= 0.68400 val_acc= 0.68400 test_acc= 0.66700\n",
      "Epoch: 0087 train_loss= 1.22971 val_loss= 1.55890 train_acc= 0.68600 val_acc= 0.68600 test_acc= 0.67000\n",
      "Epoch: 0088 train_loss= 1.22109 val_loss= 1.55492 train_acc= 0.68800 val_acc= 0.68800 test_acc= 0.67000\n",
      "Epoch: 0089 train_loss= 1.21250 val_loss= 1.55095 train_acc= 0.68800 val_acc= 0.68800 test_acc= 0.67000\n",
      "Epoch: 0090 train_loss= 1.20395 val_loss= 1.54698 train_acc= 0.68800 val_acc= 0.68800 test_acc= 0.67000\n",
      "Epoch: 0091 train_loss= 1.19543 val_loss= 1.54301 train_acc= 0.68800 val_acc= 0.68800 test_acc= 0.67000\n",
      "Epoch: 0092 train_loss= 1.18695 val_loss= 1.53903 train_acc= 0.68800 val_acc= 0.68800 test_acc= 0.67000\n",
      "Epoch: 0093 train_loss= 1.17851 val_loss= 1.53507 train_acc= 0.68800 val_acc= 0.68800 test_acc= 0.67000\n",
      "Epoch: 0094 train_loss= 1.17012 val_loss= 1.53111 train_acc= 0.68800 val_acc= 0.68800 test_acc= 0.67000\n",
      "Epoch: 0095 train_loss= 1.16176 val_loss= 1.52715 train_acc= 0.68800 val_acc= 0.68800 test_acc= 0.67000\n",
      "Epoch: 0096 train_loss= 1.15346 val_loss= 1.52321 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.67100\n",
      "Epoch: 0097 train_loss= 1.14521 val_loss= 1.51926 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.67100\n",
      "Epoch: 0098 train_loss= 1.13702 val_loss= 1.51532 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.67100\n",
      "Epoch: 0099 train_loss= 1.12886 val_loss= 1.51140 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.67100\n",
      "Epoch: 0100 train_loss= 1.12077 val_loss= 1.50748 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.67100\n",
      "Epoch: 0101 train_loss= 1.11274 val_loss= 1.50357 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.67100\n",
      "Epoch: 0102 train_loss= 1.10476 val_loss= 1.49966 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.67100\n",
      "Epoch: 0103 train_loss= 1.09683 val_loss= 1.49578 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.67100\n",
      "Epoch: 0104 train_loss= 1.08898 val_loss= 1.49191 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.67100\n",
      "Epoch: 0105 train_loss= 1.08119 val_loss= 1.48806 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.67100\n",
      "Epoch: 0106 train_loss= 1.07346 val_loss= 1.48422 train_acc= 0.69000 val_acc= 0.69000 test_acc= 0.67100\n",
      "Epoch: 0107 train_loss= 1.06579 val_loss= 1.48040 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.67100\n",
      "Epoch: 0108 train_loss= 1.05820 val_loss= 1.47659 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.67100\n",
      "Epoch: 0109 train_loss= 1.05067 val_loss= 1.47281 train_acc= 0.69000 val_acc= 0.69000 test_acc= 0.67100\n",
      "Epoch: 0110 train_loss= 1.04322 val_loss= 1.46903 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.67100\n",
      "Epoch: 0111 train_loss= 1.03581 val_loss= 1.46529 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.67100\n",
      "Epoch: 0112 train_loss= 1.02851 val_loss= 1.46156 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.67600\n",
      "Epoch: 0113 train_loss= 1.02125 val_loss= 1.45786 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.67600\n",
      "Epoch: 0114 train_loss= 1.01408 val_loss= 1.45417 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.67600\n",
      "Epoch: 0115 train_loss= 1.00697 val_loss= 1.45052 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.67600\n",
      "Epoch: 0116 train_loss= 0.99994 val_loss= 1.44690 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.67600\n",
      "Epoch: 0117 train_loss= 0.99298 val_loss= 1.44328 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.67800\n",
      "Epoch: 0118 train_loss= 0.98609 val_loss= 1.43968 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0119 train_loss= 0.97927 val_loss= 1.43611 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0120 train_loss= 0.97253 val_loss= 1.43257 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0121 train_loss= 0.96586 val_loss= 1.42906 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0122 train_loss= 0.95926 val_loss= 1.42558 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0123 train_loss= 0.95273 val_loss= 1.42211 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67900\n",
      "Epoch: 0124 train_loss= 0.94629 val_loss= 1.41867 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67900\n",
      "Epoch: 0125 train_loss= 0.93991 val_loss= 1.41526 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67900\n",
      "Epoch: 0126 train_loss= 0.93361 val_loss= 1.41187 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67900\n",
      "Epoch: 0127 train_loss= 0.92737 val_loss= 1.40851 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67900\n",
      "Epoch: 0128 train_loss= 0.92121 val_loss= 1.40519 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67900\n",
      "Epoch: 0129 train_loss= 0.91513 val_loss= 1.40189 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67900\n",
      "Epoch: 0130 train_loss= 0.90911 val_loss= 1.39861 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67900\n",
      "Epoch: 0131 train_loss= 0.90317 val_loss= 1.39536 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67900\n",
      "Epoch: 0132 train_loss= 0.89728 val_loss= 1.39214 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67900\n",
      "Epoch: 0133 train_loss= 0.89149 val_loss= 1.38896 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67900\n",
      "Epoch: 0134 train_loss= 0.88575 val_loss= 1.38580 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67900\n",
      "Epoch: 0135 train_loss= 0.88008 val_loss= 1.38267 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67900\n",
      "Epoch: 0136 train_loss= 0.87448 val_loss= 1.37956 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67900\n",
      "Epoch: 0137 train_loss= 0.86894 val_loss= 1.37648 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67900\n",
      "Epoch: 0138 train_loss= 0.86348 val_loss= 1.37344 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67900\n",
      "Epoch: 0139 train_loss= 0.85808 val_loss= 1.37042 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67900\n",
      "Epoch: 0140 train_loss= 0.85274 val_loss= 1.36743 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67900\n",
      "Epoch: 0141 train_loss= 0.84748 val_loss= 1.36446 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67900\n",
      "Epoch: 0142 train_loss= 0.84228 val_loss= 1.36151 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67900\n",
      "Epoch: 0143 train_loss= 0.83713 val_loss= 1.35862 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67900\n",
      "Epoch: 0144 train_loss= 0.83207 val_loss= 1.35574 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67900\n",
      "Epoch: 0145 train_loss= 0.82703 val_loss= 1.35289 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.68400\n",
      "Epoch: 0146 train_loss= 0.82208 val_loss= 1.35006 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0147 train_loss= 0.81719 val_loss= 1.34723 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0148 train_loss= 0.81235 val_loss= 1.34447 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0149 train_loss= 0.80759 val_loss= 1.34174 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0150 train_loss= 0.80287 val_loss= 1.33903 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0151 train_loss= 0.79821 val_loss= 1.33633 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0152 train_loss= 0.79361 val_loss= 1.33366 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0153 train_loss= 0.78907 val_loss= 1.33102 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.68400\n",
      "Epoch: 0154 train_loss= 0.78457 val_loss= 1.32842 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.68400\n",
      "Epoch: 0155 train_loss= 0.78014 val_loss= 1.32585 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.68400\n",
      "Epoch: 0156 train_loss= 0.77576 val_loss= 1.32328 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.68400\n",
      "Epoch: 0157 train_loss= 0.77144 val_loss= 1.32075 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.68400\n",
      "Epoch: 0158 train_loss= 0.76715 val_loss= 1.31825 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.68400\n",
      "Epoch: 0159 train_loss= 0.76293 val_loss= 1.31576 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.68400\n",
      "Epoch: 0160 train_loss= 0.75876 val_loss= 1.31330 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0161 train_loss= 0.75463 val_loss= 1.31087 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0162 train_loss= 0.75055 val_loss= 1.30847 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0163 train_loss= 0.74653 val_loss= 1.30609 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0164 train_loss= 0.74255 val_loss= 1.30371 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0165 train_loss= 0.73863 val_loss= 1.30138 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0166 train_loss= 0.73474 val_loss= 1.29907 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0167 train_loss= 0.73090 val_loss= 1.29677 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0168 train_loss= 0.72712 val_loss= 1.29451 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0169 train_loss= 0.72337 val_loss= 1.29226 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0170 train_loss= 0.71967 val_loss= 1.29003 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0171 train_loss= 0.71602 val_loss= 1.28785 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0172 train_loss= 0.71239 val_loss= 1.28566 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0173 train_loss= 0.70882 val_loss= 1.28348 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0174 train_loss= 0.70529 val_loss= 1.28135 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68400\n",
      "Epoch: 0175 train_loss= 0.70180 val_loss= 1.27925 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.67800\n",
      "Epoch: 0176 train_loss= 0.69835 val_loss= 1.27715 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.67800\n",
      "Epoch: 0177 train_loss= 0.69494 val_loss= 1.27508 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67800\n",
      "Epoch: 0178 train_loss= 0.69157 val_loss= 1.27303 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67800\n",
      "Epoch: 0179 train_loss= 0.68823 val_loss= 1.27099 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67800\n",
      "Epoch: 0180 train_loss= 0.68493 val_loss= 1.26897 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67800\n",
      "Epoch: 0181 train_loss= 0.68166 val_loss= 1.26699 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67800\n",
      "Epoch: 0182 train_loss= 0.67845 val_loss= 1.26503 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67800\n",
      "Epoch: 0183 train_loss= 0.67527 val_loss= 1.26308 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67800\n",
      "Epoch: 0184 train_loss= 0.67211 val_loss= 1.26114 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67800\n",
      "Epoch: 0185 train_loss= 0.66900 val_loss= 1.25921 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67800\n",
      "Epoch: 0186 train_loss= 0.66593 val_loss= 1.25730 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67800\n",
      "Epoch: 0187 train_loss= 0.66287 val_loss= 1.25543 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67800\n",
      "Epoch: 0188 train_loss= 0.65987 val_loss= 1.25357 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67800\n",
      "Epoch: 0189 train_loss= 0.65689 val_loss= 1.25174 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67800\n",
      "Epoch: 0190 train_loss= 0.65393 val_loss= 1.24992 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67800\n",
      "Epoch: 0191 train_loss= 0.65102 val_loss= 1.24813 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67800\n",
      "Epoch: 0192 train_loss= 0.64814 val_loss= 1.24633 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.67800\n",
      "Epoch: 0193 train_loss= 0.64530 val_loss= 1.24457 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.67800\n",
      "Epoch: 0194 train_loss= 0.64247 val_loss= 1.24281 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.67800\n",
      "Epoch: 0195 train_loss= 0.63968 val_loss= 1.24107 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.67800\n",
      "Epoch: 0196 train_loss= 0.63692 val_loss= 1.23934 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.67800\n",
      "Epoch: 0197 train_loss= 0.63419 val_loss= 1.23764 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.67800\n",
      "Epoch: 0198 train_loss= 0.63147 val_loss= 1.23597 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.67800\n",
      "Epoch: 0199 train_loss= 0.62880 val_loss= 1.23431 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.67800\n",
      "Epoch: 0200 train_loss= 0.62615 val_loss= 1.23267 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.67800\n",
      "Epoch: 0201 train_loss= 0.62353 val_loss= 1.23101 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.67800\n",
      "Epoch: 0202 train_loss= 0.62093 val_loss= 1.22939 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.67800\n",
      "Epoch: 0203 train_loss= 0.61837 val_loss= 1.22777 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.67800\n",
      "Epoch: 0204 train_loss= 0.61584 val_loss= 1.22618 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.67800\n",
      "Epoch: 0205 train_loss= 0.61332 val_loss= 1.22461 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0206 train_loss= 0.61083 val_loss= 1.22304 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0207 train_loss= 0.60836 val_loss= 1.22147 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0208 train_loss= 0.60592 val_loss= 1.21993 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0209 train_loss= 0.60350 val_loss= 1.21840 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0210 train_loss= 0.60111 val_loss= 1.21690 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.67800\n",
      "Epoch: 0211 train_loss= 0.59874 val_loss= 1.21542 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.67800\n",
      "Epoch: 0212 train_loss= 0.59640 val_loss= 1.21395 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.67800\n",
      "Epoch: 0213 train_loss= 0.59408 val_loss= 1.21250 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.67800\n",
      "Epoch: 0214 train_loss= 0.59178 val_loss= 1.21106 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0215 train_loss= 0.58950 val_loss= 1.20961 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0216 train_loss= 0.58725 val_loss= 1.20818 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0217 train_loss= 0.58502 val_loss= 1.20676 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0218 train_loss= 0.58280 val_loss= 1.20535 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0219 train_loss= 0.58062 val_loss= 1.20396 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0220 train_loss= 0.57844 val_loss= 1.20259 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0221 train_loss= 0.57630 val_loss= 1.20124 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0222 train_loss= 0.57418 val_loss= 1.19991 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0223 train_loss= 0.57206 val_loss= 1.19858 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0224 train_loss= 0.56997 val_loss= 1.19722 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0225 train_loss= 0.56789 val_loss= 1.19591 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0226 train_loss= 0.56586 val_loss= 1.19461 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0227 train_loss= 0.56383 val_loss= 1.19333 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0228 train_loss= 0.56181 val_loss= 1.19203 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0229 train_loss= 0.55982 val_loss= 1.19075 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0230 train_loss= 0.55784 val_loss= 1.18948 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0231 train_loss= 0.55588 val_loss= 1.18824 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0232 train_loss= 0.55394 val_loss= 1.18702 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0233 train_loss= 0.55202 val_loss= 1.18580 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0234 train_loss= 0.55011 val_loss= 1.18458 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0235 train_loss= 0.54822 val_loss= 1.18337 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0236 train_loss= 0.54636 val_loss= 1.18216 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.67800\n",
      "Epoch: 0237 train_loss= 0.54450 val_loss= 1.18097 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0238 train_loss= 0.54266 val_loss= 1.17979 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0239 train_loss= 0.54084 val_loss= 1.17865 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0240 train_loss= 0.53904 val_loss= 1.17749 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0241 train_loss= 0.53724 val_loss= 1.17634 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0242 train_loss= 0.53546 val_loss= 1.17520 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0243 train_loss= 0.53370 val_loss= 1.17408 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0244 train_loss= 0.53196 val_loss= 1.17297 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0245 train_loss= 0.53023 val_loss= 1.17187 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0246 train_loss= 0.52851 val_loss= 1.17079 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0247 train_loss= 0.52681 val_loss= 1.16970 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0248 train_loss= 0.52512 val_loss= 1.16861 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0249 train_loss= 0.52345 val_loss= 1.16753 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0250 train_loss= 0.52179 val_loss= 1.16648 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0251 train_loss= 0.52015 val_loss= 1.16542 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0252 train_loss= 0.51852 val_loss= 1.16436 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0253 train_loss= 0.51689 val_loss= 1.16332 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0254 train_loss= 0.51529 val_loss= 1.16230 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0255 train_loss= 0.51370 val_loss= 1.16129 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0256 train_loss= 0.51212 val_loss= 1.16026 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0257 train_loss= 0.51055 val_loss= 1.15926 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0258 train_loss= 0.50900 val_loss= 1.15828 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0259 train_loss= 0.50746 val_loss= 1.15728 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0260 train_loss= 0.50594 val_loss= 1.15628 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0261 train_loss= 0.50441 val_loss= 1.15530 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0262 train_loss= 0.50291 val_loss= 1.15435 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0263 train_loss= 0.50142 val_loss= 1.15341 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0264 train_loss= 0.49994 val_loss= 1.15247 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0265 train_loss= 0.49846 val_loss= 1.15154 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0266 train_loss= 0.49700 val_loss= 1.15060 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0267 train_loss= 0.49556 val_loss= 1.14968 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0268 train_loss= 0.49412 val_loss= 1.14876 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0269 train_loss= 0.49271 val_loss= 1.14785 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67800\n",
      "Epoch: 0270 train_loss= 0.49129 val_loss= 1.14694 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0271 train_loss= 0.48989 val_loss= 1.14605 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0272 train_loss= 0.48850 val_loss= 1.14517 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0273 train_loss= 0.48711 val_loss= 1.14429 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0274 train_loss= 0.48575 val_loss= 1.14341 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Epoch: 0275 train_loss= 0.48440 val_loss= 1.14249 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67800\n",
      "Early stopping...\n"
     ]
    }
   ],
   "source": [
    "from config import args\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from utils import *\n",
    "from models import GCN_dropedge\n",
    "from metrics import *\n",
    "\n",
    "# Settings\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "args.dataset=dataset_name\n",
    "\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(args.dataset)\n",
    "adj=modified_adj\n",
    "\n",
    "tuple_adj = sparse_to_tuple(adj.tocoo())\n",
    "adj_tensor = tf.SparseTensor(*tuple_adj)\n",
    "\n",
    "features = preprocess_features(features)\n",
    "\n",
    "model = GCN_dropedge(input_dim=features.shape[1], output_dim=y_train.shape[1], adj=adj_tensor)\n",
    "\n",
    "\n",
    "features_tensor = tf.convert_to_tensor(features,dtype=tf.float32)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train,dtype=tf.float32)\n",
    "train_mask_tensor = tf.convert_to_tensor(train_mask)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test,dtype=tf.float32)\n",
    "test_mask_tensor = tf.convert_to_tensor(test_mask)\n",
    "y_val_tensor = tf.convert_to_tensor(y_val,dtype=tf.float32)\n",
    "val_mask_tensor = tf.convert_to_tensor(val_mask)\n",
    "\n",
    "best_test_acc = 0\n",
    "best_val_acc = 0\n",
    "best_val_loss = 10000\n",
    "\n",
    "\n",
    "curr_step = 0\n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        output = model.call((features_tensor),training=True)\n",
    "        cross_loss = masked_softmax_cross_entropy(output, y_train_tensor,train_mask_tensor)\n",
    "        lossL2 = tf.add_n([tf.nn.l2_loss(v) for v in model.trainable_variables])\n",
    "        loss = cross_loss + args.weight_decay*lossL2\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    output = model.call((features_tensor), training=False)\n",
    "    train_acc = masked_accuracy(output, y_train_tensor,train_mask_tensor)\n",
    "    val_acc  = masked_accuracy(output, y_val_tensor,val_mask_tensor)\n",
    "    val_loss = masked_softmax_cross_entropy(output, y_val_tensor, val_mask_tensor)\n",
    "    test_acc  = masked_accuracy(output, y_test_tensor,test_mask_tensor)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        curr_step = 0\n",
    "        best_test_acc = test_acc\n",
    "        best_val_acc = val_acc\n",
    "        best_val_loss= val_loss\n",
    "        # Print results\n",
    "\n",
    "    else:\n",
    "        curr_step +=1\n",
    "    if curr_step > args.early_stop:\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cross_loss),\"val_loss=\", \"{:.5f}\".format(val_loss),\n",
    "      \"train_acc=\", \"{:.5f}\".format(val_acc), \"val_acc=\", \"{:.5f}\".format(val_acc),\n",
    "      \"test_acc=\", \"{:.5f}\".format(best_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
