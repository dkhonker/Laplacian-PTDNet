{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from utils import *\n",
    "from models import GCN, PTDNetGCN\n",
    "from metrics import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "# Settings\n",
    "args.dataset='pubmed'\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(args.dataset)\n",
    "all_labels = y_train + y_test+y_val\n",
    "single_label = np.argmax(all_labels,axis=-1)\n",
    "nodesize = features.shape[0]\n",
    "\n",
    "# Some preprocessing\n",
    "features_tmp=features.copy()\n",
    "features = preprocess_features(features).A\n",
    "support = preprocess_adj(adj)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "\n",
    "tuple_adj = sparse_to_tuple(adj.tocoo())\n",
    "features_tensor = tf.convert_to_tensor(features,dtype=dtype)\n",
    "adj_tensor = tf.SparseTensor(*tuple_adj)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train,dtype=dtype)\n",
    "train_mask_tensor = tf.convert_to_tensor(train_mask)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test,dtype=dtype)\n",
    "test_mask_tensor = tf.convert_to_tensor(test_mask)\n",
    "y_val_tensor = tf.convert_to_tensor(y_val,dtype=dtype)\n",
    "val_mask_tensor = tf.convert_to_tensor(val_mask)\n",
    "\n",
    "best_test_acc = 0\n",
    "best_val_acc_trail = 0\n",
    "best_val_loss = 10000\n",
    "\n",
    "from deeprobust.graph.data import Dataset\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.global_attack import Metattack\n",
    "# Setup Surrogate model\n",
    "idx_train=np.array(np.where(train_mask==1)).tolist()[0]\n",
    "idx_val=np.array(np.where(val_mask==1)).tolist()[0]\n",
    "idx_unlabeled=np.array(np.where(test_mask==1)).tolist()[0]\n",
    "surrogate = GCN(nfeat=features.shape[1], nclass=single_label.max().item()+1,\n",
    "                nhid=256, dropout=0, with_relu=False, with_bias=False, device='cuda').to('cuda')\n",
    "surrogate.fit(features, adj, single_label, idx_train, idx_val, patience=100)\n",
    "# Setup Attack Model\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = Metattack(surrogate, nnodes=adj.shape[0], feature_shape=features.shape,\n",
    "        attack_structure=True, attack_features=False, device='cuda', lambda_=0).to('cuda')\n",
    "# Attack\n",
    "model.attack(features, adj, single_label, idx_train, idx_unlabeled, n_perturbations=50, ll_constraint=False)\n",
    "modified_adj = model.modified_adj\n",
    "# print(adj)\n",
    "# print(\"shiy\")\n",
    "# print(modified_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.45 GiB (GPU 0; 23.70 GiB total capacity; 124.82 MiB already allocated; 616.56 MiB free; 144.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-92771f167ad0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = Metattack(surrogate, nnodes=adj.shape[0], feature_shape=features.shape,\n\u001b[0m\u001b[1;32m      2\u001b[0m         attack_structure=True, attack_features=False, device='cuda', lambda_=0).to('cuda')\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_unlabeled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_perturbations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodified_adj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodified_adj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    983\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    984\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.45 GiB (GPU 0; 23.70 GiB total capacity; 124.82 MiB already allocated; 616.56 MiB free; 144.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.7977771759033203\n",
      "GCN acc on unlabled data: 0.758\n",
      "attack loss: 0.723433256149292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:   2%|▏         | 1/50 [05:28<4:28:27, 328.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.7987044453620911\n",
      "GCN acc on unlabled data: 0.752\n",
      "attack loss: 0.7250884175300598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:   4%|▍         | 2/50 [10:14<4:02:49, 303.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.8071153163909912\n",
      "GCN acc on unlabled data: 0.756\n",
      "attack loss: 0.7356905937194824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:   6%|▌         | 3/50 [15:06<3:53:46, 298.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.8028127551078796\n",
      "GCN acc on unlabled data: 0.764\n",
      "attack loss: 0.7315675616264343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:   8%|▊         | 4/50 [20:04<3:48:27, 298.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.8134742975234985\n",
      "GCN acc on unlabled data: 0.754\n",
      "attack loss: 0.7472820281982422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  10%|█         | 5/50 [25:21<3:48:41, 304.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.8136302828788757\n",
      "GCN acc on unlabled data: 0.769\n",
      "attack loss: 0.7454394698143005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  12%|█▏        | 6/50 [30:37<3:46:24, 308.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.840639054775238\n",
      "GCN acc on unlabled data: 0.755\n",
      "attack loss: 0.774020254611969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  14%|█▍        | 7/50 [36:02<3:45:04, 314.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.8196975588798523\n",
      "GCN acc on unlabled data: 0.774\n",
      "attack loss: 0.7526183128356934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  16%|█▌        | 8/50 [40:59<3:35:58, 308.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.8418235182762146\n",
      "GCN acc on unlabled data: 0.751\n",
      "attack loss: 0.7765033841133118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  18%|█▊        | 9/50 [45:58<3:28:48, 305.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 0.8486586213111877\n",
      "GCN acc on unlabled data: 0.764\n",
      "attack loss: 0.7845679521560669\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "from utils import *\n",
    "from models import GCN, PTDNetGCN\n",
    "from metrics import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "# Settings\n",
    "args.dataset='pubmed'\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(args.dataset)\n",
    "all_labels = y_train + y_test+y_val\n",
    "single_label = np.argmax(all_labels,axis=-1)\n",
    "nodesize = features.shape[0]\n",
    "\n",
    "# Some preprocessing\n",
    "features_tmp=features.copy()\n",
    "features = preprocess_features(features).A\n",
    "support = preprocess_adj(adj)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "\n",
    "tuple_adj = sparse_to_tuple(adj.tocoo())\n",
    "features_tensor = tf.convert_to_tensor(features,dtype=dtype)\n",
    "adj_tensor = tf.SparseTensor(*tuple_adj)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train,dtype=dtype)\n",
    "train_mask_tensor = tf.convert_to_tensor(train_mask)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test,dtype=dtype)\n",
    "test_mask_tensor = tf.convert_to_tensor(test_mask)\n",
    "y_val_tensor = tf.convert_to_tensor(y_val,dtype=dtype)\n",
    "val_mask_tensor = tf.convert_to_tensor(val_mask)\n",
    "\n",
    "best_test_acc = 0\n",
    "best_val_acc_trail = 0\n",
    "best_val_loss = 10000\n",
    "\n",
    "from deeprobust.graph.data import Dataset\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.global_attack import Metattack\n",
    "# Setup Surrogate model\n",
    "idx_train=np.array(np.where(train_mask==1)).tolist()[0]\n",
    "idx_val=np.array(np.where(val_mask==1)).tolist()[0]\n",
    "idx_unlabeled=np.array(np.where(test_mask==1)).tolist()[0]\n",
    "surrogate = GCN(nfeat=features.shape[1], nclass=single_label.max().item()+1,\n",
    "                nhid=256, dropout=0, with_relu=False, with_bias=False, device='cpu').to('cpu')\n",
    "surrogate.fit(features, adj, single_label, idx_train, idx_val, patience=100)\n",
    "# Setup Attack Model\n",
    "model = Metattack(surrogate, nnodes=adj.shape[0], feature_shape=features.shape,\n",
    "        attack_structure=True, attack_features=False, device='cpu', lambda_=0).to('cpu')\n",
    "# Attack\n",
    "model.attack(features, adj, single_label, idx_train, idx_unlabeled, n_perturbations=50, ll_constraint=False)\n",
    "modified_adj = model.modified_adj\n",
    "# print(adj)\n",
    "# print(\"shiy\")\n",
    "# print(modified_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_adj=sp.csr_array(modified_adj.int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_vol 4702.1865\n",
      "Epoch: 0001 train_loss= 1.79175 val_loss= 1.79132 train_acc= 0.35000 val_acc= 0.24000 best_val_acc_trail= 0.24000 test_acc= 0.22600\n",
      "time  1.7085626125335693\n",
      "edge_vol 4691.4775\n",
      "Epoch: 0002 train_loss= 1.78986 val_loss= 1.79072 train_acc= 0.64167 val_acc= 0.34800 best_val_acc_trail= 0.34800 test_acc= 0.31400\n",
      "time  1.9730730056762695\n",
      "edge_vol 4680.9634\n",
      "Epoch: 0003 train_loss= 1.78794 val_loss= 1.79009 train_acc= 0.77500 val_acc= 0.42000 best_val_acc_trail= 0.42000 test_acc= 0.42700\n",
      "time  2.2187869548797607\n",
      "edge_vol 4670.5166\n",
      "Epoch: 0004 train_loss= 1.78593 val_loss= 1.78942 train_acc= 0.81667 val_acc= 0.48600 best_val_acc_trail= 0.48600 test_acc= 0.47600\n",
      "time  2.465973377227783\n",
      "edge_vol 4660.0645\n",
      "Epoch: 0005 train_loss= 1.78394 val_loss= 1.78870 train_acc= 0.85000 val_acc= 0.51800 best_val_acc_trail= 0.51800 test_acc= 0.51400\n",
      "time  2.70938777923584\n",
      "edge_vol 4649.545\n",
      "Epoch: 0006 train_loss= 1.78178 val_loss= 1.78792 train_acc= 0.85833 val_acc= 0.53600 best_val_acc_trail= 0.53600 test_acc= 0.54100\n",
      "time  2.9607229232788086\n",
      "edge_vol 4638.9526\n",
      "Epoch: 0007 train_loss= 1.77974 val_loss= 1.78707 train_acc= 0.86667 val_acc= 0.55400 best_val_acc_trail= 0.55400 test_acc= 0.55600\n",
      "time  3.2064132690429688\n",
      "edge_vol 4628.295\n",
      "Epoch: 0008 train_loss= 1.77733 val_loss= 1.78613 train_acc= 0.86667 val_acc= 0.57000 best_val_acc_trail= 0.57000 test_acc= 0.57500\n",
      "time  3.448763847351074\n",
      "edge_vol 4617.585\n",
      "Epoch: 0009 train_loss= 1.77480 val_loss= 1.78512 train_acc= 0.86667 val_acc= 0.58000 best_val_acc_trail= 0.58000 test_acc= 0.59000\n",
      "time  3.686641216278076\n",
      "edge_vol 4606.7734\n",
      "Epoch: 0010 train_loss= 1.77212 val_loss= 1.78402 train_acc= 0.86667 val_acc= 0.59400 best_val_acc_trail= 0.59400 test_acc= 0.60400\n",
      "time  3.9340362548828125\n",
      "edge_vol 4595.8438\n",
      "Epoch: 0011 train_loss= 1.76941 val_loss= 1.78284 train_acc= 0.86667 val_acc= 0.60600 best_val_acc_trail= 0.60600 test_acc= 0.61200\n",
      "time  4.176454067230225\n",
      "edge_vol 4584.7905\n",
      "Epoch: 0012 train_loss= 1.76654 val_loss= 1.78160 train_acc= 0.86667 val_acc= 0.61000 best_val_acc_trail= 0.61000 test_acc= 0.62000\n",
      "time  4.442600250244141\n",
      "edge_vol 4573.613\n",
      "Epoch: 0013 train_loss= 1.76335 val_loss= 1.78028 train_acc= 0.86667 val_acc= 0.61800 best_val_acc_trail= 0.61800 test_acc= 0.62400\n",
      "time  4.685513734817505\n",
      "edge_vol 4562.329\n",
      "Epoch: 0014 train_loss= 1.76013 val_loss= 1.77890 train_acc= 0.87500 val_acc= 0.62400 best_val_acc_trail= 0.62400 test_acc= 0.63400\n",
      "time  4.927985191345215\n",
      "edge_vol 4550.908\n",
      "Epoch: 0015 train_loss= 1.75657 val_loss= 1.77746 train_acc= 0.87500 val_acc= 0.63000 best_val_acc_trail= 0.63000 test_acc= 0.63600\n",
      "time  5.191051959991455\n",
      "edge_vol 4539.364\n",
      "Epoch: 0016 train_loss= 1.75302 val_loss= 1.77596 train_acc= 0.88333 val_acc= 0.62800 best_val_acc_trail= 0.63000 test_acc= 0.63600\n",
      "time  5.45420241355896\n",
      "edge_vol 4527.684\n",
      "Epoch: 0017 train_loss= 1.74979 val_loss= 1.77442 train_acc= 0.88333 val_acc= 0.63000 best_val_acc_trail= 0.63000 test_acc= 0.63600\n",
      "time  5.6982035636901855\n",
      "edge_vol 4515.8706\n",
      "Epoch: 0018 train_loss= 1.74560 val_loss= 1.77283 train_acc= 0.88333 val_acc= 0.63200 best_val_acc_trail= 0.63200 test_acc= 0.63500\n",
      "time  5.942559003829956\n",
      "edge_vol 4503.919\n",
      "Epoch: 0019 train_loss= 1.74122 val_loss= 1.77118 train_acc= 0.88333 val_acc= 0.63000 best_val_acc_trail= 0.63200 test_acc= 0.63500\n",
      "time  6.1843836307525635\n",
      "edge_vol 4491.801\n",
      "Epoch: 0020 train_loss= 1.73779 val_loss= 1.76949 train_acc= 0.88333 val_acc= 0.63600 best_val_acc_trail= 0.63600 test_acc= 0.63800\n",
      "time  6.427007436752319\n",
      "edge_vol 4479.5835\n",
      "Epoch: 0021 train_loss= 1.73283 val_loss= 1.76774 train_acc= 0.88333 val_acc= 0.63800 best_val_acc_trail= 0.63800 test_acc= 0.64100\n",
      "time  6.700839281082153\n",
      "edge_vol 4467.2534\n",
      "Epoch: 0022 train_loss= 1.72842 val_loss= 1.76596 train_acc= 0.89167 val_acc= 0.63800 best_val_acc_trail= 0.63800 test_acc= 0.64100\n",
      "time  6.948753118515015\n",
      "edge_vol 4454.7607\n",
      "Epoch: 0023 train_loss= 1.72383 val_loss= 1.76414 train_acc= 0.90000 val_acc= 0.64000 best_val_acc_trail= 0.64000 test_acc= 0.63900\n",
      "time  7.195842981338501\n",
      "edge_vol 4442.1167\n",
      "Epoch: 0024 train_loss= 1.71897 val_loss= 1.76228 train_acc= 0.90000 val_acc= 0.64200 best_val_acc_trail= 0.64200 test_acc= 0.63600\n",
      "time  7.441112041473389\n",
      "edge_vol 4429.3154\n",
      "Epoch: 0025 train_loss= 1.71371 val_loss= 1.76039 train_acc= 0.90000 val_acc= 0.64200 best_val_acc_trail= 0.64200 test_acc= 0.63600\n",
      "time  7.692797899246216\n",
      "edge_vol 4416.3545\n",
      "Epoch: 0026 train_loss= 1.70940 val_loss= 1.75847 train_acc= 0.90000 val_acc= 0.64200 best_val_acc_trail= 0.64200 test_acc= 0.63600\n",
      "time  7.955811262130737\n",
      "edge_vol 4403.244\n",
      "Epoch: 0027 train_loss= 1.70451 val_loss= 1.75651 train_acc= 0.90000 val_acc= 0.64000 best_val_acc_trail= 0.64200 test_acc= 0.63600\n",
      "time  8.209113121032715\n",
      "edge_vol 4390.015\n",
      "Epoch: 0028 train_loss= 1.69851 val_loss= 1.75453 train_acc= 0.90000 val_acc= 0.64000 best_val_acc_trail= 0.64200 test_acc= 0.63600\n",
      "time  8.464391946792603\n",
      "edge_vol 4376.6436\n",
      "Epoch: 0029 train_loss= 1.69448 val_loss= 1.75252 train_acc= 0.90000 val_acc= 0.64000 best_val_acc_trail= 0.64200 test_acc= 0.63600\n",
      "time  8.707263708114624\n",
      "edge_vol 4363.098\n",
      "Epoch: 0030 train_loss= 1.68799 val_loss= 1.75050 train_acc= 0.90833 val_acc= 0.64200 best_val_acc_trail= 0.64200 test_acc= 0.63600\n",
      "time  8.951387405395508\n",
      "edge_vol 4349.394\n",
      "Epoch: 0031 train_loss= 1.68279 val_loss= 1.74843 train_acc= 0.91667 val_acc= 0.64200 best_val_acc_trail= 0.64200 test_acc= 0.63600\n",
      "time  9.177587985992432\n",
      "edge_vol 4335.5303\n",
      "Epoch: 0032 train_loss= 1.67786 val_loss= 1.74635 train_acc= 0.91667 val_acc= 0.64400 best_val_acc_trail= 0.64400 test_acc= 0.63900\n",
      "time  9.419169187545776\n",
      "edge_vol 4321.4375\n",
      "Epoch: 0033 train_loss= 1.67081 val_loss= 1.74423 train_acc= 0.91667 val_acc= 0.64400 best_val_acc_trail= 0.64400 test_acc= 0.63900\n",
      "time  9.661001205444336\n",
      "edge_vol 4307.1787\n",
      "Epoch: 0034 train_loss= 1.66620 val_loss= 1.74209 train_acc= 0.91667 val_acc= 0.64400 best_val_acc_trail= 0.64400 test_acc= 0.64000\n",
      "time  9.89845323562622\n",
      "edge_vol 4292.724\n",
      "Epoch: 0035 train_loss= 1.66027 val_loss= 1.73993 train_acc= 0.91667 val_acc= 0.64400 best_val_acc_trail= 0.64400 test_acc= 0.64000\n",
      "time  10.145491361618042\n",
      "edge_vol 4278.0967\n",
      "Epoch: 0036 train_loss= 1.65392 val_loss= 1.73772 train_acc= 0.91667 val_acc= 0.64800 best_val_acc_trail= 0.64800 test_acc= 0.64000\n",
      "time  10.39394474029541\n",
      "edge_vol 4263.2656\n",
      "Epoch: 0037 train_loss= 1.64889 val_loss= 1.73550 train_acc= 0.91667 val_acc= 0.64800 best_val_acc_trail= 0.64800 test_acc= 0.64000\n",
      "time  10.641863822937012\n",
      "edge_vol 4248.244\n",
      "Epoch: 0038 train_loss= 1.64261 val_loss= 1.73327 train_acc= 0.92500 val_acc= 0.65200 best_val_acc_trail= 0.65200 test_acc= 0.64100\n",
      "time  10.890069007873535\n",
      "edge_vol 4233.093\n",
      "Epoch: 0039 train_loss= 1.63663 val_loss= 1.73103 train_acc= 0.92500 val_acc= 0.65400 best_val_acc_trail= 0.65400 test_acc= 0.64500\n",
      "time  11.14271330833435\n",
      "edge_vol 4217.7354\n",
      "Epoch: 0040 train_loss= 1.63033 val_loss= 1.72878 train_acc= 0.93333 val_acc= 0.65400 best_val_acc_trail= 0.65400 test_acc= 0.64500\n",
      "time  11.386739730834961\n",
      "edge_vol 4202.16\n",
      "Epoch: 0041 train_loss= 1.62386 val_loss= 1.72652 train_acc= 0.93333 val_acc= 0.65600 best_val_acc_trail= 0.65600 test_acc= 0.64900\n",
      "time  11.630386352539062\n",
      "edge_vol 4186.3643\n",
      "Epoch: 0042 train_loss= 1.61599 val_loss= 1.72425 train_acc= 0.94167 val_acc= 0.65800 best_val_acc_trail= 0.65800 test_acc= 0.65000\n",
      "time  11.868933200836182\n",
      "edge_vol 4170.467\n",
      "Epoch: 0043 train_loss= 1.61096 val_loss= 1.72197 train_acc= 0.94167 val_acc= 0.65600 best_val_acc_trail= 0.65800 test_acc= 0.65000\n",
      "time  12.115756750106812\n",
      "edge_vol 4154.453\n",
      "Epoch: 0044 train_loss= 1.60327 val_loss= 1.71969 train_acc= 0.94167 val_acc= 0.65400 best_val_acc_trail= 0.65800 test_acc= 0.65000\n",
      "time  12.354826927185059\n",
      "edge_vol 4138.248\n",
      "Epoch: 0045 train_loss= 1.59827 val_loss= 1.71738 train_acc= 0.94167 val_acc= 0.65600 best_val_acc_trail= 0.65800 test_acc= 0.65000\n",
      "time  12.599475383758545\n",
      "edge_vol 4121.9526\n",
      "Epoch: 0046 train_loss= 1.59295 val_loss= 1.71509 train_acc= 0.94167 val_acc= 0.65600 best_val_acc_trail= 0.65800 test_acc= 0.65000\n",
      "time  12.844447374343872\n",
      "edge_vol 4105.5547\n",
      "Epoch: 0047 train_loss= 1.58632 val_loss= 1.71277 train_acc= 0.95000 val_acc= 0.66000 best_val_acc_trail= 0.66000 test_acc= 0.65600\n",
      "time  13.093956232070923\n",
      "edge_vol 4089.0198\n",
      "Epoch: 0048 train_loss= 1.57939 val_loss= 1.71046 train_acc= 0.95000 val_acc= 0.66000 best_val_acc_trail= 0.66000 test_acc= 0.65600\n",
      "time  13.359673500061035\n",
      "edge_vol 4072.363\n",
      "Epoch: 0049 train_loss= 1.57253 val_loss= 1.70814 train_acc= 0.95000 val_acc= 0.66200 best_val_acc_trail= 0.66200 test_acc= 0.65700\n",
      "time  13.611088275909424\n",
      "edge_vol 4055.5093\n",
      "Epoch: 0050 train_loss= 1.56510 val_loss= 1.70583 train_acc= 0.95000 val_acc= 0.66200 best_val_acc_trail= 0.66200 test_acc= 0.65700\n",
      "time  13.855216264724731\n",
      "edge_vol 4038.5266\n",
      "Epoch: 0051 train_loss= 1.55635 val_loss= 1.70353 train_acc= 0.95000 val_acc= 0.66400 best_val_acc_trail= 0.66400 test_acc= 0.65700\n",
      "time  14.099875211715698\n",
      "edge_vol 4021.4434\n",
      "Epoch: 0052 train_loss= 1.55266 val_loss= 1.70120 train_acc= 0.95000 val_acc= 0.66400 best_val_acc_trail= 0.66400 test_acc= 0.65700\n",
      "time  14.354305505752563\n",
      "edge_vol 4004.275\n",
      "Epoch: 0053 train_loss= 1.54596 val_loss= 1.69892 train_acc= 0.95000 val_acc= 0.66400 best_val_acc_trail= 0.66400 test_acc= 0.65700\n",
      "time  14.598808765411377\n",
      "edge_vol 3986.921\n",
      "Epoch: 0054 train_loss= 1.53690 val_loss= 1.69667 train_acc= 0.95833 val_acc= 0.66400 best_val_acc_trail= 0.66400 test_acc= 0.66300\n",
      "time  14.844764232635498\n",
      "edge_vol 3969.267\n",
      "Epoch: 0055 train_loss= 1.52893 val_loss= 1.69441 train_acc= 0.96667 val_acc= 0.66800 best_val_acc_trail= 0.66800 test_acc= 0.66200\n",
      "time  15.085949897766113\n",
      "edge_vol 3951.6147\n",
      "Epoch: 0056 train_loss= 1.52343 val_loss= 1.69216 train_acc= 0.97500 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.66200\n",
      "time  15.328704833984375\n",
      "edge_vol 3933.9092\n",
      "Epoch: 0057 train_loss= 1.52057 val_loss= 1.68998 train_acc= 0.97500 val_acc= 0.67200 best_val_acc_trail= 0.67200 test_acc= 0.66100\n",
      "time  15.579399824142456\n",
      "edge_vol 3916.0464\n",
      "Epoch: 0058 train_loss= 1.50660 val_loss= 1.68784 train_acc= 0.97500 val_acc= 0.67000 best_val_acc_trail= 0.67200 test_acc= 0.66100\n",
      "time  15.821668863296509\n",
      "edge_vol 3898.094\n",
      "Epoch: 0059 train_loss= 1.50060 val_loss= 1.68574 train_acc= 0.97500 val_acc= 0.67200 best_val_acc_trail= 0.67200 test_acc= 0.66100\n",
      "time  16.072858095169067\n",
      "edge_vol 3879.9072\n",
      "Epoch: 0060 train_loss= 1.49673 val_loss= 1.68371 train_acc= 0.97500 val_acc= 0.67000 best_val_acc_trail= 0.67200 test_acc= 0.66100\n",
      "time  16.346392393112183\n",
      "edge_vol 3861.6265\n",
      "Epoch: 0061 train_loss= 1.48830 val_loss= 1.68171 train_acc= 0.97500 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.65700\n",
      "time  16.595035552978516\n",
      "edge_vol 3843.2896\n",
      "Epoch: 0062 train_loss= 1.48358 val_loss= 1.67976 train_acc= 0.97500 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.65700\n",
      "time  16.839744806289673\n",
      "edge_vol 3824.851\n",
      "Epoch: 0063 train_loss= 1.47879 val_loss= 1.67787 train_acc= 0.97500 val_acc= 0.67600 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  17.082245349884033\n",
      "edge_vol 3806.398\n",
      "Epoch: 0064 train_loss= 1.47021 val_loss= 1.67607 train_acc= 0.97500 val_acc= 0.67400 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  17.334474325180054\n",
      "edge_vol 3787.8843\n",
      "Epoch: 0065 train_loss= 1.46203 val_loss= 1.67438 train_acc= 0.98333 val_acc= 0.67600 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  17.585339784622192\n",
      "edge_vol 3769.2686\n",
      "Epoch: 0066 train_loss= 1.45981 val_loss= 1.67274 train_acc= 0.98333 val_acc= 0.67600 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  17.83116340637207\n",
      "edge_vol 3750.4539\n",
      "Epoch: 0067 train_loss= 1.45223 val_loss= 1.67122 train_acc= 0.99167 val_acc= 0.67400 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  18.083569049835205\n",
      "edge_vol 3731.45\n",
      "Epoch: 0068 train_loss= 1.44516 val_loss= 1.66978 train_acc= 0.99167 val_acc= 0.67200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  18.330851316452026\n",
      "edge_vol 3712.4268\n",
      "Epoch: 0069 train_loss= 1.43435 val_loss= 1.66846 train_acc= 0.99167 val_acc= 0.67000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  18.58815312385559\n",
      "edge_vol 3693.239\n",
      "Epoch: 0070 train_loss= 1.43406 val_loss= 1.66724 train_acc= 0.99167 val_acc= 0.67000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  18.83159112930298\n",
      "edge_vol 3674.1045\n",
      "Epoch: 0071 train_loss= 1.42159 val_loss= 1.66602 train_acc= 0.99167 val_acc= 0.67000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  19.07903480529785\n",
      "edge_vol 3654.688\n",
      "Epoch: 0072 train_loss= 1.41751 val_loss= 1.66480 train_acc= 0.99167 val_acc= 0.67200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  19.311356782913208\n",
      "edge_vol 3635.045\n",
      "Epoch: 0073 train_loss= 1.41182 val_loss= 1.66373 train_acc= 0.99167 val_acc= 0.67200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  19.55837869644165\n",
      "edge_vol 3615.23\n",
      "Epoch: 0074 train_loss= 1.40503 val_loss= 1.66270 train_acc= 0.99167 val_acc= 0.66800 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  19.813499212265015\n",
      "edge_vol 3595.3003\n",
      "Epoch: 0075 train_loss= 1.39915 val_loss= 1.66182 train_acc= 0.99167 val_acc= 0.66600 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  20.057902097702026\n",
      "edge_vol 3575.0645\n",
      "Epoch: 0076 train_loss= 1.38936 val_loss= 1.66099 train_acc= 0.99167 val_acc= 0.67200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  20.311501264572144\n",
      "edge_vol 3554.71\n",
      "Epoch: 0077 train_loss= 1.38876 val_loss= 1.66025 train_acc= 0.99167 val_acc= 0.67200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  20.57043147087097\n",
      "edge_vol 3534.0566\n",
      "Epoch: 0078 train_loss= 1.37953 val_loss= 1.65953 train_acc= 0.99167 val_acc= 0.67000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  20.829297304153442\n",
      "edge_vol 3513.038\n",
      "Epoch: 0079 train_loss= 1.37583 val_loss= 1.65885 train_acc= 0.99167 val_acc= 0.67200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  21.074676275253296\n",
      "edge_vol 3492.2773\n",
      "Epoch: 0080 train_loss= 1.36807 val_loss= 1.65825 train_acc= 0.99167 val_acc= 0.67400 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  21.35996437072754\n",
      "edge_vol 3471.3347\n",
      "Epoch: 0081 train_loss= 1.36260 val_loss= 1.65763 train_acc= 0.99167 val_acc= 0.67000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  21.60765242576599\n",
      "edge_vol 3449.833\n",
      "Epoch: 0082 train_loss= 1.35932 val_loss= 1.65706 train_acc= 0.99167 val_acc= 0.67000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  21.86588454246521\n",
      "edge_vol 3427.9502\n",
      "Epoch: 0083 train_loss= 1.35326 val_loss= 1.65655 train_acc= 0.99167 val_acc= 0.67000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  22.11725163459778\n",
      "edge_vol 3405.9585\n",
      "Epoch: 0084 train_loss= 1.35411 val_loss= 1.65619 train_acc= 0.99167 val_acc= 0.67000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  22.360443592071533\n",
      "edge_vol 3383.9165\n",
      "Epoch: 0085 train_loss= 1.34879 val_loss= 1.65588 train_acc= 0.99167 val_acc= 0.66800 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  22.612969160079956\n",
      "edge_vol 3361.4404\n",
      "Epoch: 0086 train_loss= 1.33251 val_loss= 1.65555 train_acc= 0.99167 val_acc= 0.66800 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  22.857736825942993\n",
      "edge_vol 3338.4812\n",
      "Epoch: 0087 train_loss= 1.32886 val_loss= 1.65531 train_acc= 0.99167 val_acc= 0.66800 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  23.10326862335205\n",
      "edge_vol 3315.504\n",
      "Epoch: 0088 train_loss= 1.32692 val_loss= 1.65510 train_acc= 0.99167 val_acc= 0.66600 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  23.366677045822144\n",
      "edge_vol 3292.01\n",
      "Epoch: 0089 train_loss= 1.32015 val_loss= 1.65484 train_acc= 0.99167 val_acc= 0.66400 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  23.606672763824463\n",
      "edge_vol 3267.884\n",
      "Epoch: 0090 train_loss= 1.31990 val_loss= 1.65460 train_acc= 0.99167 val_acc= 0.66400 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  23.850221872329712\n",
      "edge_vol 3243.358\n",
      "Epoch: 0091 train_loss= 1.31011 val_loss= 1.65441 train_acc= 0.99167 val_acc= 0.66400 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  24.097142457962036\n",
      "edge_vol 3218.5098\n",
      "Epoch: 0092 train_loss= 1.30378 val_loss= 1.65420 train_acc= 0.99167 val_acc= 0.66200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  24.346518754959106\n",
      "edge_vol 3193.1538\n",
      "Epoch: 0093 train_loss= 1.31036 val_loss= 1.65405 train_acc= 0.99167 val_acc= 0.66200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  24.59476947784424\n",
      "edge_vol 3167.5151\n",
      "Epoch: 0094 train_loss= 1.28904 val_loss= 1.65393 train_acc= 0.99167 val_acc= 0.66000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  24.837872982025146\n",
      "edge_vol 3141.6995\n",
      "Epoch: 0095 train_loss= 1.28817 val_loss= 1.65384 train_acc= 0.99167 val_acc= 0.66000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  25.08896255493164\n",
      "edge_vol 3115.6968\n",
      "Epoch: 0096 train_loss= 1.28452 val_loss= 1.65376 train_acc= 0.99167 val_acc= 0.65200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  25.343170881271362\n",
      "edge_vol 3089.1138\n",
      "Epoch: 0097 train_loss= 1.28228 val_loss= 1.65361 train_acc= 1.00000 val_acc= 0.65200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  25.58504605293274\n",
      "edge_vol 3062.129\n",
      "Epoch: 0098 train_loss= 1.28128 val_loss= 1.65340 train_acc= 1.00000 val_acc= 0.65200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  25.828993558883667\n",
      "edge_vol 3034.7007\n",
      "Epoch: 0099 train_loss= 1.27184 val_loss= 1.65304 train_acc= 1.00000 val_acc= 0.65000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  26.06659173965454\n",
      "edge_vol 3006.0933\n",
      "Epoch: 0100 train_loss= 1.26520 val_loss= 1.65257 train_acc= 1.00000 val_acc= 0.64800 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  26.316118240356445\n",
      "edge_vol 2976.892\n",
      "Epoch: 0101 train_loss= 1.26269 val_loss= 1.65228 train_acc= 1.00000 val_acc= 0.65200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  26.556960582733154\n",
      "edge_vol 2946.6294\n",
      "Epoch: 0102 train_loss= 1.25771 val_loss= 1.65193 train_acc= 1.00000 val_acc= 0.65200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  26.80959153175354\n",
      "edge_vol 2916.2092\n",
      "Epoch: 0103 train_loss= 1.25574 val_loss= 1.65172 train_acc= 1.00000 val_acc= 0.64800 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  27.061498880386353\n",
      "edge_vol 2885.412\n",
      "Epoch: 0104 train_loss= 1.25114 val_loss= 1.65156 train_acc= 1.00000 val_acc= 0.65400 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  27.308568000793457\n",
      "edge_vol 2854.4934\n",
      "Epoch: 0105 train_loss= 1.25514 val_loss= 1.65154 train_acc= 1.00000 val_acc= 0.65200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  27.55423092842102\n",
      "edge_vol 2823.0803\n",
      "Epoch: 0106 train_loss= 1.23860 val_loss= 1.65161 train_acc= 1.00000 val_acc= 0.65200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  27.806806325912476\n",
      "edge_vol 2791.1934\n",
      "Epoch: 0107 train_loss= 1.24032 val_loss= 1.65174 train_acc= 1.00000 val_acc= 0.65400 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  28.05417776107788\n",
      "edge_vol 2758.8289\n",
      "Epoch: 0108 train_loss= 1.23684 val_loss= 1.65204 train_acc= 1.00000 val_acc= 0.65600 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  28.307252168655396\n",
      "edge_vol 2725.838\n",
      "Epoch: 0109 train_loss= 1.22634 val_loss= 1.65245 train_acc= 1.00000 val_acc= 0.65600 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  28.54930567741394\n",
      "edge_vol 2692.6562\n",
      "Epoch: 0110 train_loss= 1.22406 val_loss= 1.65282 train_acc= 1.00000 val_acc= 0.65000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  28.787752628326416\n",
      "edge_vol 2658.756\n",
      "Epoch: 0111 train_loss= 1.22781 val_loss= 1.65314 train_acc= 1.00000 val_acc= 0.65000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  29.025718450546265\n",
      "edge_vol 2624.3408\n",
      "Epoch: 0112 train_loss= 1.21657 val_loss= 1.65345 train_acc= 1.00000 val_acc= 0.65000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  29.293149948120117\n",
      "edge_vol 2590.0032\n",
      "Epoch: 0113 train_loss= 1.21416 val_loss= 1.65375 train_acc= 1.00000 val_acc= 0.65000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  29.547661781311035\n",
      "edge_vol 2555.3315\n",
      "Epoch: 0114 train_loss= 1.21169 val_loss= 1.65414 train_acc= 1.00000 val_acc= 0.64600 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  29.807250499725342\n",
      "edge_vol 2519.9438\n",
      "Epoch: 0115 train_loss= 1.20504 val_loss= 1.65444 train_acc= 1.00000 val_acc= 0.64600 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  30.055691480636597\n",
      "edge_vol 2484.1455\n",
      "Epoch: 0116 train_loss= 1.21250 val_loss= 1.65455 train_acc= 1.00000 val_acc= 0.64200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  30.300061464309692\n",
      "edge_vol 2447.4692\n",
      "Epoch: 0117 train_loss= 1.19228 val_loss= 1.65458 train_acc= 1.00000 val_acc= 0.64400 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  30.54004216194153\n",
      "edge_vol 2410.2905\n",
      "Epoch: 0118 train_loss= 1.19578 val_loss= 1.65462 train_acc= 1.00000 val_acc= 0.64800 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  30.783194065093994\n",
      "edge_vol 2372.954\n",
      "Epoch: 0119 train_loss= 1.20629 val_loss= 1.65467 train_acc= 1.00000 val_acc= 0.65400 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  31.033764839172363\n",
      "edge_vol 2335.403\n",
      "Epoch: 0120 train_loss= 1.18366 val_loss= 1.65468 train_acc= 1.00000 val_acc= 0.65200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  31.28541350364685\n",
      "edge_vol 2297.673\n",
      "Epoch: 0121 train_loss= 1.17865 val_loss= 1.65451 train_acc= 1.00000 val_acc= 0.65000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  31.54463815689087\n",
      "edge_vol 2259.6008\n",
      "Epoch: 0122 train_loss= 1.17988 val_loss= 1.65444 train_acc= 1.00000 val_acc= 0.65000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  31.782390832901\n",
      "edge_vol 2221.4668\n",
      "Epoch: 0123 train_loss= 1.18344 val_loss= 1.65453 train_acc= 1.00000 val_acc= 0.64800 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  32.022167921066284\n",
      "edge_vol 2182.8042\n",
      "Epoch: 0124 train_loss= 1.17874 val_loss= 1.65467 train_acc= 1.00000 val_acc= 0.65000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  32.28226065635681\n",
      "edge_vol 2143.8657\n",
      "Epoch: 0125 train_loss= 1.17361 val_loss= 1.65483 train_acc= 1.00000 val_acc= 0.64800 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  32.53866171836853\n",
      "edge_vol 2104.5742\n",
      "Epoch: 0126 train_loss= 1.15852 val_loss= 1.65491 train_acc= 1.00000 val_acc= 0.65000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  32.78873658180237\n",
      "edge_vol 2065.2578\n",
      "Epoch: 0127 train_loss= 1.16594 val_loss= 1.65495 train_acc= 1.00000 val_acc= 0.65000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  33.03448224067688\n",
      "edge_vol 2025.7233\n",
      "Epoch: 0128 train_loss= 1.15868 val_loss= 1.65488 train_acc= 1.00000 val_acc= 0.65000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  33.27333164215088\n",
      "edge_vol 1986.2563\n",
      "Epoch: 0129 train_loss= 1.16791 val_loss= 1.65476 train_acc= 1.00000 val_acc= 0.64400 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  33.52454710006714\n",
      "edge_vol 1946.5952\n",
      "Epoch: 0130 train_loss= 1.15144 val_loss= 1.65473 train_acc= 1.00000 val_acc= 0.64400 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  33.77252793312073\n",
      "edge_vol 1906.7269\n",
      "Epoch: 0131 train_loss= 1.15720 val_loss= 1.65467 train_acc= 1.00000 val_acc= 0.64600 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  34.03722381591797\n",
      "edge_vol 1867.0858\n",
      "Epoch: 0132 train_loss= 1.14364 val_loss= 1.65465 train_acc= 1.00000 val_acc= 0.64800 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  34.30635595321655\n",
      "edge_vol 1828.0348\n",
      "Epoch: 0133 train_loss= 1.13987 val_loss= 1.65476 train_acc= 1.00000 val_acc= 0.64800 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  34.566349506378174\n",
      "edge_vol 1789.1597\n",
      "Epoch: 0134 train_loss= 1.14961 val_loss= 1.65496 train_acc= 1.00000 val_acc= 0.64800 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  34.82421350479126\n",
      "edge_vol 1750.6423\n",
      "Epoch: 0135 train_loss= 1.14038 val_loss= 1.65519 train_acc= 1.00000 val_acc= 0.64600 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  35.07473278045654\n",
      "edge_vol 1712.3342\n",
      "Epoch: 0136 train_loss= 1.13474 val_loss= 1.65547 train_acc= 1.00000 val_acc= 0.64200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  35.32042694091797\n",
      "edge_vol 1673.771\n",
      "Epoch: 0137 train_loss= 1.12406 val_loss= 1.65573 train_acc= 1.00000 val_acc= 0.64400 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  35.58349680900574\n",
      "edge_vol 1635.5098\n",
      "Epoch: 0138 train_loss= 1.12934 val_loss= 1.65612 train_acc= 1.00000 val_acc= 0.64200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  35.83819818496704\n",
      "edge_vol 1597.4564\n",
      "Epoch: 0139 train_loss= 1.13412 val_loss= 1.65642 train_acc= 1.00000 val_acc= 0.64200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  36.08534646034241\n",
      "edge_vol 1559.7457\n",
      "Epoch: 0140 train_loss= 1.11938 val_loss= 1.65674 train_acc= 1.00000 val_acc= 0.64200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  36.33723521232605\n",
      "edge_vol 1522.0776\n",
      "Epoch: 0141 train_loss= 1.11465 val_loss= 1.65700 train_acc= 1.00000 val_acc= 0.63800 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  36.584426403045654\n",
      "edge_vol 1484.4308\n",
      "Epoch: 0142 train_loss= 1.11350 val_loss= 1.65707 train_acc= 1.00000 val_acc= 0.63800 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  36.85012698173523\n",
      "edge_vol 1447.5002\n",
      "Epoch: 0143 train_loss= 1.11418 val_loss= 1.65700 train_acc= 1.00000 val_acc= 0.64000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  37.101484060287476\n",
      "edge_vol 1411.0956\n",
      "Epoch: 0144 train_loss= 1.10702 val_loss= 1.65682 train_acc= 1.00000 val_acc= 0.64000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  37.34331130981445\n",
      "edge_vol 1375.0186\n",
      "Epoch: 0145 train_loss= 1.09816 val_loss= 1.65647 train_acc= 1.00000 val_acc= 0.64000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  37.592655420303345\n",
      "edge_vol 1339.3743\n",
      "Epoch: 0146 train_loss= 1.09327 val_loss= 1.65594 train_acc= 1.00000 val_acc= 0.63600 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  37.83465361595154\n",
      "edge_vol 1304.5161\n",
      "Epoch: 0147 train_loss= 1.08827 val_loss= 1.65536 train_acc= 1.00000 val_acc= 0.63400 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  38.07864165306091\n",
      "edge_vol 1269.7334\n",
      "Epoch: 0148 train_loss= 1.08155 val_loss= 1.65467 train_acc= 1.00000 val_acc= 0.63400 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  38.329339027404785\n",
      "edge_vol 1235.177\n",
      "Epoch: 0149 train_loss= 1.07541 val_loss= 1.65400 train_acc= 1.00000 val_acc= 0.63800 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  38.58371353149414\n",
      "edge_vol 1200.7117\n",
      "Epoch: 0150 train_loss= 1.07114 val_loss= 1.65357 train_acc= 1.00000 val_acc= 0.64200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  38.83111047744751\n",
      "edge_vol 1167.1335\n",
      "Epoch: 0151 train_loss= 1.06325 val_loss= 1.65338 train_acc= 1.00000 val_acc= 0.64600 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  39.085853815078735\n",
      "edge_vol 1134.2249\n",
      "Epoch: 0152 train_loss= 1.05697 val_loss= 1.65296 train_acc= 1.00000 val_acc= 0.64400 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  39.353641986846924\n",
      "edge_vol 1102.019\n",
      "Epoch: 0153 train_loss= 1.04649 val_loss= 1.65254 train_acc= 1.00000 val_acc= 0.64400 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  39.600953340530396\n",
      "edge_vol 1070.241\n",
      "Epoch: 0154 train_loss= 1.04398 val_loss= 1.65206 train_acc= 1.00000 val_acc= 0.64000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  39.87345337867737\n",
      "edge_vol 1038.7538\n",
      "Epoch: 0155 train_loss= 1.04171 val_loss= 1.65151 train_acc= 1.00000 val_acc= 0.64800 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  40.13454341888428\n",
      "edge_vol 1007.7896\n",
      "Epoch: 0156 train_loss= 1.03153 val_loss= 1.65104 train_acc= 1.00000 val_acc= 0.64200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  40.38088369369507\n",
      "edge_vol 977.62964\n",
      "Epoch: 0157 train_loss= 1.02970 val_loss= 1.65056 train_acc= 1.00000 val_acc= 0.64200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  40.637598276138306\n",
      "edge_vol 947.90295\n",
      "Epoch: 0158 train_loss= 1.02801 val_loss= 1.65017 train_acc= 1.00000 val_acc= 0.63800 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  40.8904664516449\n",
      "edge_vol 918.7814\n",
      "Epoch: 0159 train_loss= 1.01243 val_loss= 1.64962 train_acc= 1.00000 val_acc= 0.63600 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  41.16598129272461\n",
      "edge_vol 890.17816\n",
      "Epoch: 0160 train_loss= 1.01041 val_loss= 1.64900 train_acc= 1.00000 val_acc= 0.62800 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  41.40923047065735\n",
      "edge_vol 862.0741\n",
      "Epoch: 0161 train_loss= 1.01009 val_loss= 1.64840 train_acc= 1.00000 val_acc= 0.63000 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  41.667837619781494\n",
      "edge_vol 834.7125\n",
      "Epoch: 0162 train_loss= 0.99255 val_loss= 1.64757 train_acc= 1.00000 val_acc= 0.62600 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  41.94353938102722\n",
      "edge_vol 807.78156\n",
      "Epoch: 0163 train_loss= 0.99545 val_loss= 1.64659 train_acc= 1.00000 val_acc= 0.62600 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "time  42.189290046691895\n",
      "edge_vol 781.636\n",
      "Epoch: 0164 train_loss= 0.97611 val_loss= 1.64575 train_acc= 1.00000 val_acc= 0.62200 best_val_acc_trail= 0.67600 test_acc= 0.66000\n",
      "Early stopping...\n"
     ]
    }
   ],
   "source": [
    "## PTDNet\n",
    "from config import *\n",
    "from utils import *\n",
    "from models import GCN, PTDNetGCN\n",
    "from metrics import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "# Settings\n",
    "args.dataset='pubmed'\n",
    "\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(args.dataset)\n",
    "adj=modified_adj\n",
    "all_labels = y_train + y_test+y_val\n",
    "single_label = np.argmax(all_labels,axis=-1)\n",
    "\n",
    "nodesize = features.shape[0]\n",
    "\n",
    "# Some preprocessing\n",
    "features = preprocess_features(features)\n",
    "support = preprocess_adj(adj)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "\n",
    "tuple_adj = sparse_to_tuple(adj.tocoo())\n",
    "features_tensor = tf.convert_to_tensor(features,dtype=dtype)\n",
    "adj_tensor = tf.SparseTensor(*tuple_adj)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train,dtype=dtype)\n",
    "train_mask_tensor = tf.convert_to_tensor(train_mask)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test,dtype=dtype)\n",
    "test_mask_tensor = tf.convert_to_tensor(test_mask)\n",
    "y_val_tensor = tf.convert_to_tensor(y_val,dtype=dtype)\n",
    "val_mask_tensor = tf.convert_to_tensor(val_mask)\n",
    "\n",
    "\n",
    "\n",
    "best_test_acc = 0\n",
    "best_val_acc_trail = 0\n",
    "best_val_loss = 10000\n",
    "import time\n",
    "begin = time.time()\n",
    "\n",
    "model = PTDNetGCN(input_dim=features.shape[1], output_dim=y_train.shape[1])\n",
    "model.set_fea_adj(np.array(range(adj.shape[0])), features_tensor, adj_tensor)\n",
    "\n",
    "best_epoch = 0\n",
    "curr_step = 0\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    temperature = max(0.05,args.init_temperature * pow(args.temperature_decay, epoch))\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = []\n",
    "        for l in range(args.outL):\n",
    "            output = model.call(temperature,training=True)\n",
    "            preds.append(tf.expand_dims(output,0))\n",
    "        all_preds = tf.concat(preds,axis=0)\n",
    "        mean_preds = tf.reduce_mean(preds,axis=0)\n",
    "        consistency_loss = tf.nn.l2_loss(mean_preds-all_preds)\n",
    "\n",
    "        cross_loss = masked_softmax_cross_entropy(mean_preds, y_train_tensor,train_mask_tensor)\n",
    "        lossL2 = tf.add_n([tf.nn.l2_loss(v) for v in model.trainable_variables])\n",
    "        lossl0 = model.lossl0(temperature)\n",
    "        #nuclear = model.my_nuclear()\n",
    "        nuclear = model.nuclear()\n",
    "        loss = cross_loss + args.weight_decay*lossL2 + args.lambda1*lossl0 + args.lambda3*nuclear + args.coff_consis*consistency_loss\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    output = model.call(None, training=False)\n",
    "    edges_volumn = tf.reduce_sum(model.maskes[0])\n",
    "    print('edge_vol',edges_volumn.numpy())\n",
    "\n",
    "    train_acc = masked_accuracy(output, y_train_tensor,train_mask_tensor)\n",
    "    val_acc  = masked_accuracy(output, y_val_tensor,val_mask_tensor)\n",
    "    val_loss = masked_softmax_cross_entropy(output, y_val_tensor, val_mask_tensor)\n",
    "    test_acc  = masked_accuracy(output, y_test_tensor,test_mask_tensor)\n",
    "    if val_acc > best_val_acc:\n",
    "        curr_step = 0\n",
    "        best_epoch = epoch\n",
    "        best_val_acc = val_acc\n",
    "        best_val_loss= val_loss\n",
    "        if val_acc>best_val_acc_trail:\n",
    "            best_test_acc = test_acc\n",
    "            best_val_acc_trail = val_acc\n",
    "    else:\n",
    "        curr_step +=1\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cross_loss),\"val_loss=\", \"{:.5f}\".format(val_loss),\n",
    "      \"train_acc=\", \"{:.5f}\".format(train_acc), \"val_acc=\", \"{:.5f}\".format(val_acc),\"best_val_acc_trail=\", \"{:.5f}\".format(best_val_acc_trail),\n",
    "      \"test_acc=\", \"{:.5f}\".format(best_test_acc))\n",
    "\n",
    "    if curr_step > args.early_stop:\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "    end = time.time()\n",
    "    print('time ',(end-begin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_vol 4705.077\n",
      "Epoch: 0001 train_loss= 1.79192 val_loss= 1.79123 train_acc= 0.30000 val_acc= 0.21400 best_val_acc_trail= 0.21400 test_acc= 0.18800\n",
      "time  2.0077571868896484\n",
      "edge_vol 4706.5605\n",
      "Epoch: 0002 train_loss= 1.79000 val_loss= 1.79062 train_acc= 0.50833 val_acc= 0.27600 best_val_acc_trail= 0.27600 test_acc= 0.24100\n",
      "time  2.452193260192871\n",
      "edge_vol 4703.255\n",
      "Epoch: 0003 train_loss= 1.78800 val_loss= 1.78999 train_acc= 0.66667 val_acc= 0.34200 best_val_acc_trail= 0.34200 test_acc= 0.30900\n",
      "time  2.862983226776123\n",
      "edge_vol 4697.424\n",
      "Epoch: 0004 train_loss= 1.78605 val_loss= 1.78932 train_acc= 0.73333 val_acc= 0.38200 best_val_acc_trail= 0.38200 test_acc= 0.37600\n",
      "time  3.267390012741089\n",
      "edge_vol 4690.1074\n",
      "Epoch: 0005 train_loss= 1.78404 val_loss= 1.78860 train_acc= 0.79167 val_acc= 0.44200 best_val_acc_trail= 0.44200 test_acc= 0.43500\n",
      "time  3.6743762493133545\n",
      "edge_vol 4681.6924\n",
      "Epoch: 0006 train_loss= 1.78192 val_loss= 1.78782 train_acc= 0.84167 val_acc= 0.48000 best_val_acc_trail= 0.48000 test_acc= 0.48500\n",
      "time  4.075523853302002\n",
      "edge_vol 4672.4185\n",
      "Epoch: 0007 train_loss= 1.77965 val_loss= 1.78695 train_acc= 0.85833 val_acc= 0.51600 best_val_acc_trail= 0.51600 test_acc= 0.51700\n",
      "time  4.476080417633057\n",
      "edge_vol 4662.3857\n",
      "Epoch: 0008 train_loss= 1.77749 val_loss= 1.78600 train_acc= 0.86667 val_acc= 0.52800 best_val_acc_trail= 0.52800 test_acc= 0.54200\n",
      "time  4.91294264793396\n",
      "edge_vol 4651.7153\n",
      "Epoch: 0009 train_loss= 1.77488 val_loss= 1.78496 train_acc= 0.86667 val_acc= 0.55400 best_val_acc_trail= 0.55400 test_acc= 0.55500\n",
      "time  5.3270673751831055\n",
      "edge_vol 4640.514\n",
      "Epoch: 0010 train_loss= 1.77219 val_loss= 1.78383 train_acc= 0.86667 val_acc= 0.56600 best_val_acc_trail= 0.56600 test_acc= 0.56800\n",
      "time  5.7424492835998535\n",
      "edge_vol 4628.8984\n",
      "Epoch: 0011 train_loss= 1.76929 val_loss= 1.78262 train_acc= 0.86667 val_acc= 0.57600 best_val_acc_trail= 0.57600 test_acc= 0.57800\n",
      "time  6.144280433654785\n",
      "edge_vol 4616.967\n",
      "Epoch: 0012 train_loss= 1.76653 val_loss= 1.78135 train_acc= 0.86667 val_acc= 0.58200 best_val_acc_trail= 0.58200 test_acc= 0.58200\n",
      "time  6.545758247375488\n",
      "edge_vol 4604.786\n",
      "Epoch: 0013 train_loss= 1.76336 val_loss= 1.78000 train_acc= 0.85833 val_acc= 0.59000 best_val_acc_trail= 0.59000 test_acc= 0.59100\n",
      "time  6.960108280181885\n",
      "edge_vol 4592.412\n",
      "Epoch: 0014 train_loss= 1.76002 val_loss= 1.77859 train_acc= 0.87500 val_acc= 0.59400 best_val_acc_trail= 0.59400 test_acc= 0.59400\n",
      "time  7.363079786300659\n",
      "edge_vol 4579.88\n",
      "Epoch: 0015 train_loss= 1.75643 val_loss= 1.77713 train_acc= 0.87500 val_acc= 0.59800 best_val_acc_trail= 0.59800 test_acc= 0.59800\n",
      "time  7.7934582233428955\n",
      "edge_vol 4567.1787\n",
      "Epoch: 0016 train_loss= 1.75310 val_loss= 1.77561 train_acc= 0.87500 val_acc= 0.59800 best_val_acc_trail= 0.59800 test_acc= 0.59800\n",
      "time  8.217015504837036\n",
      "edge_vol 4554.2935\n",
      "Epoch: 0017 train_loss= 1.74914 val_loss= 1.77405 train_acc= 0.87500 val_acc= 0.60000 best_val_acc_trail= 0.60000 test_acc= 0.61000\n",
      "time  8.643548965454102\n",
      "edge_vol 4541.183\n",
      "Epoch: 0018 train_loss= 1.74502 val_loss= 1.77242 train_acc= 0.87500 val_acc= 0.60200 best_val_acc_trail= 0.60200 test_acc= 0.61200\n",
      "time  9.047902345657349\n",
      "edge_vol 4527.9043\n",
      "Epoch: 0019 train_loss= 1.74106 val_loss= 1.77075 train_acc= 0.87500 val_acc= 0.61000 best_val_acc_trail= 0.61000 test_acc= 0.61300\n",
      "time  9.447772741317749\n",
      "edge_vol 4514.497\n",
      "Epoch: 0020 train_loss= 1.73689 val_loss= 1.76904 train_acc= 0.87500 val_acc= 0.61200 best_val_acc_trail= 0.61200 test_acc= 0.61600\n",
      "time  9.87279725074768\n",
      "edge_vol 4500.9824\n",
      "Epoch: 0021 train_loss= 1.73265 val_loss= 1.76730 train_acc= 0.87500 val_acc= 0.61200 best_val_acc_trail= 0.61200 test_acc= 0.61600\n",
      "time  10.281969547271729\n",
      "edge_vol 4487.3594\n",
      "Epoch: 0022 train_loss= 1.72811 val_loss= 1.76552 train_acc= 0.87500 val_acc= 0.61600 best_val_acc_trail= 0.61600 test_acc= 0.62000\n",
      "time  10.682838439941406\n",
      "edge_vol 4473.6865\n",
      "Epoch: 0023 train_loss= 1.72371 val_loss= 1.76371 train_acc= 0.87500 val_acc= 0.61800 best_val_acc_trail= 0.61800 test_acc= 0.62200\n",
      "time  11.085564613342285\n",
      "edge_vol 4459.8467\n",
      "Epoch: 0024 train_loss= 1.71807 val_loss= 1.76185 train_acc= 0.88333 val_acc= 0.62400 best_val_acc_trail= 0.62400 test_acc= 0.62100\n",
      "time  11.487833499908447\n",
      "edge_vol 4445.729\n",
      "Epoch: 0025 train_loss= 1.71278 val_loss= 1.75995 train_acc= 0.88333 val_acc= 0.62400 best_val_acc_trail= 0.62400 test_acc= 0.62100\n",
      "time  11.919765710830688\n",
      "edge_vol 4431.5\n",
      "Epoch: 0026 train_loss= 1.70866 val_loss= 1.75803 train_acc= 0.88333 val_acc= 0.62600 best_val_acc_trail= 0.62600 test_acc= 0.62200\n",
      "time  12.329144716262817\n",
      "edge_vol 4417.234\n",
      "Epoch: 0027 train_loss= 1.70327 val_loss= 1.75608 train_acc= 0.88333 val_acc= 0.62800 best_val_acc_trail= 0.62800 test_acc= 0.62300\n",
      "time  12.731139898300171\n",
      "edge_vol 4402.9077\n",
      "Epoch: 0028 train_loss= 1.69856 val_loss= 1.75410 train_acc= 0.88333 val_acc= 0.63200 best_val_acc_trail= 0.63200 test_acc= 0.62400\n",
      "time  13.132761240005493\n",
      "edge_vol 4388.607\n",
      "Epoch: 0029 train_loss= 1.69356 val_loss= 1.75210 train_acc= 0.88333 val_acc= 0.63200 best_val_acc_trail= 0.63200 test_acc= 0.62400\n",
      "time  13.53320574760437\n",
      "edge_vol 4374.268\n",
      "Epoch: 0030 train_loss= 1.68791 val_loss= 1.75009 train_acc= 0.88333 val_acc= 0.63200 best_val_acc_trail= 0.63200 test_acc= 0.62400\n",
      "time  13.940124750137329\n",
      "edge_vol 4359.6943\n",
      "Epoch: 0031 train_loss= 1.68200 val_loss= 1.74804 train_acc= 0.89167 val_acc= 0.63200 best_val_acc_trail= 0.63200 test_acc= 0.62400\n",
      "time  14.375902891159058\n",
      "edge_vol 4344.882\n",
      "Epoch: 0032 train_loss= 1.67652 val_loss= 1.74598 train_acc= 0.89167 val_acc= 0.63200 best_val_acc_trail= 0.63200 test_acc= 0.62400\n",
      "time  14.78972053527832\n",
      "edge_vol 4330.199\n",
      "Epoch: 0033 train_loss= 1.67283 val_loss= 1.74389 train_acc= 0.89167 val_acc= 0.63600 best_val_acc_trail= 0.63600 test_acc= 0.62700\n",
      "time  15.19243311882019\n",
      "edge_vol 4315.4893\n",
      "Epoch: 0034 train_loss= 1.66558 val_loss= 1.74177 train_acc= 0.89167 val_acc= 0.63400 best_val_acc_trail= 0.63600 test_acc= 0.62700\n",
      "time  15.59541940689087\n",
      "edge_vol 4300.435\n",
      "Epoch: 0035 train_loss= 1.65857 val_loss= 1.73964 train_acc= 0.89167 val_acc= 0.63400 best_val_acc_trail= 0.63600 test_acc= 0.62700\n",
      "time  16.006345748901367\n",
      "edge_vol 4285.3057\n",
      "Epoch: 0036 train_loss= 1.65387 val_loss= 1.73749 train_acc= 0.89167 val_acc= 0.63400 best_val_acc_trail= 0.63600 test_acc= 0.62700\n",
      "time  16.404253244400024\n",
      "edge_vol 4270.218\n",
      "Epoch: 0037 train_loss= 1.64865 val_loss= 1.73534 train_acc= 0.90000 val_acc= 0.63400 best_val_acc_trail= 0.63600 test_acc= 0.62700\n",
      "time  16.804452180862427\n",
      "edge_vol 4255.106\n",
      "Epoch: 0038 train_loss= 1.64163 val_loss= 1.73316 train_acc= 0.90000 val_acc= 0.63600 best_val_acc_trail= 0.63600 test_acc= 0.62700\n",
      "time  17.236427783966064\n",
      "edge_vol 4239.783\n",
      "Epoch: 0039 train_loss= 1.63547 val_loss= 1.73093 train_acc= 0.90833 val_acc= 0.63800 best_val_acc_trail= 0.63800 test_acc= 0.62800\n",
      "time  17.63735294342041\n",
      "edge_vol 4224.268\n",
      "Epoch: 0040 train_loss= 1.63012 val_loss= 1.72870 train_acc= 0.90833 val_acc= 0.63800 best_val_acc_trail= 0.63800 test_acc= 0.62800\n",
      "time  18.078925371170044\n",
      "edge_vol 4208.953\n",
      "Epoch: 0041 train_loss= 1.62288 val_loss= 1.72647 train_acc= 0.90833 val_acc= 0.63800 best_val_acc_trail= 0.63800 test_acc= 0.62800\n",
      "time  18.49229621887207\n",
      "edge_vol 4193.6416\n",
      "Epoch: 0042 train_loss= 1.61607 val_loss= 1.72424 train_acc= 0.90833 val_acc= 0.64200 best_val_acc_trail= 0.64200 test_acc= 0.63400\n",
      "time  18.89529538154602\n",
      "edge_vol 4178.3633\n",
      "Epoch: 0043 train_loss= 1.61231 val_loss= 1.72201 train_acc= 0.91667 val_acc= 0.64400 best_val_acc_trail= 0.64400 test_acc= 0.63700\n",
      "time  19.294710636138916\n",
      "edge_vol 4163.1943\n",
      "Epoch: 0044 train_loss= 1.60599 val_loss= 1.71977 train_acc= 0.91667 val_acc= 0.64200 best_val_acc_trail= 0.64400 test_acc= 0.63700\n",
      "time  19.695532083511353\n",
      "edge_vol 4148.136\n",
      "Epoch: 0045 train_loss= 1.60026 val_loss= 1.71757 train_acc= 0.91667 val_acc= 0.64000 best_val_acc_trail= 0.64400 test_acc= 0.63700\n",
      "time  20.1270854473114\n",
      "edge_vol 4133.3022\n",
      "Epoch: 0046 train_loss= 1.59281 val_loss= 1.71536 train_acc= 0.91667 val_acc= 0.64000 best_val_acc_trail= 0.64400 test_acc= 0.63700\n",
      "time  20.534977912902832\n",
      "edge_vol 4118.444\n",
      "Epoch: 0047 train_loss= 1.58340 val_loss= 1.71314 train_acc= 0.92500 val_acc= 0.64200 best_val_acc_trail= 0.64400 test_acc= 0.63700\n",
      "time  20.9354031085968\n",
      "edge_vol 4104.027\n",
      "Epoch: 0048 train_loss= 1.58096 val_loss= 1.71092 train_acc= 0.93333 val_acc= 0.64600 best_val_acc_trail= 0.64600 test_acc= 0.63800\n",
      "time  21.386111974716187\n",
      "edge_vol 4089.6846\n",
      "Epoch: 0049 train_loss= 1.57375 val_loss= 1.70871 train_acc= 0.93333 val_acc= 0.65000 best_val_acc_trail= 0.65000 test_acc= 0.64200\n",
      "time  21.790262937545776\n",
      "edge_vol 4075.1611\n",
      "Epoch: 0050 train_loss= 1.56775 val_loss= 1.70650 train_acc= 0.93333 val_acc= 0.65000 best_val_acc_trail= 0.65000 test_acc= 0.64200\n",
      "time  22.197266578674316\n",
      "edge_vol 4061.4006\n",
      "Epoch: 0051 train_loss= 1.55978 val_loss= 1.70429 train_acc= 0.93333 val_acc= 0.65000 best_val_acc_trail= 0.65000 test_acc= 0.64200\n",
      "time  22.59850573539734\n",
      "edge_vol 4047.5068\n",
      "Epoch: 0052 train_loss= 1.55416 val_loss= 1.70212 train_acc= 0.93333 val_acc= 0.65000 best_val_acc_trail= 0.65000 test_acc= 0.64200\n",
      "time  23.001864671707153\n",
      "edge_vol 4034.3027\n",
      "Epoch: 0053 train_loss= 1.54824 val_loss= 1.69994 train_acc= 0.95000 val_acc= 0.65200 best_val_acc_trail= 0.65200 test_acc= 0.64200\n",
      "time  23.412380695343018\n",
      "edge_vol 4020.71\n",
      "Epoch: 0054 train_loss= 1.54086 val_loss= 1.69781 train_acc= 0.95000 val_acc= 0.65200 best_val_acc_trail= 0.65200 test_acc= 0.64200\n",
      "time  23.837396144866943\n",
      "edge_vol 4007.666\n",
      "Epoch: 0055 train_loss= 1.53601 val_loss= 1.69568 train_acc= 0.95000 val_acc= 0.65200 best_val_acc_trail= 0.65200 test_acc= 0.64200\n",
      "time  24.242619037628174\n",
      "edge_vol 3995.3232\n",
      "Epoch: 0056 train_loss= 1.52833 val_loss= 1.69355 train_acc= 0.95000 val_acc= 0.65400 best_val_acc_trail= 0.65400 test_acc= 0.64600\n",
      "time  24.65202498435974\n",
      "edge_vol 3983.309\n",
      "Epoch: 0057 train_loss= 1.52216 val_loss= 1.69143 train_acc= 0.95000 val_acc= 0.65600 best_val_acc_trail= 0.65600 test_acc= 0.64600\n",
      "time  25.154845476150513\n",
      "edge_vol 3972.177\n",
      "Epoch: 0058 train_loss= 1.51529 val_loss= 1.68932 train_acc= 0.95000 val_acc= 0.66000 best_val_acc_trail= 0.66000 test_acc= 0.64700\n",
      "time  25.551927089691162\n",
      "edge_vol 3960.7915\n",
      "Epoch: 0059 train_loss= 1.51026 val_loss= 1.68728 train_acc= 0.95000 val_acc= 0.66400 best_val_acc_trail= 0.66400 test_acc= 0.64700\n",
      "time  25.96767544746399\n",
      "edge_vol 3949.7363\n",
      "Epoch: 0060 train_loss= 1.50275 val_loss= 1.68531 train_acc= 0.95000 val_acc= 0.66600 best_val_acc_trail= 0.66600 test_acc= 0.64800\n",
      "time  26.367791414260864\n",
      "edge_vol 3939.133\n",
      "Epoch: 0061 train_loss= 1.49908 val_loss= 1.68341 train_acc= 0.95833 val_acc= 0.66600 best_val_acc_trail= 0.66600 test_acc= 0.64800\n",
      "time  26.77014970779419\n",
      "edge_vol 3930.3074\n",
      "Epoch: 0062 train_loss= 1.49289 val_loss= 1.68157 train_acc= 0.95833 val_acc= 0.66800 best_val_acc_trail= 0.66800 test_acc= 0.65100\n",
      "time  27.170628786087036\n",
      "edge_vol 3921.4253\n",
      "Epoch: 0063 train_loss= 1.48316 val_loss= 1.67978 train_acc= 0.96667 val_acc= 0.66600 best_val_acc_trail= 0.66800 test_acc= 0.65100\n",
      "time  27.577544927597046\n",
      "edge_vol 3912.7114\n",
      "Epoch: 0064 train_loss= 1.47950 val_loss= 1.67801 train_acc= 0.96667 val_acc= 0.66600 best_val_acc_trail= 0.66800 test_acc= 0.65100\n",
      "time  27.978870391845703\n",
      "edge_vol 3903.2183\n",
      "Epoch: 0065 train_loss= 1.47581 val_loss= 1.67628 train_acc= 0.96667 val_acc= 0.66400 best_val_acc_trail= 0.66800 test_acc= 0.65100\n",
      "time  28.38098406791687\n",
      "edge_vol 3896.2383\n",
      "Epoch: 0066 train_loss= 1.46329 val_loss= 1.67453 train_acc= 0.96667 val_acc= 0.66200 best_val_acc_trail= 0.66800 test_acc= 0.65100\n",
      "time  28.783477067947388\n",
      "edge_vol 3893.2527\n",
      "Epoch: 0067 train_loss= 1.46376 val_loss= 1.67286 train_acc= 0.96667 val_acc= 0.66600 best_val_acc_trail= 0.66800 test_acc= 0.65100\n",
      "time  29.189247369766235\n",
      "edge_vol 3892.2778\n",
      "Epoch: 0068 train_loss= 1.45257 val_loss= 1.67117 train_acc= 0.96667 val_acc= 0.66800 best_val_acc_trail= 0.66800 test_acc= 0.65500\n",
      "time  29.652472496032715\n",
      "edge_vol 3893.4514\n",
      "Epoch: 0069 train_loss= 1.45056 val_loss= 1.66953 train_acc= 0.96667 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  30.09844994544983\n",
      "edge_vol 3895.7266\n",
      "Epoch: 0070 train_loss= 1.44670 val_loss= 1.66791 train_acc= 0.96667 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  30.499779224395752\n",
      "edge_vol 3901.0151\n",
      "Epoch: 0071 train_loss= 1.43729 val_loss= 1.66637 train_acc= 0.96667 val_acc= 0.66800 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  30.899535417556763\n",
      "edge_vol 3909.8516\n",
      "Epoch: 0072 train_loss= 1.43685 val_loss= 1.66486 train_acc= 0.96667 val_acc= 0.66600 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  31.30500602722168\n",
      "edge_vol 3921.849\n",
      "Epoch: 0073 train_loss= 1.43084 val_loss= 1.66341 train_acc= 0.96667 val_acc= 0.66800 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  31.726361989974976\n",
      "edge_vol 3934.5542\n",
      "Epoch: 0074 train_loss= 1.42116 val_loss= 1.66198 train_acc= 0.96667 val_acc= 0.66600 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  32.16620326042175\n",
      "edge_vol 3946.7742\n",
      "Epoch: 0075 train_loss= 1.41731 val_loss= 1.66054 train_acc= 0.96667 val_acc= 0.66600 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  32.56683111190796\n",
      "edge_vol 3961.5645\n",
      "Epoch: 0076 train_loss= 1.41345 val_loss= 1.65918 train_acc= 0.96667 val_acc= 0.66400 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  32.96539759635925\n",
      "edge_vol 3976.473\n",
      "Epoch: 0077 train_loss= 1.40846 val_loss= 1.65792 train_acc= 0.96667 val_acc= 0.66600 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  33.36662411689758\n",
      "edge_vol 3993.0278\n",
      "Epoch: 0078 train_loss= 1.40553 val_loss= 1.65678 train_acc= 0.96667 val_acc= 0.66800 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  33.766621589660645\n",
      "edge_vol 4011.8008\n",
      "Epoch: 0079 train_loss= 1.39913 val_loss= 1.65568 train_acc= 0.95833 val_acc= 0.66800 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  34.170685052871704\n",
      "edge_vol 4032.181\n",
      "Epoch: 0080 train_loss= 1.39233 val_loss= 1.65472 train_acc= 0.95833 val_acc= 0.66800 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  34.60806679725647\n",
      "edge_vol 4053.91\n",
      "Epoch: 0081 train_loss= 1.39481 val_loss= 1.65378 train_acc= 0.95833 val_acc= 0.66600 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  35.02783489227295\n",
      "edge_vol 4076.9712\n",
      "Epoch: 0082 train_loss= 1.39026 val_loss= 1.65282 train_acc= 0.95833 val_acc= 0.66600 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  35.431532859802246\n",
      "edge_vol 4100.8145\n",
      "Epoch: 0083 train_loss= 1.38256 val_loss= 1.65194 train_acc= 0.95833 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  35.841572523117065\n",
      "edge_vol 4126.518\n",
      "Epoch: 0084 train_loss= 1.37609 val_loss= 1.65111 train_acc= 0.95833 val_acc= 0.66800 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  36.24500298500061\n",
      "edge_vol 4152.993\n",
      "Epoch: 0085 train_loss= 1.37594 val_loss= 1.65028 train_acc= 0.95833 val_acc= 0.66600 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  36.64476251602173\n",
      "edge_vol 4179.7593\n",
      "Epoch: 0086 train_loss= 1.37453 val_loss= 1.64950 train_acc= 0.95833 val_acc= 0.66400 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  37.04306364059448\n",
      "edge_vol 4207.5615\n",
      "Epoch: 0087 train_loss= 1.36773 val_loss= 1.64879 train_acc= 0.95833 val_acc= 0.66600 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  37.45036029815674\n",
      "edge_vol 4236.105\n",
      "Epoch: 0088 train_loss= 1.36770 val_loss= 1.64809 train_acc= 0.95833 val_acc= 0.66400 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  37.84650492668152\n",
      "edge_vol 4265.0337\n",
      "Epoch: 0089 train_loss= 1.36572 val_loss= 1.64748 train_acc= 0.95833 val_acc= 0.66400 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  38.290072202682495\n",
      "edge_vol 4294.508\n",
      "Epoch: 0090 train_loss= 1.35865 val_loss= 1.64692 train_acc= 0.95000 val_acc= 0.66400 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  38.71062755584717\n",
      "edge_vol 4324.1426\n",
      "Epoch: 0091 train_loss= 1.35791 val_loss= 1.64641 train_acc= 0.95000 val_acc= 0.66400 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  39.11928987503052\n",
      "edge_vol 4353.88\n",
      "Epoch: 0092 train_loss= 1.35593 val_loss= 1.64591 train_acc= 0.95000 val_acc= 0.66400 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  39.51829123497009\n",
      "edge_vol 4383.5513\n",
      "Epoch: 0093 train_loss= 1.34635 val_loss= 1.64539 train_acc= 0.95000 val_acc= 0.66600 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  39.972312927246094\n",
      "edge_vol 4412.878\n",
      "Epoch: 0094 train_loss= 1.35004 val_loss= 1.64486 train_acc= 0.95000 val_acc= 0.66600 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  40.408183097839355\n",
      "edge_vol 4441.1455\n",
      "Epoch: 0095 train_loss= 1.33542 val_loss= 1.64434 train_acc= 0.95000 val_acc= 0.66600 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  40.85375952720642\n",
      "edge_vol 4469.7637\n",
      "Epoch: 0096 train_loss= 1.33814 val_loss= 1.64386 train_acc= 0.95000 val_acc= 0.66400 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  41.327181339263916\n",
      "edge_vol 4498.2715\n",
      "Epoch: 0097 train_loss= 1.33359 val_loss= 1.64332 train_acc= 0.95000 val_acc= 0.66800 best_val_acc_trail= 0.67000 test_acc= 0.65300\n",
      "time  41.74996495246887\n",
      "edge_vol 4527.293\n",
      "Epoch: 0098 train_loss= 1.32819 val_loss= 1.64281 train_acc= 0.95000 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.64900\n",
      "time  42.18253517150879\n",
      "edge_vol 4556.949\n",
      "Epoch: 0099 train_loss= 1.32759 val_loss= 1.64224 train_acc= 0.95000 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.64900\n",
      "time  42.61996150016785\n",
      "edge_vol 4586.623\n",
      "Epoch: 0100 train_loss= 1.32961 val_loss= 1.64171 train_acc= 0.95000 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.64900\n",
      "time  43.06599235534668\n",
      "edge_vol 4616.345\n",
      "Epoch: 0101 train_loss= 1.32248 val_loss= 1.64121 train_acc= 0.95000 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.64900\n",
      "time  43.5090708732605\n",
      "edge_vol 4645.422\n",
      "Epoch: 0102 train_loss= 1.31861 val_loss= 1.64066 train_acc= 0.95000 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.64900\n",
      "time  43.94229483604431\n",
      "edge_vol 4674.9023\n",
      "Epoch: 0103 train_loss= 1.31633 val_loss= 1.64018 train_acc= 0.95000 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.64900\n",
      "time  44.3726909160614\n",
      "edge_vol 4704.9424\n",
      "Epoch: 0104 train_loss= 1.31550 val_loss= 1.63970 train_acc= 0.95000 val_acc= 0.66600 best_val_acc_trail= 0.67000 test_acc= 0.64900\n",
      "time  44.79366970062256\n",
      "edge_vol 4735.368\n",
      "Epoch: 0105 train_loss= 1.31975 val_loss= 1.63924 train_acc= 0.95833 val_acc= 0.66600 best_val_acc_trail= 0.67000 test_acc= 0.64900\n",
      "time  45.22012162208557\n",
      "edge_vol 4766.09\n",
      "Epoch: 0106 train_loss= 1.30489 val_loss= 1.63878 train_acc= 0.95833 val_acc= 0.66600 best_val_acc_trail= 0.67000 test_acc= 0.64900\n",
      "time  45.64466691017151\n",
      "edge_vol 4797.162\n",
      "Epoch: 0107 train_loss= 1.30523 val_loss= 1.63825 train_acc= 0.95833 val_acc= 0.66600 best_val_acc_trail= 0.67000 test_acc= 0.64900\n",
      "time  46.05097770690918\n",
      "edge_vol 4828.294\n",
      "Epoch: 0108 train_loss= 1.30805 val_loss= 1.63768 train_acc= 0.95833 val_acc= 0.66600 best_val_acc_trail= 0.67000 test_acc= 0.64900\n",
      "time  46.44993615150452\n",
      "edge_vol 4860.123\n",
      "Epoch: 0109 train_loss= 1.30311 val_loss= 1.63707 train_acc= 0.95833 val_acc= 0.66600 best_val_acc_trail= 0.67000 test_acc= 0.64900\n",
      "time  46.884795904159546\n",
      "edge_vol 4892.226\n",
      "Epoch: 0110 train_loss= 1.30012 val_loss= 1.63647 train_acc= 0.95833 val_acc= 0.66800 best_val_acc_trail= 0.67000 test_acc= 0.64900\n",
      "time  47.311954736709595\n",
      "edge_vol 4924.055\n",
      "Epoch: 0111 train_loss= 1.29753 val_loss= 1.63586 train_acc= 0.95833 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.64900\n",
      "time  47.734493255615234\n",
      "edge_vol 4956.209\n",
      "Epoch: 0112 train_loss= 1.29347 val_loss= 1.63519 train_acc= 0.95833 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.64900\n",
      "time  48.16584897041321\n",
      "edge_vol 4987.0127\n",
      "Epoch: 0113 train_loss= 1.29555 val_loss= 1.63458 train_acc= 0.95833 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.64900\n",
      "time  48.61022472381592\n",
      "edge_vol 5015.8364\n",
      "Epoch: 0114 train_loss= 1.28312 val_loss= 1.63397 train_acc= 0.95833 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.64900\n",
      "time  49.11308789253235\n",
      "edge_vol 5041.1646\n",
      "Epoch: 0115 train_loss= 1.29159 val_loss= 1.63336 train_acc= 0.95000 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.64900\n",
      "time  49.5749249458313\n",
      "edge_vol 5063.2427\n",
      "Epoch: 0116 train_loss= 1.28141 val_loss= 1.63268 train_acc= 0.95000 val_acc= 0.67200 best_val_acc_trail= 0.67200 test_acc= 0.64200\n",
      "time  49.97997856140137\n",
      "edge_vol 5083.3154\n",
      "Epoch: 0117 train_loss= 1.28203 val_loss= 1.63211 train_acc= 0.95000 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  50.38467335700989\n",
      "edge_vol 5103.2095\n",
      "Epoch: 0118 train_loss= 1.27679 val_loss= 1.63143 train_acc= 0.95000 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  50.80751371383667\n",
      "edge_vol 5123.2188\n",
      "Epoch: 0119 train_loss= 1.27680 val_loss= 1.63069 train_acc= 0.95000 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  51.23267984390259\n",
      "edge_vol 5143.779\n",
      "Epoch: 0120 train_loss= 1.27920 val_loss= 1.63004 train_acc= 0.95000 val_acc= 0.67000 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  51.65259909629822\n",
      "edge_vol 5164.394\n",
      "Epoch: 0121 train_loss= 1.27316 val_loss= 1.62937 train_acc= 0.95000 val_acc= 0.66600 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  52.049962759017944\n",
      "edge_vol 5185.371\n",
      "Epoch: 0122 train_loss= 1.26784 val_loss= 1.62857 train_acc= 0.95000 val_acc= 0.66400 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  52.48103475570679\n",
      "edge_vol 5206.644\n",
      "Epoch: 0123 train_loss= 1.27185 val_loss= 1.62776 train_acc= 0.95000 val_acc= 0.66600 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  52.88803029060364\n",
      "edge_vol 5228.1675\n",
      "Epoch: 0124 train_loss= 1.26585 val_loss= 1.62680 train_acc= 0.95000 val_acc= 0.67000 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  53.296873569488525\n",
      "edge_vol 5250.189\n",
      "Epoch: 0125 train_loss= 1.26008 val_loss= 1.62579 train_acc= 0.95000 val_acc= 0.67000 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  53.7048773765564\n",
      "edge_vol 5272.492\n",
      "Epoch: 0126 train_loss= 1.25753 val_loss= 1.62482 train_acc= 0.95000 val_acc= 0.67000 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  54.108662843704224\n",
      "edge_vol 5295.247\n",
      "Epoch: 0127 train_loss= 1.25522 val_loss= 1.62381 train_acc= 0.95000 val_acc= 0.66800 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  54.5070743560791\n",
      "edge_vol 5317.879\n",
      "Epoch: 0128 train_loss= 1.25087 val_loss= 1.62263 train_acc= 0.95000 val_acc= 0.66600 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  54.91226887702942\n",
      "edge_vol 5340.6104\n",
      "Epoch: 0129 train_loss= 1.24883 val_loss= 1.62137 train_acc= 0.95000 val_acc= 0.66600 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  55.310171127319336\n",
      "edge_vol 5363.8257\n",
      "Epoch: 0130 train_loss= 1.24709 val_loss= 1.61998 train_acc= 0.94167 val_acc= 0.66600 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  55.71644377708435\n",
      "edge_vol 5387.4185\n",
      "Epoch: 0131 train_loss= 1.24702 val_loss= 1.61852 train_acc= 0.94167 val_acc= 0.66600 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  56.11694288253784\n",
      "edge_vol 5411.365\n",
      "Epoch: 0132 train_loss= 1.23936 val_loss= 1.61702 train_acc= 0.94167 val_acc= 0.66600 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  56.545130252838135\n",
      "edge_vol 5435.633\n",
      "Epoch: 0133 train_loss= 1.23755 val_loss= 1.61541 train_acc= 0.94167 val_acc= 0.66800 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  56.99091672897339\n",
      "edge_vol 5460.288\n",
      "Epoch: 0134 train_loss= 1.23621 val_loss= 1.61377 train_acc= 0.94167 val_acc= 0.66800 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  57.39511013031006\n",
      "edge_vol 5485.2896\n",
      "Epoch: 0135 train_loss= 1.22879 val_loss= 1.61200 train_acc= 0.95000 val_acc= 0.66800 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  57.79120373725891\n",
      "edge_vol 5510.545\n",
      "Epoch: 0136 train_loss= 1.22124 val_loss= 1.61012 train_acc= 0.95000 val_acc= 0.66600 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  58.188233375549316\n",
      "edge_vol 5535.841\n",
      "Epoch: 0137 train_loss= 1.21665 val_loss= 1.60808 train_acc= 0.95000 val_acc= 0.66600 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  58.58684515953064\n",
      "edge_vol 5560.9946\n",
      "Epoch: 0138 train_loss= 1.21414 val_loss= 1.60598 train_acc= 0.95000 val_acc= 0.66600 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  59.01844120025635\n",
      "edge_vol 5586.3945\n",
      "Epoch: 0139 train_loss= 1.21469 val_loss= 1.60389 train_acc= 0.95000 val_acc= 0.66600 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  59.41567826271057\n",
      "edge_vol 5611.852\n",
      "Epoch: 0140 train_loss= 1.20850 val_loss= 1.60172 train_acc= 0.95000 val_acc= 0.66600 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  59.815150022506714\n",
      "edge_vol 5637.7314\n",
      "Epoch: 0141 train_loss= 1.20409 val_loss= 1.59945 train_acc= 0.95000 val_acc= 0.66600 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  60.240044593811035\n",
      "edge_vol 5663.7573\n",
      "Epoch: 0142 train_loss= 1.19732 val_loss= 1.59711 train_acc= 0.95000 val_acc= 0.66600 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  60.65829253196716\n",
      "edge_vol 5689.919\n",
      "Epoch: 0143 train_loss= 1.19085 val_loss= 1.59472 train_acc= 0.95000 val_acc= 0.66600 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  61.06189775466919\n",
      "edge_vol 5716.588\n",
      "Epoch: 0144 train_loss= 1.19583 val_loss= 1.59234 train_acc= 0.95000 val_acc= 0.66200 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  61.457820892333984\n",
      "edge_vol 5743.586\n",
      "Epoch: 0145 train_loss= 1.18595 val_loss= 1.58993 train_acc= 0.95000 val_acc= 0.66400 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  61.85456585884094\n",
      "edge_vol 5771.4683\n",
      "Epoch: 0146 train_loss= 1.18515 val_loss= 1.58745 train_acc= 0.95000 val_acc= 0.67000 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  62.25109386444092\n",
      "edge_vol 5799.9243\n",
      "Epoch: 0147 train_loss= 1.17613 val_loss= 1.58498 train_acc= 0.94167 val_acc= 0.66600 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  62.65701699256897\n",
      "edge_vol 5828.4473\n",
      "Epoch: 0148 train_loss= 1.16701 val_loss= 1.58244 train_acc= 0.94167 val_acc= 0.66400 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  63.061742544174194\n",
      "edge_vol 5857.2285\n",
      "Epoch: 0149 train_loss= 1.16483 val_loss= 1.57988 train_acc= 0.94167 val_acc= 0.66600 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  63.46617245674133\n",
      "edge_vol 5886.6836\n",
      "Epoch: 0150 train_loss= 1.16090 val_loss= 1.57726 train_acc= 0.94167 val_acc= 0.66600 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  63.93802809715271\n",
      "edge_vol 5916.883\n",
      "Epoch: 0151 train_loss= 1.15761 val_loss= 1.57460 train_acc= 0.94167 val_acc= 0.66800 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  64.35074162483215\n",
      "edge_vol 5947.439\n",
      "Epoch: 0152 train_loss= 1.15540 val_loss= 1.57186 train_acc= 0.94167 val_acc= 0.66800 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  64.75555896759033\n",
      "edge_vol 5978.8135\n",
      "Epoch: 0153 train_loss= 1.14463 val_loss= 1.56920 train_acc= 0.94167 val_acc= 0.66800 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  65.15347027778625\n",
      "edge_vol 6010.6963\n",
      "Epoch: 0154 train_loss= 1.14179 val_loss= 1.56657 train_acc= 0.94167 val_acc= 0.67200 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  65.55765151977539\n",
      "edge_vol 6043.3125\n",
      "Epoch: 0155 train_loss= 1.13916 val_loss= 1.56400 train_acc= 0.95000 val_acc= 0.67000 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  66.0223376750946\n",
      "edge_vol 6075.998\n",
      "Epoch: 0156 train_loss= 1.12717 val_loss= 1.56140 train_acc= 0.95000 val_acc= 0.67000 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  66.43906426429749\n",
      "edge_vol 6108.8496\n",
      "Epoch: 0157 train_loss= 1.12800 val_loss= 1.55884 train_acc= 0.95000 val_acc= 0.67000 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  66.83765411376953\n",
      "edge_vol 6141.705\n",
      "Epoch: 0158 train_loss= 1.12052 val_loss= 1.55614 train_acc= 0.95000 val_acc= 0.67000 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  67.24000144004822\n",
      "edge_vol 6175.51\n",
      "Epoch: 0159 train_loss= 1.11777 val_loss= 1.55352 train_acc= 0.95000 val_acc= 0.67200 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  67.65274810791016\n",
      "edge_vol 6208.839\n",
      "Epoch: 0160 train_loss= 1.11359 val_loss= 1.55092 train_acc= 0.95000 val_acc= 0.67200 best_val_acc_trail= 0.67400 test_acc= 0.64300\n",
      "time  68.05975985527039\n",
      "edge_vol 6242.743\n",
      "Epoch: 0161 train_loss= 1.10854 val_loss= 1.54834 train_acc= 0.95000 val_acc= 0.67600 best_val_acc_trail= 0.67600 test_acc= 0.66200\n",
      "time  68.46510434150696\n",
      "edge_vol 6277.258\n",
      "Epoch: 0162 train_loss= 1.10585 val_loss= 1.54589 train_acc= 0.95000 val_acc= 0.67800 best_val_acc_trail= 0.67800 test_acc= 0.66200\n",
      "time  68.86658525466919\n",
      "edge_vol 6311.8564\n",
      "Epoch: 0163 train_loss= 1.09964 val_loss= 1.54350 train_acc= 0.95000 val_acc= 0.67400 best_val_acc_trail= 0.67800 test_acc= 0.66200\n",
      "time  69.26578259468079\n",
      "edge_vol 6347.039\n",
      "Epoch: 0164 train_loss= 1.09704 val_loss= 1.54121 train_acc= 0.95000 val_acc= 0.67400 best_val_acc_trail= 0.67800 test_acc= 0.66200\n",
      "time  69.68891644477844\n",
      "edge_vol 6382.4614\n",
      "Epoch: 0165 train_loss= 1.09121 val_loss= 1.53901 train_acc= 0.95833 val_acc= 0.67400 best_val_acc_trail= 0.67800 test_acc= 0.66200\n",
      "time  70.11757898330688\n",
      "edge_vol 6418.3555\n",
      "Epoch: 0166 train_loss= 1.08732 val_loss= 1.53681 train_acc= 0.95833 val_acc= 0.67600 best_val_acc_trail= 0.67800 test_acc= 0.66200\n",
      "time  70.51852321624756\n",
      "edge_vol 6454.6846\n",
      "Epoch: 0167 train_loss= 1.08134 val_loss= 1.53461 train_acc= 0.95833 val_acc= 0.67600 best_val_acc_trail= 0.67800 test_acc= 0.66200\n",
      "time  70.91628003120422\n",
      "edge_vol 6491.229\n",
      "Epoch: 0168 train_loss= 1.08051 val_loss= 1.53243 train_acc= 0.95833 val_acc= 0.67400 best_val_acc_trail= 0.67800 test_acc= 0.66200\n",
      "time  71.32347559928894\n",
      "edge_vol 6527.6465\n",
      "Epoch: 0169 train_loss= 1.07318 val_loss= 1.53022 train_acc= 0.95833 val_acc= 0.67600 best_val_acc_trail= 0.67800 test_acc= 0.66200\n",
      "time  71.73116850852966\n",
      "edge_vol 6563.9395\n",
      "Epoch: 0170 train_loss= 1.07271 val_loss= 1.52796 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.67800 test_acc= 0.66500\n",
      "time  72.13738870620728\n",
      "edge_vol 6600.545\n",
      "Epoch: 0171 train_loss= 1.06735 val_loss= 1.52571 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.67800 test_acc= 0.66500\n",
      "time  72.55046796798706\n",
      "edge_vol 6637.626\n",
      "Epoch: 0172 train_loss= 1.06081 val_loss= 1.52344 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68000 test_acc= 0.66900\n",
      "time  72.94978427886963\n",
      "edge_vol 6674.973\n",
      "Epoch: 0173 train_loss= 1.06081 val_loss= 1.52139 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.68000 test_acc= 0.66900\n",
      "time  73.3481171131134\n",
      "edge_vol 6712.217\n",
      "Epoch: 0174 train_loss= 1.05591 val_loss= 1.51932 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.68000 test_acc= 0.66900\n",
      "time  73.74976968765259\n",
      "edge_vol 6749.761\n",
      "Epoch: 0175 train_loss= 1.05594 val_loss= 1.51734 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.68000 test_acc= 0.66900\n",
      "time  74.27241444587708\n",
      "edge_vol 6787.3945\n",
      "Epoch: 0176 train_loss= 1.04675 val_loss= 1.51549 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.68000 test_acc= 0.66900\n",
      "time  74.69252586364746\n",
      "edge_vol 6824.8843\n",
      "Epoch: 0177 train_loss= 1.04417 val_loss= 1.51376 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68000 test_acc= 0.66800\n",
      "time  75.10500764846802\n",
      "edge_vol 6862.2773\n",
      "Epoch: 0178 train_loss= 1.04246 val_loss= 1.51195 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68000 test_acc= 0.66800\n",
      "time  75.54897475242615\n",
      "edge_vol 6900.0264\n",
      "Epoch: 0179 train_loss= 1.04252 val_loss= 1.51040 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68000 test_acc= 0.66800\n",
      "time  75.96436810493469\n",
      "edge_vol 6938.327\n",
      "Epoch: 0180 train_loss= 1.03599 val_loss= 1.50901 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.68000 test_acc= 0.66800\n",
      "time  76.37150025367737\n",
      "edge_vol 6976.7656\n",
      "Epoch: 0181 train_loss= 1.03486 val_loss= 1.50764 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.68000 test_acc= 0.66800\n",
      "time  76.77361226081848\n",
      "edge_vol 7014.867\n",
      "Epoch: 0182 train_loss= 1.03134 val_loss= 1.50635 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.68000 test_acc= 0.66800\n",
      "time  77.17073917388916\n",
      "edge_vol 7052.684\n",
      "Epoch: 0183 train_loss= 1.02741 val_loss= 1.50496 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68000 test_acc= 0.66800\n",
      "time  77.57290005683899\n",
      "edge_vol 7090.3496\n",
      "Epoch: 0184 train_loss= 1.02244 val_loss= 1.50355 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68000 test_acc= 0.66800\n",
      "time  77.97533702850342\n",
      "edge_vol 7128.0146\n",
      "Epoch: 0185 train_loss= 1.01976 val_loss= 1.50206 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  78.37488007545471\n",
      "edge_vol 7165.677\n",
      "Epoch: 0186 train_loss= 1.01504 val_loss= 1.50052 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  78.81182861328125\n",
      "edge_vol 7203.3525\n",
      "Epoch: 0187 train_loss= 1.01339 val_loss= 1.49895 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  79.21374320983887\n",
      "edge_vol 7240.656\n",
      "Epoch: 0188 train_loss= 1.01328 val_loss= 1.49753 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  79.6243622303009\n",
      "edge_vol 7277.867\n",
      "Epoch: 0189 train_loss= 1.00967 val_loss= 1.49603 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  80.06008529663086\n",
      "edge_vol 7314.7607\n",
      "Epoch: 0190 train_loss= 1.00666 val_loss= 1.49459 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  80.46900606155396\n",
      "edge_vol 7351.3394\n",
      "Epoch: 0191 train_loss= 1.00346 val_loss= 1.49317 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  80.8733377456665\n",
      "edge_vol 7387.8184\n",
      "Epoch: 0192 train_loss= 0.99723 val_loss= 1.49165 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  81.28058552742004\n",
      "edge_vol 7423.797\n",
      "Epoch: 0193 train_loss= 0.99901 val_loss= 1.48999 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  81.68023228645325\n",
      "edge_vol 7459.3013\n",
      "Epoch: 0194 train_loss= 0.99751 val_loss= 1.48827 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  82.07527422904968\n",
      "edge_vol 7494.2686\n",
      "Epoch: 0195 train_loss= 0.99088 val_loss= 1.48646 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  82.47284865379333\n",
      "edge_vol 7530.084\n",
      "Epoch: 0196 train_loss= 0.98785 val_loss= 1.48477 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  82.87030720710754\n",
      "edge_vol 7565.55\n",
      "Epoch: 0197 train_loss= 0.98266 val_loss= 1.48301 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  83.26885294914246\n",
      "edge_vol 7600.853\n",
      "Epoch: 0198 train_loss= 0.98096 val_loss= 1.48128 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  83.75089979171753\n",
      "edge_vol 7635.6997\n",
      "Epoch: 0199 train_loss= 0.97891 val_loss= 1.47941 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  84.18236875534058\n",
      "edge_vol 7670.8564\n",
      "Epoch: 0200 train_loss= 0.97426 val_loss= 1.47759 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  84.59280443191528\n",
      "edge_vol 7706.065\n",
      "Epoch: 0201 train_loss= 0.97036 val_loss= 1.47573 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  85.02865386009216\n",
      "edge_vol 7741.324\n",
      "Epoch: 0202 train_loss= 0.97144 val_loss= 1.47376 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  85.43307662010193\n",
      "edge_vol 7776.039\n",
      "Epoch: 0203 train_loss= 0.96484 val_loss= 1.47179 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  85.83564305305481\n",
      "edge_vol 7810.3184\n",
      "Epoch: 0204 train_loss= 0.96137 val_loss= 1.46968 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  86.2355146408081\n",
      "edge_vol 7843.8403\n",
      "Epoch: 0205 train_loss= 0.95955 val_loss= 1.46751 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  86.63634300231934\n",
      "edge_vol 7876.8174\n",
      "Epoch: 0206 train_loss= 0.95021 val_loss= 1.46532 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  87.07981204986572\n",
      "edge_vol 7909.53\n",
      "Epoch: 0207 train_loss= 0.94675 val_loss= 1.46308 train_acc= 0.96667 val_acc= 0.67800 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  87.52118563652039\n",
      "edge_vol 7941.3955\n",
      "Epoch: 0208 train_loss= 0.94822 val_loss= 1.46083 train_acc= 0.96667 val_acc= 0.67800 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  87.95108366012573\n",
      "edge_vol 7972.6523\n",
      "Epoch: 0209 train_loss= 0.94317 val_loss= 1.45857 train_acc= 0.96667 val_acc= 0.67800 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  88.35198259353638\n",
      "edge_vol 8003.344\n",
      "Epoch: 0210 train_loss= 0.94301 val_loss= 1.45624 train_acc= 0.96667 val_acc= 0.68000 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  88.75093722343445\n",
      "edge_vol 8033.615\n",
      "Epoch: 0211 train_loss= 0.93399 val_loss= 1.45402 train_acc= 0.96667 val_acc= 0.68000 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  89.15148735046387\n",
      "edge_vol 8063.243\n",
      "Epoch: 0212 train_loss= 0.93215 val_loss= 1.45178 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  89.55190229415894\n",
      "edge_vol 8092.67\n",
      "Epoch: 0213 train_loss= 0.93223 val_loss= 1.44957 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  89.97571182250977\n",
      "edge_vol 8121.7695\n",
      "Epoch: 0214 train_loss= 0.92289 val_loss= 1.44739 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.66600\n",
      "time  90.3758487701416\n",
      "edge_vol 8150.484\n",
      "Epoch: 0215 train_loss= 0.91632 val_loss= 1.44532 train_acc= 0.96667 val_acc= 0.68400 best_val_acc_trail= 0.68400 test_acc= 0.67200\n",
      "time  90.87062287330627\n",
      "edge_vol 8178.9053\n",
      "Epoch: 0216 train_loss= 0.91595 val_loss= 1.44319 train_acc= 0.96667 val_acc= 0.68400 best_val_acc_trail= 0.68400 test_acc= 0.67200\n",
      "time  91.30494284629822\n",
      "edge_vol 8206.933\n",
      "Epoch: 0217 train_loss= 0.91257 val_loss= 1.44096 train_acc= 0.96667 val_acc= 0.68400 best_val_acc_trail= 0.68400 test_acc= 0.67200\n",
      "time  91.71557211875916\n",
      "edge_vol 8234.568\n",
      "Epoch: 0218 train_loss= 0.90890 val_loss= 1.43879 train_acc= 0.96667 val_acc= 0.68400 best_val_acc_trail= 0.68400 test_acc= 0.67200\n",
      "time  92.11577153205872\n",
      "edge_vol 8261.652\n",
      "Epoch: 0219 train_loss= 0.90219 val_loss= 1.43651 train_acc= 0.96667 val_acc= 0.68600 best_val_acc_trail= 0.68600 test_acc= 0.67100\n",
      "time  92.55711960792542\n",
      "edge_vol 8288.271\n",
      "Epoch: 0220 train_loss= 0.90167 val_loss= 1.43421 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.68800 test_acc= 0.67100\n",
      "time  92.95820093154907\n",
      "edge_vol 8314.556\n",
      "Epoch: 0221 train_loss= 0.89672 val_loss= 1.43184 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  93.35229349136353\n",
      "edge_vol 8340.171\n",
      "Epoch: 0222 train_loss= 0.89585 val_loss= 1.42937 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  93.7501528263092\n",
      "edge_vol 8365.635\n",
      "Epoch: 0223 train_loss= 0.88831 val_loss= 1.42687 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  94.18378448486328\n",
      "edge_vol 8390.776\n",
      "Epoch: 0224 train_loss= 0.88486 val_loss= 1.42430 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  94.58707332611084\n",
      "edge_vol 8415.574\n",
      "Epoch: 0225 train_loss= 0.87815 val_loss= 1.42184 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  94.99359011650085\n",
      "edge_vol 8439.726\n",
      "Epoch: 0226 train_loss= 0.87610 val_loss= 1.41934 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  95.39485931396484\n",
      "edge_vol 8463.288\n",
      "Epoch: 0227 train_loss= 0.87139 val_loss= 1.41685 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  95.794992685318\n",
      "edge_vol 8486.09\n",
      "Epoch: 0228 train_loss= 0.86317 val_loss= 1.41429 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  96.19678378105164\n",
      "edge_vol 8508.352\n",
      "Epoch: 0229 train_loss= 0.86206 val_loss= 1.41172 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  96.60674405097961\n",
      "edge_vol 8530.195\n",
      "Epoch: 0230 train_loss= 0.85954 val_loss= 1.40925 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  97.00631737709045\n",
      "edge_vol 8551.898\n",
      "Epoch: 0231 train_loss= 0.85635 val_loss= 1.40680 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  97.40765309333801\n",
      "edge_vol 8573.365\n",
      "Epoch: 0232 train_loss= 0.85093 val_loss= 1.40443 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  97.80416798591614\n",
      "edge_vol 8594.754\n",
      "Epoch: 0233 train_loss= 0.84670 val_loss= 1.40200 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  98.25062608718872\n",
      "edge_vol 8615.915\n",
      "Epoch: 0234 train_loss= 0.84286 val_loss= 1.39961 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  98.68473839759827\n",
      "edge_vol 8636.339\n",
      "Epoch: 0235 train_loss= 0.83932 val_loss= 1.39714 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  99.08918881416321\n",
      "edge_vol 8656.047\n",
      "Epoch: 0236 train_loss= 0.83501 val_loss= 1.39453 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  99.48719239234924\n",
      "edge_vol 8674.852\n",
      "Epoch: 0237 train_loss= 0.83209 val_loss= 1.39192 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  99.91128897666931\n",
      "edge_vol 8693.215\n",
      "Epoch: 0238 train_loss= 0.82734 val_loss= 1.38924 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  100.33958554267883\n",
      "edge_vol 8711.15\n",
      "Epoch: 0239 train_loss= 0.82343 val_loss= 1.38640 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  100.76791048049927\n",
      "edge_vol 8728.759\n",
      "Epoch: 0240 train_loss= 0.82092 val_loss= 1.38364 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  101.19502377510071\n",
      "edge_vol 8746.224\n",
      "Epoch: 0241 train_loss= 0.81320 val_loss= 1.38088 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.67100\n",
      "time  101.62059664726257\n",
      "edge_vol 8763.505\n",
      "Epoch: 0242 train_loss= 0.81044 val_loss= 1.37817 train_acc= 0.96667 val_acc= 0.69200 best_val_acc_trail= 0.69200 test_acc= 0.67900\n",
      "time  102.04484343528748\n",
      "edge_vol 8780.232\n",
      "Epoch: 0243 train_loss= 0.80238 val_loss= 1.37551 train_acc= 0.96667 val_acc= 0.69200 best_val_acc_trail= 0.69200 test_acc= 0.67900\n",
      "time  102.45146775245667\n",
      "edge_vol 8796.492\n",
      "Epoch: 0244 train_loss= 0.80355 val_loss= 1.37283 train_acc= 0.96667 val_acc= 0.69200 best_val_acc_trail= 0.69200 test_acc= 0.67900\n",
      "time  102.85611605644226\n",
      "edge_vol 8812.273\n",
      "Epoch: 0245 train_loss= 0.79637 val_loss= 1.37019 train_acc= 0.96667 val_acc= 0.69200 best_val_acc_trail= 0.69200 test_acc= 0.67900\n",
      "time  103.26278758049011\n",
      "edge_vol 8827.742\n",
      "Epoch: 0246 train_loss= 0.79605 val_loss= 1.36756 train_acc= 0.96667 val_acc= 0.69200 best_val_acc_trail= 0.69200 test_acc= 0.67900\n",
      "time  103.66041302680969\n",
      "edge_vol 8842.857\n",
      "Epoch: 0247 train_loss= 0.78920 val_loss= 1.36482 train_acc= 0.96667 val_acc= 0.69200 best_val_acc_trail= 0.69200 test_acc= 0.67900\n",
      "time  104.0723044872284\n",
      "edge_vol 8857.617\n",
      "Epoch: 0248 train_loss= 0.78759 val_loss= 1.36213 train_acc= 0.96667 val_acc= 0.69200 best_val_acc_trail= 0.69200 test_acc= 0.67900\n",
      "time  104.49901008605957\n",
      "edge_vol 8871.921\n",
      "Epoch: 0249 train_loss= 0.78352 val_loss= 1.35940 train_acc= 0.96667 val_acc= 0.69200 best_val_acc_trail= 0.69200 test_acc= 0.67900\n",
      "time  104.91372179985046\n",
      "edge_vol 8885.797\n",
      "Epoch: 0250 train_loss= 0.77883 val_loss= 1.35667 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69200 test_acc= 0.67900\n",
      "time  105.31503677368164\n",
      "edge_vol 8899.521\n",
      "Epoch: 0251 train_loss= 0.77418 val_loss= 1.35399 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69200 test_acc= 0.67900\n",
      "time  105.76963257789612\n",
      "edge_vol 8913.028\n",
      "Epoch: 0252 train_loss= 0.76961 val_loss= 1.35132 train_acc= 0.96667 val_acc= 0.69200 best_val_acc_trail= 0.69200 test_acc= 0.67900\n",
      "time  106.20628046989441\n",
      "edge_vol 8926.296\n",
      "Epoch: 0253 train_loss= 0.76495 val_loss= 1.34868 train_acc= 0.96667 val_acc= 0.69200 best_val_acc_trail= 0.69200 test_acc= 0.67900\n",
      "time  106.6187014579773\n",
      "edge_vol 8939.293\n",
      "Epoch: 0254 train_loss= 0.76186 val_loss= 1.34609 train_acc= 0.96667 val_acc= 0.69200 best_val_acc_trail= 0.69200 test_acc= 0.67900\n",
      "time  107.01942110061646\n",
      "edge_vol 8951.819\n",
      "Epoch: 0255 train_loss= 0.75962 val_loss= 1.34340 train_acc= 0.96667 val_acc= 0.69200 best_val_acc_trail= 0.69200 test_acc= 0.67900\n",
      "time  107.41909193992615\n",
      "edge_vol 8963.689\n",
      "Epoch: 0256 train_loss= 0.75359 val_loss= 1.34072 train_acc= 0.96667 val_acc= 0.69200 best_val_acc_trail= 0.69200 test_acc= 0.67900\n",
      "time  107.81862378120422\n",
      "edge_vol 8975.055\n",
      "Epoch: 0257 train_loss= 0.75004 val_loss= 1.33809 train_acc= 0.96667 val_acc= 0.69200 best_val_acc_trail= 0.69200 test_acc= 0.67900\n",
      "time  108.25565147399902\n",
      "edge_vol 8985.937\n",
      "Epoch: 0258 train_loss= 0.74719 val_loss= 1.33534 train_acc= 0.96667 val_acc= 0.69400 best_val_acc_trail= 0.69400 test_acc= 0.68500\n",
      "time  108.6544897556305\n",
      "edge_vol 8996.413\n",
      "Epoch: 0259 train_loss= 0.74286 val_loss= 1.33260 train_acc= 0.96667 val_acc= 0.69400 best_val_acc_trail= 0.69400 test_acc= 0.68500\n",
      "time  109.05143690109253\n",
      "edge_vol 9006.65\n",
      "Epoch: 0260 train_loss= 0.74303 val_loss= 1.32986 train_acc= 0.96667 val_acc= 0.69400 best_val_acc_trail= 0.69400 test_acc= 0.68500\n",
      "time  109.44725561141968\n",
      "edge_vol 9016.622\n",
      "Epoch: 0261 train_loss= 0.73538 val_loss= 1.32719 train_acc= 0.96667 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68400\n",
      "time  109.87684488296509\n",
      "edge_vol 9026.402\n",
      "Epoch: 0262 train_loss= 0.73127 val_loss= 1.32451 train_acc= 0.96667 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68400\n",
      "time  110.27893877029419\n",
      "edge_vol 9035.949\n",
      "Epoch: 0263 train_loss= 0.72638 val_loss= 1.32201 train_acc= 0.96667 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68400\n",
      "time  110.6757960319519\n",
      "edge_vol 9045.583\n",
      "Epoch: 0264 train_loss= 0.72172 val_loss= 1.31949 train_acc= 0.96667 val_acc= 0.69400 best_val_acc_trail= 0.69600 test_acc= 0.68400\n",
      "time  111.07350826263428\n",
      "edge_vol 9054.713\n",
      "Epoch: 0265 train_loss= 0.72045 val_loss= 1.31692 train_acc= 0.96667 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68400\n",
      "time  111.47150492668152\n",
      "edge_vol 9063.429\n",
      "Epoch: 0266 train_loss= 0.71589 val_loss= 1.31445 train_acc= 0.96667 val_acc= 0.69400 best_val_acc_trail= 0.69600 test_acc= 0.68400\n",
      "time  111.95921516418457\n",
      "edge_vol 9072.11\n",
      "Epoch: 0267 train_loss= 0.71168 val_loss= 1.31195 train_acc= 0.96667 val_acc= 0.69400 best_val_acc_trail= 0.69600 test_acc= 0.68400\n",
      "time  112.37511491775513\n",
      "edge_vol 9080.679\n",
      "Epoch: 0268 train_loss= 0.70776 val_loss= 1.30932 train_acc= 0.97500 val_acc= 0.69400 best_val_acc_trail= 0.69600 test_acc= 0.68400\n",
      "time  112.77563858032227\n",
      "edge_vol 9088.949\n",
      "Epoch: 0269 train_loss= 0.70340 val_loss= 1.30657 train_acc= 0.97500 val_acc= 0.69400 best_val_acc_trail= 0.69600 test_acc= 0.68400\n",
      "time  113.20650219917297\n",
      "edge_vol 9096.873\n",
      "Epoch: 0270 train_loss= 0.70099 val_loss= 1.30396 train_acc= 0.97500 val_acc= 0.69400 best_val_acc_trail= 0.69600 test_acc= 0.68400\n",
      "time  113.61432480812073\n",
      "edge_vol 9104.507\n",
      "Epoch: 0271 train_loss= 0.69805 val_loss= 1.30133 train_acc= 0.97500 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68400\n",
      "time  114.01615810394287\n",
      "edge_vol 9112.063\n",
      "Epoch: 0272 train_loss= 0.69133 val_loss= 1.29874 train_acc= 0.97500 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68400\n",
      "time  114.42011404037476\n",
      "edge_vol 9119.472\n",
      "Epoch: 0273 train_loss= 0.68798 val_loss= 1.29622 train_acc= 0.97500 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68400\n",
      "time  114.8189902305603\n",
      "edge_vol 9126.87\n",
      "Epoch: 0274 train_loss= 0.68576 val_loss= 1.29372 train_acc= 0.97500 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68400\n",
      "time  115.21948480606079\n",
      "edge_vol 9134.072\n",
      "Epoch: 0275 train_loss= 0.68200 val_loss= 1.29128 train_acc= 0.97500 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68400\n",
      "time  115.66855025291443\n",
      "edge_vol 9141.064\n",
      "Epoch: 0276 train_loss= 0.67699 val_loss= 1.28896 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.69800 test_acc= 0.68900\n",
      "time  116.09241151809692\n",
      "edge_vol 9147.954\n",
      "Epoch: 0277 train_loss= 0.67583 val_loss= 1.28659 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.69800 test_acc= 0.68900\n",
      "time  116.53854870796204\n",
      "edge_vol 9154.594\n",
      "Epoch: 0278 train_loss= 0.67153 val_loss= 1.28420 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.69800 test_acc= 0.68900\n",
      "time  116.95141673088074\n",
      "edge_vol 9160.96\n",
      "Epoch: 0279 train_loss= 0.66874 val_loss= 1.28177 train_acc= 0.97500 val_acc= 0.70000 best_val_acc_trail= 0.70000 test_acc= 0.69000\n",
      "time  117.36237359046936\n",
      "edge_vol 9167.258\n",
      "Epoch: 0280 train_loss= 0.66477 val_loss= 1.27927 train_acc= 0.97500 val_acc= 0.70000 best_val_acc_trail= 0.70000 test_acc= 0.69000\n",
      "time  117.75938367843628\n",
      "edge_vol 9173.383\n",
      "Epoch: 0281 train_loss= 0.66121 val_loss= 1.27671 train_acc= 0.97500 val_acc= 0.70200 best_val_acc_trail= 0.70200 test_acc= 0.69000\n",
      "time  118.16012787818909\n",
      "edge_vol 9179.389\n",
      "Epoch: 0282 train_loss= 0.65903 val_loss= 1.27407 train_acc= 0.97500 val_acc= 0.70200 best_val_acc_trail= 0.70200 test_acc= 0.69000\n",
      "time  118.56239461898804\n",
      "edge_vol 9185.472\n",
      "Epoch: 0283 train_loss= 0.65586 val_loss= 1.27138 train_acc= 0.97500 val_acc= 0.70200 best_val_acc_trail= 0.70200 test_acc= 0.69000\n",
      "time  118.96424436569214\n",
      "edge_vol 9191.201\n",
      "Epoch: 0284 train_loss= 0.65129 val_loss= 1.26875 train_acc= 0.97500 val_acc= 0.70200 best_val_acc_trail= 0.70200 test_acc= 0.69000\n",
      "time  119.3769588470459\n",
      "edge_vol 9196.858\n",
      "Epoch: 0285 train_loss= 0.64752 val_loss= 1.26611 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.70400 test_acc= 0.69000\n",
      "time  119.8311858177185\n",
      "edge_vol 9202.445\n",
      "Epoch: 0286 train_loss= 0.64555 val_loss= 1.26366 train_acc= 0.97500 val_acc= 0.70200 best_val_acc_trail= 0.70400 test_acc= 0.69000\n",
      "time  120.26935958862305\n",
      "edge_vol 9207.793\n",
      "Epoch: 0287 train_loss= 0.64199 val_loss= 1.26117 train_acc= 0.97500 val_acc= 0.70200 best_val_acc_trail= 0.70400 test_acc= 0.69000\n",
      "time  120.66931009292603\n",
      "edge_vol 9213.296\n",
      "Epoch: 0288 train_loss= 0.63810 val_loss= 1.25867 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.70400 test_acc= 0.69000\n",
      "time  121.06664967536926\n",
      "edge_vol 9218.491\n",
      "Epoch: 0289 train_loss= 0.63560 val_loss= 1.25614 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.70400 test_acc= 0.69000\n",
      "time  121.46721601486206\n",
      "edge_vol 9223.439\n",
      "Epoch: 0290 train_loss= 0.63137 val_loss= 1.25368 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70600 test_acc= 0.69000\n",
      "time  121.86633586883545\n",
      "edge_vol 9228.311\n",
      "Epoch: 0291 train_loss= 0.62801 val_loss= 1.25141 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70600 test_acc= 0.69000\n",
      "time  122.2690258026123\n",
      "edge_vol 9233.041\n",
      "Epoch: 0292 train_loss= 0.62700 val_loss= 1.24914 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70600 test_acc= 0.69000\n",
      "time  122.67087244987488\n",
      "edge_vol 9237.66\n",
      "Epoch: 0293 train_loss= 0.62462 val_loss= 1.24686 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  123.10588216781616\n",
      "edge_vol 9242.205\n",
      "Epoch: 0294 train_loss= 0.62121 val_loss= 1.24465 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  123.51086807250977\n",
      "edge_vol 9246.599\n",
      "Epoch: 0295 train_loss= 0.61795 val_loss= 1.24248 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  123.91916465759277\n",
      "edge_vol 9250.908\n",
      "Epoch: 0296 train_loss= 0.61609 val_loss= 1.24037 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  124.33514213562012\n",
      "edge_vol 9255.0\n",
      "Epoch: 0297 train_loss= 0.61327 val_loss= 1.23838 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  124.73440957069397\n",
      "edge_vol 9258.973\n",
      "Epoch: 0298 train_loss= 0.60946 val_loss= 1.23652 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  125.17316150665283\n",
      "edge_vol 9262.937\n",
      "Epoch: 0299 train_loss= 0.60713 val_loss= 1.23469 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  125.59875988960266\n",
      "edge_vol 9266.728\n",
      "Epoch: 0300 train_loss= 0.60245 val_loss= 1.23276 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  126.0067834854126\n",
      "edge_vol 9270.264\n",
      "Epoch: 0301 train_loss= 0.60039 val_loss= 1.23070 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  126.46101236343384\n",
      "edge_vol 9273.59\n",
      "Epoch: 0302 train_loss= 0.59974 val_loss= 1.22868 train_acc= 0.98333 val_acc= 0.70400 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  126.86253786087036\n",
      "edge_vol 9276.76\n",
      "Epoch: 0303 train_loss= 0.59702 val_loss= 1.22655 train_acc= 0.98333 val_acc= 0.70400 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  127.26195955276489\n",
      "edge_vol 9279.914\n",
      "Epoch: 0304 train_loss= 0.59463 val_loss= 1.22451 train_acc= 0.98333 val_acc= 0.70400 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  127.66329884529114\n",
      "edge_vol 9283.012\n",
      "Epoch: 0305 train_loss= 0.59026 val_loss= 1.22227 train_acc= 0.98333 val_acc= 0.70400 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  128.06089615821838\n",
      "edge_vol 9286.029\n",
      "Epoch: 0306 train_loss= 0.58814 val_loss= 1.22015 train_acc= 0.98333 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  128.46470069885254\n",
      "edge_vol 9289.047\n",
      "Epoch: 0307 train_loss= 0.58546 val_loss= 1.21804 train_acc= 0.98333 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  128.86197972297668\n",
      "edge_vol 9292.027\n",
      "Epoch: 0308 train_loss= 0.58230 val_loss= 1.21601 train_acc= 0.98333 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  129.25946927070618\n",
      "edge_vol 9295.077\n",
      "Epoch: 0309 train_loss= 0.58060 val_loss= 1.21411 train_acc= 0.98333 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  129.6595594882965\n",
      "edge_vol 9297.954\n",
      "Epoch: 0310 train_loss= 0.57828 val_loss= 1.21220 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  130.0595188140869\n",
      "edge_vol 9300.703\n",
      "Epoch: 0311 train_loss= 0.57521 val_loss= 1.21023 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  130.4607856273651\n",
      "edge_vol 9303.279\n",
      "Epoch: 0312 train_loss= 0.57322 val_loss= 1.20828 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  130.89597368240356\n",
      "edge_vol 9305.818\n",
      "Epoch: 0313 train_loss= 0.56968 val_loss= 1.20646 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  131.30352425575256\n",
      "edge_vol 9308.168\n",
      "Epoch: 0314 train_loss= 0.56644 val_loss= 1.20454 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.69100\n",
      "time  131.7311019897461\n",
      "edge_vol 9310.563\n",
      "Epoch: 0315 train_loss= 0.56577 val_loss= 1.20264 train_acc= 0.98333 val_acc= 0.71000 best_val_acc_trail= 0.71000 test_acc= 0.69200\n",
      "time  132.1435031890869\n",
      "edge_vol 9312.895\n",
      "Epoch: 0316 train_loss= 0.56271 val_loss= 1.20081 train_acc= 0.98333 val_acc= 0.71000 best_val_acc_trail= 0.71000 test_acc= 0.69200\n",
      "time  132.57166051864624\n",
      "edge_vol 9315.141\n",
      "Epoch: 0317 train_loss= 0.56004 val_loss= 1.19888 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.71000 test_acc= 0.69200\n",
      "time  132.97081470489502\n",
      "edge_vol 9317.1875\n",
      "Epoch: 0318 train_loss= 0.55732 val_loss= 1.19682 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.71000 test_acc= 0.69200\n",
      "time  133.3947193622589\n",
      "edge_vol 9319.064\n",
      "Epoch: 0319 train_loss= 0.55420 val_loss= 1.19473 train_acc= 0.98333 val_acc= 0.70600 best_val_acc_trail= 0.71000 test_acc= 0.69200\n",
      "time  133.81207275390625\n",
      "edge_vol 9320.697\n",
      "Epoch: 0320 train_loss= 0.55144 val_loss= 1.19282 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.71000 test_acc= 0.69200\n",
      "time  134.21182489395142\n",
      "edge_vol 9322.166\n",
      "Epoch: 0321 train_loss= 0.54941 val_loss= 1.19093 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.71000 test_acc= 0.69200\n",
      "time  134.62621021270752\n",
      "edge_vol 9323.427\n",
      "Epoch: 0322 train_loss= 0.54660 val_loss= 1.18907 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71200 test_acc= 0.69300\n",
      "time  135.0264904499054\n",
      "edge_vol 9324.516\n",
      "Epoch: 0323 train_loss= 0.54401 val_loss= 1.18713 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71200 test_acc= 0.69300\n",
      "time  135.4649031162262\n",
      "edge_vol 9325.43\n",
      "Epoch: 0324 train_loss= 0.54174 val_loss= 1.18526 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71200 test_acc= 0.69300\n",
      "time  135.88234400749207\n",
      "edge_vol 9326.156\n",
      "Epoch: 0325 train_loss= 0.53907 val_loss= 1.18342 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71200 test_acc= 0.69300\n",
      "time  136.33888220787048\n",
      "edge_vol 9326.711\n",
      "Epoch: 0326 train_loss= 0.53681 val_loss= 1.18154 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71200 test_acc= 0.69300\n",
      "time  136.73965907096863\n",
      "edge_vol 9327.109\n",
      "Epoch: 0327 train_loss= 0.53335 val_loss= 1.17963 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71200 test_acc= 0.69300\n",
      "time  137.13456273078918\n",
      "edge_vol 9327.384\n",
      "Epoch: 0328 train_loss= 0.53233 val_loss= 1.17765 train_acc= 0.98333 val_acc= 0.71600 best_val_acc_trail= 0.71600 test_acc= 0.69700\n",
      "time  137.53516507148743\n",
      "edge_vol 9327.578\n",
      "Epoch: 0329 train_loss= 0.52960 val_loss= 1.17586 train_acc= 0.98333 val_acc= 0.71600 best_val_acc_trail= 0.71600 test_acc= 0.69700\n",
      "time  137.9328727722168\n",
      "edge_vol 9327.713\n",
      "Epoch: 0330 train_loss= 0.52774 val_loss= 1.17410 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.69700\n",
      "time  138.32885098457336\n",
      "edge_vol 9327.803\n",
      "Epoch: 0331 train_loss= 0.52457 val_loss= 1.17238 train_acc= 0.98333 val_acc= 0.71600 best_val_acc_trail= 0.71600 test_acc= 0.69700\n",
      "time  138.7501184940338\n",
      "edge_vol 9327.861\n",
      "Epoch: 0332 train_loss= 0.52345 val_loss= 1.17077 train_acc= 0.98333 val_acc= 0.71600 best_val_acc_trail= 0.71600 test_acc= 0.69700\n",
      "time  139.17804551124573\n",
      "edge_vol 9327.899\n",
      "Epoch: 0333 train_loss= 0.52096 val_loss= 1.16914 train_acc= 0.98333 val_acc= 0.71600 best_val_acc_trail= 0.71600 test_acc= 0.69700\n",
      "time  139.5823347568512\n",
      "edge_vol 9327.922\n",
      "Epoch: 0334 train_loss= 0.51861 val_loss= 1.16735 train_acc= 0.98333 val_acc= 0.71600 best_val_acc_trail= 0.71600 test_acc= 0.69700\n",
      "time  139.98516464233398\n",
      "edge_vol 9327.9375\n",
      "Epoch: 0335 train_loss= 0.51697 val_loss= 1.16566 train_acc= 0.98333 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  140.38408374786377\n",
      "edge_vol 9327.947\n",
      "Epoch: 0336 train_loss= 0.51450 val_loss= 1.16400 train_acc= 0.98333 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  140.79526567459106\n",
      "edge_vol 9327.955\n",
      "Epoch: 0337 train_loss= 0.51199 val_loss= 1.16241 train_acc= 0.98333 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  141.20085287094116\n",
      "edge_vol 9327.962\n",
      "Epoch: 0338 train_loss= 0.51032 val_loss= 1.16085 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  141.59851932525635\n",
      "edge_vol 9327.967\n",
      "Epoch: 0339 train_loss= 0.50899 val_loss= 1.15924 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  141.99850010871887\n",
      "edge_vol 9327.973\n",
      "Epoch: 0340 train_loss= 0.50641 val_loss= 1.15764 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  142.3940372467041\n",
      "edge_vol 9327.977\n",
      "Epoch: 0341 train_loss= 0.50523 val_loss= 1.15607 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  142.80566549301147\n",
      "edge_vol 9327.98\n",
      "Epoch: 0342 train_loss= 0.50279 val_loss= 1.15456 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  143.2021243572235\n",
      "edge_vol 9327.984\n",
      "Epoch: 0343 train_loss= 0.50246 val_loss= 1.15300 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  143.59927558898926\n",
      "edge_vol 9327.988\n",
      "Epoch: 0344 train_loss= 0.49875 val_loss= 1.15140 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  143.99947261810303\n",
      "edge_vol 9327.991\n",
      "Epoch: 0345 train_loss= 0.49705 val_loss= 1.14983 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  144.39683508872986\n",
      "edge_vol 9327.994\n",
      "Epoch: 0346 train_loss= 0.49534 val_loss= 1.14835 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  144.84416580200195\n",
      "edge_vol 9327.997\n",
      "Epoch: 0347 train_loss= 0.49360 val_loss= 1.14689 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  145.27279806137085\n",
      "edge_vol 9327.999\n",
      "Epoch: 0348 train_loss= 0.49128 val_loss= 1.14543 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  145.68876218795776\n",
      "edge_vol 9328.0\n",
      "Epoch: 0349 train_loss= 0.49020 val_loss= 1.14403 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  146.11624813079834\n",
      "edge_vol 9328.0\n",
      "Epoch: 0350 train_loss= 0.48815 val_loss= 1.14258 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  146.53142380714417\n",
      "edge_vol 9328.0\n",
      "Epoch: 0351 train_loss= 0.48623 val_loss= 1.14110 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  146.93152976036072\n",
      "edge_vol 9328.0\n",
      "Epoch: 0352 train_loss= 0.48487 val_loss= 1.13956 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  147.33143830299377\n",
      "edge_vol 9328.0\n",
      "Epoch: 0353 train_loss= 0.48217 val_loss= 1.13812 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  147.73007345199585\n",
      "edge_vol 9328.0\n",
      "Epoch: 0354 train_loss= 0.48061 val_loss= 1.13661 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  148.1305673122406\n",
      "edge_vol 9328.0\n",
      "Epoch: 0355 train_loss= 0.47937 val_loss= 1.13511 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  148.52816128730774\n",
      "edge_vol 9328.0\n",
      "Epoch: 0356 train_loss= 0.47590 val_loss= 1.13356 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  148.9229393005371\n",
      "edge_vol 9328.0\n",
      "Epoch: 0357 train_loss= 0.47610 val_loss= 1.13203 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  149.3188033103943\n",
      "edge_vol 9328.0\n",
      "Epoch: 0358 train_loss= 0.47428 val_loss= 1.13047 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  149.71858620643616\n",
      "edge_vol 9328.0\n",
      "Epoch: 0359 train_loss= 0.47199 val_loss= 1.12903 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  150.11614108085632\n",
      "edge_vol 9328.0\n",
      "Epoch: 0360 train_loss= 0.47014 val_loss= 1.12771 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  150.51088619232178\n",
      "edge_vol 9328.0\n",
      "Epoch: 0361 train_loss= 0.46855 val_loss= 1.12636 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  150.90832495689392\n",
      "edge_vol 9328.0\n",
      "Epoch: 0362 train_loss= 0.46707 val_loss= 1.12503 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  151.30712342262268\n",
      "edge_vol 9328.0\n",
      "Epoch: 0363 train_loss= 0.46511 val_loss= 1.12370 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  151.7272825241089\n",
      "edge_vol 9328.0\n",
      "Epoch: 0364 train_loss= 0.46416 val_loss= 1.12259 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  152.16071605682373\n",
      "edge_vol 9328.0\n",
      "Epoch: 0365 train_loss= 0.46199 val_loss= 1.12148 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  152.55995273590088\n",
      "edge_vol 9328.0\n",
      "Epoch: 0366 train_loss= 0.46113 val_loss= 1.12042 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  152.95983910560608\n",
      "edge_vol 9328.0\n",
      "Epoch: 0367 train_loss= 0.45958 val_loss= 1.11928 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  153.35953855514526\n",
      "edge_vol 9328.0\n",
      "Epoch: 0368 train_loss= 0.45815 val_loss= 1.11808 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  153.80687069892883\n",
      "edge_vol 9328.0\n",
      "Epoch: 0369 train_loss= 0.45756 val_loss= 1.11702 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  154.20681929588318\n",
      "edge_vol 9328.0\n",
      "Epoch: 0370 train_loss= 0.45622 val_loss= 1.11592 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  154.60655236244202\n",
      "edge_vol 9328.0\n",
      "Epoch: 0371 train_loss= 0.45402 val_loss= 1.11486 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  155.00974249839783\n",
      "edge_vol 9328.0\n",
      "Epoch: 0372 train_loss= 0.45236 val_loss= 1.11375 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  155.40777707099915\n",
      "edge_vol 9328.0\n",
      "Epoch: 0373 train_loss= 0.45192 val_loss= 1.11269 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  155.82780861854553\n",
      "edge_vol 9328.0\n",
      "Epoch: 0374 train_loss= 0.44926 val_loss= 1.11175 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  156.24417877197266\n",
      "edge_vol 9328.0\n",
      "Epoch: 0375 train_loss= 0.44997 val_loss= 1.11075 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  156.649751663208\n",
      "edge_vol 9328.0\n",
      "Epoch: 0376 train_loss= 0.44734 val_loss= 1.10981 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  157.05710577964783\n",
      "edge_vol 9328.0\n",
      "Epoch: 0377 train_loss= 0.44623 val_loss= 1.10883 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  157.4899890422821\n",
      "edge_vol 9328.0\n",
      "Epoch: 0378 train_loss= 0.44546 val_loss= 1.10781 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  157.99180698394775\n",
      "edge_vol 9328.0\n",
      "Epoch: 0379 train_loss= 0.44331 val_loss= 1.10682 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  158.43437552452087\n",
      "edge_vol 9328.0\n",
      "Epoch: 0380 train_loss= 0.44255 val_loss= 1.10580 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  158.84786009788513\n",
      "edge_vol 9328.0\n",
      "Epoch: 0381 train_loss= 0.44078 val_loss= 1.10473 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  159.2712287902832\n",
      "edge_vol 9328.0\n",
      "Epoch: 0382 train_loss= 0.43971 val_loss= 1.10361 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  159.68911218643188\n",
      "edge_vol 9328.0\n",
      "Epoch: 0383 train_loss= 0.43782 val_loss= 1.10249 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  160.08579802513123\n",
      "edge_vol 9328.0\n",
      "Epoch: 0384 train_loss= 0.43725 val_loss= 1.10157 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.71800 test_acc= 0.69700\n",
      "time  160.48267030715942\n",
      "edge_vol 9328.0\n",
      "Epoch: 0385 train_loss= 0.43560 val_loss= 1.10068 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  160.8824052810669\n",
      "edge_vol 9328.0\n",
      "Epoch: 0386 train_loss= 0.43558 val_loss= 1.09988 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  161.32491087913513\n",
      "edge_vol 9328.0\n",
      "Epoch: 0387 train_loss= 0.43204 val_loss= 1.09908 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  161.79409265518188\n",
      "edge_vol 9328.0\n",
      "Epoch: 0388 train_loss= 0.43113 val_loss= 1.09821 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  162.19064712524414\n",
      "edge_vol 9328.0\n",
      "Epoch: 0389 train_loss= 0.43019 val_loss= 1.09729 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  162.59185481071472\n",
      "edge_vol 9328.0\n",
      "Epoch: 0390 train_loss= 0.42850 val_loss= 1.09630 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  162.991117477417\n",
      "edge_vol 9328.0\n",
      "Epoch: 0391 train_loss= 0.42748 val_loss= 1.09532 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  163.3915135860443\n",
      "edge_vol 9328.0\n",
      "Epoch: 0392 train_loss= 0.42583 val_loss= 1.09434 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  163.8233196735382\n",
      "edge_vol 9328.0\n",
      "Epoch: 0393 train_loss= 0.42498 val_loss= 1.09345 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  164.28126287460327\n",
      "edge_vol 9328.0\n",
      "Epoch: 0394 train_loss= 0.42298 val_loss= 1.09253 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  164.69016981124878\n",
      "edge_vol 9328.0\n",
      "Epoch: 0395 train_loss= 0.42334 val_loss= 1.09168 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  165.08709740638733\n",
      "edge_vol 9328.0\n",
      "Epoch: 0396 train_loss= 0.42074 val_loss= 1.09086 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  165.51769876480103\n",
      "edge_vol 9328.0\n",
      "Epoch: 0397 train_loss= 0.41995 val_loss= 1.08994 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  165.9213638305664\n",
      "edge_vol 9328.0\n",
      "Epoch: 0398 train_loss= 0.41874 val_loss= 1.08915 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  166.32265210151672\n",
      "edge_vol 9328.0\n",
      "Epoch: 0399 train_loss= 0.41738 val_loss= 1.08833 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  166.71740126609802\n",
      "edge_vol 9328.0\n",
      "Epoch: 0400 train_loss= 0.41552 val_loss= 1.08746 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  167.1165771484375\n",
      "edge_vol 9328.0\n",
      "Epoch: 0401 train_loss= 0.41485 val_loss= 1.08656 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  167.51410555839539\n",
      "edge_vol 9328.0\n",
      "Epoch: 0402 train_loss= 0.41373 val_loss= 1.08567 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  168.02093625068665\n",
      "edge_vol 9328.0\n",
      "Epoch: 0403 train_loss= 0.41290 val_loss= 1.08479 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  168.4423360824585\n",
      "edge_vol 9328.0\n",
      "Epoch: 0404 train_loss= 0.41172 val_loss= 1.08386 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  168.86192202568054\n",
      "edge_vol 9328.0\n",
      "Epoch: 0405 train_loss= 0.41003 val_loss= 1.08295 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  169.28278350830078\n",
      "edge_vol 9328.0\n",
      "Epoch: 0406 train_loss= 0.40993 val_loss= 1.08201 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  169.68563103675842\n",
      "edge_vol 9328.0\n",
      "Epoch: 0407 train_loss= 0.40853 val_loss= 1.08118 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  170.14570236206055\n",
      "edge_vol 9328.0\n",
      "Epoch: 0408 train_loss= 0.40780 val_loss= 1.08046 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  170.56523370742798\n",
      "edge_vol 9328.0\n",
      "Epoch: 0409 train_loss= 0.40549 val_loss= 1.07974 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  170.9753737449646\n",
      "edge_vol 9328.0\n",
      "Epoch: 0410 train_loss= 0.40676 val_loss= 1.07902 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  171.378488779068\n",
      "edge_vol 9328.0\n",
      "Epoch: 0411 train_loss= 0.40472 val_loss= 1.07826 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  171.8004744052887\n",
      "edge_vol 9328.0\n",
      "Epoch: 0412 train_loss= 0.40350 val_loss= 1.07751 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  172.2031500339508\n",
      "edge_vol 9328.0\n",
      "Epoch: 0413 train_loss= 0.40337 val_loss= 1.07684 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  172.60395407676697\n",
      "edge_vol 9328.0\n",
      "Epoch: 0414 train_loss= 0.40171 val_loss= 1.07608 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  173.00431656837463\n",
      "edge_vol 9328.0\n",
      "Epoch: 0415 train_loss= 0.40072 val_loss= 1.07529 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  173.40217185020447\n",
      "edge_vol 9328.0\n",
      "Epoch: 0416 train_loss= 0.39994 val_loss= 1.07457 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  173.80285906791687\n",
      "edge_vol 9328.0\n",
      "Epoch: 0417 train_loss= 0.39857 val_loss= 1.07378 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  174.23694229125977\n",
      "edge_vol 9328.0\n",
      "Epoch: 0418 train_loss= 0.39808 val_loss= 1.07300 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  174.66847777366638\n",
      "edge_vol 9328.0\n",
      "Epoch: 0419 train_loss= 0.39681 val_loss= 1.07222 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  175.06781935691833\n",
      "edge_vol 9328.0\n",
      "Epoch: 0420 train_loss= 0.39507 val_loss= 1.07135 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  175.478577375412\n",
      "edge_vol 9328.0\n",
      "Epoch: 0421 train_loss= 0.39470 val_loss= 1.07049 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  175.87983417510986\n",
      "edge_vol 9328.0\n",
      "Epoch: 0422 train_loss= 0.39294 val_loss= 1.06974 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  176.27928495407104\n",
      "edge_vol 9328.0\n",
      "Epoch: 0423 train_loss= 0.39244 val_loss= 1.06896 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  176.7023868560791\n",
      "edge_vol 9328.0\n",
      "Epoch: 0424 train_loss= 0.39096 val_loss= 1.06823 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  177.13480710983276\n",
      "edge_vol 9328.0\n",
      "Epoch: 0425 train_loss= 0.39031 val_loss= 1.06750 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  177.5349543094635\n",
      "edge_vol 9328.0\n",
      "Epoch: 0426 train_loss= 0.38986 val_loss= 1.06677 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  177.9662299156189\n",
      "edge_vol 9328.0\n",
      "Epoch: 0427 train_loss= 0.38830 val_loss= 1.06609 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  178.3733720779419\n",
      "edge_vol 9328.0\n",
      "Epoch: 0428 train_loss= 0.38704 val_loss= 1.06535 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  178.76875019073486\n",
      "edge_vol 9328.0\n",
      "Epoch: 0429 train_loss= 0.38631 val_loss= 1.06463 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  179.1651635169983\n",
      "edge_vol 9328.0\n",
      "Epoch: 0430 train_loss= 0.38499 val_loss= 1.06390 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  179.59766387939453\n",
      "edge_vol 9328.0\n",
      "Epoch: 0431 train_loss= 0.38475 val_loss= 1.06321 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  180.00147318840027\n",
      "edge_vol 9328.0\n",
      "Epoch: 0432 train_loss= 0.38381 val_loss= 1.06251 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  180.47578883171082\n",
      "edge_vol 9328.0\n",
      "Epoch: 0433 train_loss= 0.38290 val_loss= 1.06185 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  180.90739488601685\n",
      "edge_vol 9328.0\n",
      "Epoch: 0434 train_loss= 0.38154 val_loss= 1.06117 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  181.30699920654297\n",
      "edge_vol 9328.0\n",
      "Epoch: 0435 train_loss= 0.38135 val_loss= 1.06040 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  181.70406818389893\n",
      "edge_vol 9328.0\n",
      "Epoch: 0436 train_loss= 0.38000 val_loss= 1.05967 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  182.10522508621216\n",
      "edge_vol 9328.0\n",
      "Epoch: 0437 train_loss= 0.37939 val_loss= 1.05894 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  182.50173425674438\n",
      "edge_vol 9328.0\n",
      "Epoch: 0438 train_loss= 0.37802 val_loss= 1.05832 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  182.94738745689392\n",
      "edge_vol 9328.0\n",
      "Epoch: 0439 train_loss= 0.37755 val_loss= 1.05768 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  183.35510921478271\n",
      "edge_vol 9328.0\n",
      "Epoch: 0440 train_loss= 0.37661 val_loss= 1.05697 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  183.75160670280457\n",
      "edge_vol 9328.0\n",
      "Epoch: 0441 train_loss= 0.37567 val_loss= 1.05631 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  184.1510157585144\n",
      "edge_vol 9328.0\n",
      "Epoch: 0442 train_loss= 0.37456 val_loss= 1.05568 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  184.58100175857544\n",
      "edge_vol 9328.0\n",
      "Epoch: 0443 train_loss= 0.37399 val_loss= 1.05503 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  184.97731685638428\n",
      "edge_vol 9328.0\n",
      "Epoch: 0444 train_loss= 0.37286 val_loss= 1.05443 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  185.3873734474182\n",
      "edge_vol 9328.0\n",
      "Epoch: 0445 train_loss= 0.37218 val_loss= 1.05389 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  185.78336715698242\n",
      "edge_vol 9328.0\n",
      "Epoch: 0446 train_loss= 0.37121 val_loss= 1.05342 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  186.18533992767334\n",
      "edge_vol 9328.0\n",
      "Epoch: 0447 train_loss= 0.37043 val_loss= 1.05292 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  186.58765029907227\n",
      "edge_vol 9328.0\n",
      "Epoch: 0448 train_loss= 0.36951 val_loss= 1.05236 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  186.98580026626587\n",
      "edge_vol 9328.0\n",
      "Epoch: 0449 train_loss= 0.36808 val_loss= 1.05187 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  187.38717770576477\n",
      "edge_vol 9328.0\n",
      "Epoch: 0450 train_loss= 0.36805 val_loss= 1.05137 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  187.78880739212036\n",
      "edge_vol 9328.0\n",
      "Epoch: 0451 train_loss= 0.36740 val_loss= 1.05076 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  188.21376943588257\n",
      "edge_vol 9328.0\n",
      "Epoch: 0452 train_loss= 0.36662 val_loss= 1.05005 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  188.6311798095703\n",
      "edge_vol 9328.0\n",
      "Epoch: 0453 train_loss= 0.36607 val_loss= 1.04941 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  189.02921175956726\n",
      "edge_vol 9328.0\n",
      "Epoch: 0454 train_loss= 0.36496 val_loss= 1.04870 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  189.42819356918335\n",
      "edge_vol 9328.0\n",
      "Epoch: 0455 train_loss= 0.36454 val_loss= 1.04802 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  189.8257439136505\n",
      "edge_vol 9328.0\n",
      "Epoch: 0456 train_loss= 0.36349 val_loss= 1.04735 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  190.22236704826355\n",
      "edge_vol 9328.0\n",
      "Epoch: 0457 train_loss= 0.36269 val_loss= 1.04681 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  190.62158465385437\n",
      "edge_vol 9328.0\n",
      "Epoch: 0458 train_loss= 0.36236 val_loss= 1.04641 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  191.02134585380554\n",
      "edge_vol 9328.0\n",
      "Epoch: 0459 train_loss= 0.36163 val_loss= 1.04594 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  191.42127060890198\n",
      "edge_vol 9328.0\n",
      "Epoch: 0460 train_loss= 0.36099 val_loss= 1.04547 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  191.81965565681458\n",
      "edge_vol 9328.0\n",
      "Epoch: 0461 train_loss= 0.36083 val_loss= 1.04496 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  192.31516289710999\n",
      "edge_vol 9328.0\n",
      "Epoch: 0462 train_loss= 0.35956 val_loss= 1.04449 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  192.73328852653503\n",
      "edge_vol 9328.0\n",
      "Epoch: 0463 train_loss= 0.35830 val_loss= 1.04402 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  193.1539397239685\n",
      "edge_vol 9328.0\n",
      "Epoch: 0464 train_loss= 0.35871 val_loss= 1.04349 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  193.59499669075012\n",
      "edge_vol 9328.0\n",
      "Epoch: 0465 train_loss= 0.35801 val_loss= 1.04286 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  193.9980435371399\n",
      "edge_vol 9328.0\n",
      "Epoch: 0466 train_loss= 0.35711 val_loss= 1.04235 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  194.40345072746277\n",
      "edge_vol 9328.0\n",
      "Epoch: 0467 train_loss= 0.35636 val_loss= 1.04181 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  194.80764532089233\n",
      "edge_vol 9328.0\n",
      "Epoch: 0468 train_loss= 0.35614 val_loss= 1.04121 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  195.2116084098816\n",
      "edge_vol 9328.0\n",
      "Epoch: 0469 train_loss= 0.35592 val_loss= 1.04055 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  195.6197009086609\n",
      "edge_vol 9328.0\n",
      "Epoch: 0470 train_loss= 0.35464 val_loss= 1.03997 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  196.04768586158752\n",
      "edge_vol 9328.0\n",
      "Epoch: 0471 train_loss= 0.35436 val_loss= 1.03951 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  196.45281863212585\n",
      "edge_vol 9328.0\n",
      "Epoch: 0472 train_loss= 0.35382 val_loss= 1.03911 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  196.8517360687256\n",
      "edge_vol 9328.0\n",
      "Epoch: 0473 train_loss= 0.35303 val_loss= 1.03865 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  197.2751214504242\n",
      "edge_vol 9328.0\n",
      "Epoch: 0474 train_loss= 0.35197 val_loss= 1.03815 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  197.6880874633789\n",
      "edge_vol 9328.0\n",
      "Epoch: 0475 train_loss= 0.35188 val_loss= 1.03771 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  198.0893213748932\n",
      "edge_vol 9328.0\n",
      "Epoch: 0476 train_loss= 0.35114 val_loss= 1.03728 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  198.48780751228333\n",
      "edge_vol 9328.0\n",
      "Epoch: 0477 train_loss= 0.35053 val_loss= 1.03690 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  198.88691306114197\n",
      "edge_vol 9328.0\n",
      "Epoch: 0478 train_loss= 0.35009 val_loss= 1.03657 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  199.28758311271667\n",
      "edge_vol 9328.0\n",
      "Epoch: 0479 train_loss= 0.34897 val_loss= 1.03628 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  199.68714880943298\n",
      "edge_vol 9328.0\n",
      "Epoch: 0480 train_loss= 0.34937 val_loss= 1.03599 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  200.11585998535156\n",
      "edge_vol 9328.0\n",
      "Epoch: 0481 train_loss= 0.34810 val_loss= 1.03575 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  200.5277578830719\n",
      "edge_vol 9328.0\n",
      "Epoch: 0482 train_loss= 0.34739 val_loss= 1.03551 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  200.94406080245972\n",
      "edge_vol 9328.0\n",
      "Epoch: 0483 train_loss= 0.34679 val_loss= 1.03523 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  201.36306023597717\n",
      "edge_vol 9328.0\n",
      "Epoch: 0484 train_loss= 0.34606 val_loss= 1.03499 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  201.80231523513794\n",
      "edge_vol 9328.0\n",
      "Epoch: 0485 train_loss= 0.34606 val_loss= 1.03476 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  202.2105004787445\n",
      "edge_vol 9328.0\n",
      "Epoch: 0486 train_loss= 0.34554 val_loss= 1.03458 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  202.6127986907959\n",
      "edge_vol 9328.0\n",
      "Epoch: 0487 train_loss= 0.34442 val_loss= 1.03433 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  203.01060390472412\n",
      "edge_vol 9328.0\n",
      "Epoch: 0488 train_loss= 0.34380 val_loss= 1.03409 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  203.41285872459412\n",
      "edge_vol 9328.0\n",
      "Epoch: 0489 train_loss= 0.34319 val_loss= 1.03380 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  203.80825972557068\n",
      "edge_vol 9328.0\n",
      "Epoch: 0490 train_loss= 0.34267 val_loss= 1.03346 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  204.20786690711975\n",
      "edge_vol 9328.0\n",
      "Epoch: 0491 train_loss= 0.34224 val_loss= 1.03313 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  204.61262607574463\n",
      "edge_vol 9328.0\n",
      "Epoch: 0492 train_loss= 0.34115 val_loss= 1.03278 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  205.01416444778442\n",
      "edge_vol 9328.0\n",
      "Epoch: 0493 train_loss= 0.34044 val_loss= 1.03241 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  205.46332120895386\n",
      "edge_vol 9328.0\n",
      "Epoch: 0494 train_loss= 0.33991 val_loss= 1.03213 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  205.9001224040985\n",
      "edge_vol 9328.0\n",
      "Epoch: 0495 train_loss= 0.33932 val_loss= 1.03176 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  206.31810855865479\n",
      "edge_vol 9328.0\n",
      "Epoch: 0496 train_loss= 0.33896 val_loss= 1.03152 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  206.81517577171326\n",
      "edge_vol 9328.0\n",
      "Epoch: 0497 train_loss= 0.33827 val_loss= 1.03127 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  207.22919154167175\n",
      "edge_vol 9328.0\n",
      "Epoch: 0498 train_loss= 0.33699 val_loss= 1.03088 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  207.64342665672302\n",
      "edge_vol 9328.0\n",
      "Epoch: 0499 train_loss= 0.33703 val_loss= 1.03055 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  208.04207825660706\n",
      "edge_vol 9328.0\n",
      "Epoch: 0500 train_loss= 0.33619 val_loss= 1.03037 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  208.49442338943481\n",
      "edge_vol 9328.0\n",
      "Epoch: 0501 train_loss= 0.33570 val_loss= 1.03009 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  208.9000587463379\n",
      "edge_vol 9328.0\n",
      "Epoch: 0502 train_loss= 0.33525 val_loss= 1.02979 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  209.3554503917694\n",
      "edge_vol 9328.0\n",
      "Epoch: 0503 train_loss= 0.33470 val_loss= 1.02949 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  209.786146402359\n",
      "edge_vol 9328.0\n",
      "Epoch: 0504 train_loss= 0.33409 val_loss= 1.02915 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  210.182514667511\n",
      "edge_vol 9328.0\n",
      "Epoch: 0505 train_loss= 0.33367 val_loss= 1.02871 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  210.61914896965027\n",
      "edge_vol 9328.0\n",
      "Epoch: 0506 train_loss= 0.33275 val_loss= 1.02835 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  211.0497395992279\n",
      "edge_vol 9328.0\n",
      "Epoch: 0507 train_loss= 0.33277 val_loss= 1.02797 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  211.4775094985962\n",
      "edge_vol 9328.0\n",
      "Epoch: 0508 train_loss= 0.33228 val_loss= 1.02761 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  211.87772274017334\n",
      "edge_vol 9328.0\n",
      "Epoch: 0509 train_loss= 0.33167 val_loss= 1.02720 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  212.32045364379883\n",
      "edge_vol 9328.0\n",
      "Epoch: 0510 train_loss= 0.33091 val_loss= 1.02680 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  212.73018169403076\n",
      "edge_vol 9328.0\n",
      "Epoch: 0511 train_loss= 0.33021 val_loss= 1.02650 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  213.2004406452179\n",
      "edge_vol 9328.0\n",
      "Epoch: 0512 train_loss= 0.32972 val_loss= 1.02618 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  213.59851217269897\n",
      "edge_vol 9328.0\n",
      "Epoch: 0513 train_loss= 0.32916 val_loss= 1.02587 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  213.9827220439911\n",
      "edge_vol 9328.0\n",
      "Epoch: 0514 train_loss= 0.32888 val_loss= 1.02548 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  214.36621952056885\n",
      "edge_vol 9328.0\n",
      "Epoch: 0515 train_loss= 0.32819 val_loss= 1.02515 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  214.75860357284546\n",
      "edge_vol 9328.0\n",
      "Epoch: 0516 train_loss= 0.32796 val_loss= 1.02481 train_acc= 0.99167 val_acc= 0.71200 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  215.14330625534058\n",
      "edge_vol 9328.0\n",
      "Epoch: 0517 train_loss= 0.32694 val_loss= 1.02447 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "time  215.5312855243683\n",
      "edge_vol 9328.0\n",
      "Epoch: 0518 train_loss= 0.32666 val_loss= 1.02412 train_acc= 0.99167 val_acc= 0.71400 best_val_acc_trail= 0.72200 test_acc= 0.69700\n",
      "Early stopping...\n"
     ]
    }
   ],
   "source": [
    "## My met\n",
    "from config import *\n",
    "from utils import *\n",
    "from models import GCN, PTDNetGCN\n",
    "from metrics import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "# Settings\n",
    "args.dataset='pubmed'\n",
    "\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(args.dataset)\n",
    "adj=modified_adj\n",
    "all_labels = y_train + y_test+y_val\n",
    "single_label = np.argmax(all_labels,axis=-1)\n",
    "\n",
    "nodesize = features.shape[0]\n",
    "\n",
    "# Some preprocessing\n",
    "features = preprocess_features(features)\n",
    "support = preprocess_adj(adj)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "\n",
    "tuple_adj = sparse_to_tuple(adj.tocoo())\n",
    "features_tensor = tf.convert_to_tensor(features,dtype=dtype)\n",
    "adj_tensor = tf.SparseTensor(*tuple_adj)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train,dtype=dtype)\n",
    "train_mask_tensor = tf.convert_to_tensor(train_mask)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test,dtype=dtype)\n",
    "test_mask_tensor = tf.convert_to_tensor(test_mask)\n",
    "y_val_tensor = tf.convert_to_tensor(y_val,dtype=dtype)\n",
    "val_mask_tensor = tf.convert_to_tensor(val_mask)\n",
    "\n",
    "\n",
    "\n",
    "best_test_acc = 0\n",
    "best_val_acc_trail = 0\n",
    "best_val_loss = 10000\n",
    "import time\n",
    "begin = time.time()\n",
    "\n",
    "model = PTDNetGCN(input_dim=features.shape[1], output_dim=y_train.shape[1])\n",
    "model.set_fea_adj(np.array(range(adj.shape[0])), features_tensor, adj_tensor)\n",
    "\n",
    "best_epoch = 0\n",
    "curr_step = 0\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    temperature = max(0.05,args.init_temperature * pow(args.temperature_decay, epoch))\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = []\n",
    "        for l in range(args.outL):\n",
    "            output = model.call(temperature,training=True)\n",
    "            preds.append(tf.expand_dims(output,0))\n",
    "        all_preds = tf.concat(preds,axis=0)\n",
    "        mean_preds = tf.reduce_mean(preds,axis=0)\n",
    "        consistency_loss = tf.nn.l2_loss(mean_preds-all_preds)\n",
    "\n",
    "        cross_loss = masked_softmax_cross_entropy(mean_preds, y_train_tensor,train_mask_tensor)\n",
    "        lossL2 = tf.add_n([tf.nn.l2_loss(v) for v in model.trainable_variables])\n",
    "        lossl0 = model.lossl0(temperature)\n",
    "        nuclear = model.my_nuclear()\n",
    "        #nuclear = model.nuclear()\n",
    "        loss = cross_loss + args.weight_decay*lossL2 + args.lambda1*lossl0 + args.lambda3*nuclear + args.coff_consis*consistency_loss\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    output = model.call(None, training=False)\n",
    "    edges_volumn = tf.reduce_sum(model.maskes[0])\n",
    "    print('edge_vol',edges_volumn.numpy())\n",
    "\n",
    "    train_acc = masked_accuracy(output, y_train_tensor,train_mask_tensor)\n",
    "    val_acc  = masked_accuracy(output, y_val_tensor,val_mask_tensor)\n",
    "    val_loss = masked_softmax_cross_entropy(output, y_val_tensor, val_mask_tensor)\n",
    "    test_acc  = masked_accuracy(output, y_test_tensor,test_mask_tensor)\n",
    "    if val_acc > best_val_acc:\n",
    "        curr_step = 0\n",
    "        best_epoch = epoch\n",
    "        best_val_acc = val_acc\n",
    "        best_val_loss= val_loss\n",
    "        if val_acc>best_val_acc_trail:\n",
    "            best_test_acc = test_acc\n",
    "            best_val_acc_trail = val_acc\n",
    "    else:\n",
    "        curr_step +=1\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cross_loss),\"val_loss=\", \"{:.5f}\".format(val_loss),\n",
    "      \"train_acc=\", \"{:.5f}\".format(train_acc), \"val_acc=\", \"{:.5f}\".format(val_acc),\"best_val_acc_trail=\", \"{:.5f}\".format(best_val_acc_trail),\n",
    "      \"test_acc=\", \"{:.5f}\".format(best_test_acc))\n",
    "\n",
    "    if curr_step > args.early_stop:\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "    end = time.time()\n",
    "    print('time ',(end-begin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.79160 val_loss= 1.79134 train_acc= 0.25000 val_acc= 0.25000 test_acc= 0.23200\n",
      "Epoch: 0002 train_loss= 1.78976 val_loss= 1.79072 train_acc= 0.33800 val_acc= 0.33800 test_acc= 0.33800\n",
      "Epoch: 0003 train_loss= 1.78790 val_loss= 1.79008 train_acc= 0.40000 val_acc= 0.40000 test_acc= 0.40200\n",
      "Epoch: 0004 train_loss= 1.78603 val_loss= 1.78940 train_acc= 0.45400 val_acc= 0.45400 test_acc= 0.45300\n",
      "Epoch: 0005 train_loss= 1.78413 val_loss= 1.78868 train_acc= 0.49200 val_acc= 0.49200 test_acc= 0.47600\n",
      "Epoch: 0006 train_loss= 1.78215 val_loss= 1.78790 train_acc= 0.52600 val_acc= 0.52600 test_acc= 0.50800\n",
      "Epoch: 0007 train_loss= 1.78007 val_loss= 1.78705 train_acc= 0.55000 val_acc= 0.55000 test_acc= 0.53700\n",
      "Epoch: 0008 train_loss= 1.77787 val_loss= 1.78613 train_acc= 0.56400 val_acc= 0.56400 test_acc= 0.56100\n",
      "Epoch: 0009 train_loss= 1.77554 val_loss= 1.78514 train_acc= 0.58000 val_acc= 0.58000 test_acc= 0.57100\n",
      "Epoch: 0010 train_loss= 1.77307 val_loss= 1.78408 train_acc= 0.59200 val_acc= 0.59200 test_acc= 0.58300\n",
      "Epoch: 0011 train_loss= 1.77046 val_loss= 1.78294 train_acc= 0.59200 val_acc= 0.59200 test_acc= 0.58300\n",
      "Epoch: 0012 train_loss= 1.76768 val_loss= 1.78174 train_acc= 0.59400 val_acc= 0.59400 test_acc= 0.59300\n",
      "Epoch: 0013 train_loss= 1.76475 val_loss= 1.78046 train_acc= 0.60000 val_acc= 0.60000 test_acc= 0.59800\n",
      "Epoch: 0014 train_loss= 1.76166 val_loss= 1.77913 train_acc= 0.60200 val_acc= 0.60200 test_acc= 0.59700\n",
      "Epoch: 0015 train_loss= 1.75843 val_loss= 1.77774 train_acc= 0.60800 val_acc= 0.60800 test_acc= 0.60300\n",
      "Epoch: 0016 train_loss= 1.75505 val_loss= 1.77629 train_acc= 0.60800 val_acc= 0.60800 test_acc= 0.60800\n",
      "Epoch: 0017 train_loss= 1.75152 val_loss= 1.77480 train_acc= 0.62200 val_acc= 0.62200 test_acc= 0.61100\n",
      "Epoch: 0018 train_loss= 1.74785 val_loss= 1.77325 train_acc= 0.62000 val_acc= 0.62000 test_acc= 0.61100\n",
      "Epoch: 0019 train_loss= 1.74404 val_loss= 1.77166 train_acc= 0.62800 val_acc= 0.62800 test_acc= 0.61800\n",
      "Epoch: 0020 train_loss= 1.74010 val_loss= 1.77002 train_acc= 0.62800 val_acc= 0.62800 test_acc= 0.61800\n",
      "Epoch: 0021 train_loss= 1.73603 val_loss= 1.76834 train_acc= 0.63000 val_acc= 0.63000 test_acc= 0.62500\n",
      "Epoch: 0022 train_loss= 1.73184 val_loss= 1.76662 train_acc= 0.63000 val_acc= 0.63000 test_acc= 0.62500\n",
      "Epoch: 0023 train_loss= 1.72753 val_loss= 1.76486 train_acc= 0.63200 val_acc= 0.63200 test_acc= 0.62400\n",
      "Epoch: 0024 train_loss= 1.72311 val_loss= 1.76307 train_acc= 0.63400 val_acc= 0.63400 test_acc= 0.62600\n",
      "Epoch: 0025 train_loss= 1.71859 val_loss= 1.76124 train_acc= 0.63600 val_acc= 0.63600 test_acc= 0.62900\n",
      "Epoch: 0026 train_loss= 1.71395 val_loss= 1.75938 train_acc= 0.63600 val_acc= 0.63600 test_acc= 0.62900\n",
      "Epoch: 0027 train_loss= 1.70923 val_loss= 1.75749 train_acc= 0.64000 val_acc= 0.64000 test_acc= 0.63300\n",
      "Epoch: 0028 train_loss= 1.70440 val_loss= 1.75556 train_acc= 0.64000 val_acc= 0.64000 test_acc= 0.63300\n",
      "Epoch: 0029 train_loss= 1.69948 val_loss= 1.75360 train_acc= 0.64200 val_acc= 0.64200 test_acc= 0.63300\n",
      "Epoch: 0030 train_loss= 1.69447 val_loss= 1.75160 train_acc= 0.64200 val_acc= 0.64200 test_acc= 0.63300\n",
      "Epoch: 0031 train_loss= 1.68937 val_loss= 1.74958 train_acc= 0.64200 val_acc= 0.64200 test_acc= 0.63300\n",
      "Epoch: 0032 train_loss= 1.68419 val_loss= 1.74753 train_acc= 0.64400 val_acc= 0.64400 test_acc= 0.63400\n",
      "Epoch: 0033 train_loss= 1.67892 val_loss= 1.74544 train_acc= 0.64400 val_acc= 0.64400 test_acc= 0.63400\n",
      "Epoch: 0034 train_loss= 1.67357 val_loss= 1.74332 train_acc= 0.64400 val_acc= 0.64400 test_acc= 0.63400\n",
      "Epoch: 0035 train_loss= 1.66814 val_loss= 1.74117 train_acc= 0.64800 val_acc= 0.64800 test_acc= 0.63200\n",
      "Epoch: 0036 train_loss= 1.66264 val_loss= 1.73899 train_acc= 0.64800 val_acc= 0.64800 test_acc= 0.63200\n",
      "Epoch: 0037 train_loss= 1.65706 val_loss= 1.73678 train_acc= 0.65000 val_acc= 0.65000 test_acc= 0.63300\n",
      "Epoch: 0038 train_loss= 1.65140 val_loss= 1.73454 train_acc= 0.65000 val_acc= 0.65000 test_acc= 0.63300\n",
      "Epoch: 0039 train_loss= 1.64566 val_loss= 1.73225 train_acc= 0.65000 val_acc= 0.65000 test_acc= 0.63300\n",
      "Epoch: 0040 train_loss= 1.63986 val_loss= 1.72994 train_acc= 0.65000 val_acc= 0.65000 test_acc= 0.63300\n",
      "Epoch: 0041 train_loss= 1.63398 val_loss= 1.72759 train_acc= 0.65000 val_acc= 0.65000 test_acc= 0.63300\n",
      "Epoch: 0042 train_loss= 1.62803 val_loss= 1.72521 train_acc= 0.65000 val_acc= 0.65000 test_acc= 0.63300\n",
      "Epoch: 0043 train_loss= 1.62201 val_loss= 1.72279 train_acc= 0.65000 val_acc= 0.65000 test_acc= 0.63300\n",
      "Epoch: 0044 train_loss= 1.61591 val_loss= 1.72035 train_acc= 0.65000 val_acc= 0.65000 test_acc= 0.63300\n",
      "Epoch: 0045 train_loss= 1.60976 val_loss= 1.71786 train_acc= 0.65200 val_acc= 0.65200 test_acc= 0.63800\n",
      "Epoch: 0046 train_loss= 1.60354 val_loss= 1.71533 train_acc= 0.65400 val_acc= 0.65400 test_acc= 0.63800\n",
      "Epoch: 0047 train_loss= 1.59724 val_loss= 1.71278 train_acc= 0.65200 val_acc= 0.65200 test_acc= 0.63800\n",
      "Epoch: 0048 train_loss= 1.59088 val_loss= 1.71019 train_acc= 0.65200 val_acc= 0.65200 test_acc= 0.63800\n",
      "Epoch: 0049 train_loss= 1.58445 val_loss= 1.70757 train_acc= 0.65200 val_acc= 0.65200 test_acc= 0.63800\n",
      "Epoch: 0050 train_loss= 1.57796 val_loss= 1.70492 train_acc= 0.65400 val_acc= 0.65400 test_acc= 0.63800\n",
      "Epoch: 0051 train_loss= 1.57140 val_loss= 1.70223 train_acc= 0.65400 val_acc= 0.65400 test_acc= 0.63800\n",
      "Epoch: 0052 train_loss= 1.56478 val_loss= 1.69950 train_acc= 0.65600 val_acc= 0.65600 test_acc= 0.63800\n",
      "Epoch: 0053 train_loss= 1.55810 val_loss= 1.69674 train_acc= 0.65600 val_acc= 0.65600 test_acc= 0.63800\n",
      "Epoch: 0054 train_loss= 1.55135 val_loss= 1.69394 train_acc= 0.65600 val_acc= 0.65600 test_acc= 0.63800\n",
      "Epoch: 0055 train_loss= 1.54455 val_loss= 1.69112 train_acc= 0.65600 val_acc= 0.65600 test_acc= 0.63800\n",
      "Epoch: 0056 train_loss= 1.53769 val_loss= 1.68826 train_acc= 0.66000 val_acc= 0.66000 test_acc= 0.64000\n",
      "Epoch: 0057 train_loss= 1.53077 val_loss= 1.68536 train_acc= 0.66200 val_acc= 0.66200 test_acc= 0.64000\n",
      "Epoch: 0058 train_loss= 1.52378 val_loss= 1.68243 train_acc= 0.66200 val_acc= 0.66200 test_acc= 0.64000\n",
      "Epoch: 0059 train_loss= 1.51675 val_loss= 1.67947 train_acc= 0.66400 val_acc= 0.66400 test_acc= 0.63900\n",
      "Epoch: 0060 train_loss= 1.50967 val_loss= 1.67647 train_acc= 0.66600 val_acc= 0.66600 test_acc= 0.63900\n",
      "Epoch: 0061 train_loss= 1.50253 val_loss= 1.67345 train_acc= 0.66400 val_acc= 0.66400 test_acc= 0.63900\n",
      "Epoch: 0062 train_loss= 1.49533 val_loss= 1.67039 train_acc= 0.66400 val_acc= 0.66400 test_acc= 0.63900\n",
      "Epoch: 0063 train_loss= 1.48810 val_loss= 1.66730 train_acc= 0.66400 val_acc= 0.66400 test_acc= 0.63900\n",
      "Epoch: 0064 train_loss= 1.48081 val_loss= 1.66419 train_acc= 0.66400 val_acc= 0.66400 test_acc= 0.63900\n",
      "Epoch: 0065 train_loss= 1.47348 val_loss= 1.66104 train_acc= 0.66800 val_acc= 0.66800 test_acc= 0.63800\n",
      "Epoch: 0066 train_loss= 1.46610 val_loss= 1.65786 train_acc= 0.66600 val_acc= 0.66600 test_acc= 0.63800\n",
      "Epoch: 0067 train_loss= 1.45869 val_loss= 1.65465 train_acc= 0.66600 val_acc= 0.66600 test_acc= 0.63800\n",
      "Epoch: 0068 train_loss= 1.45123 val_loss= 1.65142 train_acc= 0.66600 val_acc= 0.66600 test_acc= 0.63800\n",
      "Epoch: 0069 train_loss= 1.44374 val_loss= 1.64816 train_acc= 0.66600 val_acc= 0.66600 test_acc= 0.63800\n",
      "Epoch: 0070 train_loss= 1.43621 val_loss= 1.64487 train_acc= 0.66600 val_acc= 0.66600 test_acc= 0.63800\n",
      "Epoch: 0071 train_loss= 1.42865 val_loss= 1.64155 train_acc= 0.66600 val_acc= 0.66600 test_acc= 0.63800\n",
      "Epoch: 0072 train_loss= 1.42106 val_loss= 1.63821 train_acc= 0.66600 val_acc= 0.66600 test_acc= 0.63800\n",
      "Epoch: 0073 train_loss= 1.41344 val_loss= 1.63484 train_acc= 0.67000 val_acc= 0.67000 test_acc= 0.64100\n",
      "Epoch: 0074 train_loss= 1.40579 val_loss= 1.63145 train_acc= 0.67000 val_acc= 0.67000 test_acc= 0.64100\n",
      "Epoch: 0075 train_loss= 1.39812 val_loss= 1.62805 train_acc= 0.67200 val_acc= 0.67200 test_acc= 0.64100\n",
      "Epoch: 0076 train_loss= 1.39042 val_loss= 1.62462 train_acc= 0.67200 val_acc= 0.67200 test_acc= 0.64100\n",
      "Epoch: 0077 train_loss= 1.38271 val_loss= 1.62116 train_acc= 0.67200 val_acc= 0.67200 test_acc= 0.64100\n",
      "Epoch: 0078 train_loss= 1.37498 val_loss= 1.61769 train_acc= 0.67200 val_acc= 0.67200 test_acc= 0.64100\n",
      "Epoch: 0079 train_loss= 1.36724 val_loss= 1.61419 train_acc= 0.67200 val_acc= 0.67200 test_acc= 0.64100\n",
      "Epoch: 0080 train_loss= 1.35948 val_loss= 1.61069 train_acc= 0.67200 val_acc= 0.67200 test_acc= 0.64100\n",
      "Epoch: 0081 train_loss= 1.35172 val_loss= 1.60718 train_acc= 0.67200 val_acc= 0.67200 test_acc= 0.64100\n",
      "Epoch: 0082 train_loss= 1.34394 val_loss= 1.60365 train_acc= 0.67200 val_acc= 0.67200 test_acc= 0.64100\n",
      "Epoch: 0083 train_loss= 1.33617 val_loss= 1.60009 train_acc= 0.67200 val_acc= 0.67200 test_acc= 0.64100\n",
      "Epoch: 0084 train_loss= 1.32838 val_loss= 1.59653 train_acc= 0.67200 val_acc= 0.67200 test_acc= 0.64100\n",
      "Epoch: 0085 train_loss= 1.32060 val_loss= 1.59295 train_acc= 0.67200 val_acc= 0.67200 test_acc= 0.64100\n",
      "Epoch: 0086 train_loss= 1.31282 val_loss= 1.58936 train_acc= 0.67200 val_acc= 0.67200 test_acc= 0.64100\n",
      "Epoch: 0087 train_loss= 1.30505 val_loss= 1.58576 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.64000\n",
      "Epoch: 0088 train_loss= 1.29729 val_loss= 1.58215 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.64000\n",
      "Epoch: 0089 train_loss= 1.28952 val_loss= 1.57854 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.64000\n",
      "Epoch: 0090 train_loss= 1.28177 val_loss= 1.57491 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.64000\n",
      "Epoch: 0091 train_loss= 1.27404 val_loss= 1.57127 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.64000\n",
      "Epoch: 0092 train_loss= 1.26631 val_loss= 1.56763 train_acc= 0.67400 val_acc= 0.67400 test_acc= 0.64000\n",
      "Epoch: 0093 train_loss= 1.25861 val_loss= 1.56398 train_acc= 0.67600 val_acc= 0.67600 test_acc= 0.64500\n",
      "Epoch: 0094 train_loss= 1.25092 val_loss= 1.56033 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.64400\n",
      "Epoch: 0095 train_loss= 1.24326 val_loss= 1.55669 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.64400\n",
      "Epoch: 0096 train_loss= 1.23562 val_loss= 1.55305 train_acc= 0.67800 val_acc= 0.67800 test_acc= 0.64400\n",
      "Epoch: 0097 train_loss= 1.22800 val_loss= 1.54940 train_acc= 0.68000 val_acc= 0.68000 test_acc= 0.64800\n",
      "Epoch: 0098 train_loss= 1.22041 val_loss= 1.54574 train_acc= 0.68000 val_acc= 0.68000 test_acc= 0.64800\n",
      "Epoch: 0099 train_loss= 1.21286 val_loss= 1.54209 train_acc= 0.68200 val_acc= 0.68200 test_acc= 0.65000\n",
      "Epoch: 0100 train_loss= 1.20532 val_loss= 1.53845 train_acc= 0.68400 val_acc= 0.68400 test_acc= 0.65000\n",
      "Epoch: 0101 train_loss= 1.19783 val_loss= 1.53481 train_acc= 0.68600 val_acc= 0.68600 test_acc= 0.65000\n",
      "Epoch: 0102 train_loss= 1.19037 val_loss= 1.53117 train_acc= 0.68600 val_acc= 0.68600 test_acc= 0.65000\n",
      "Epoch: 0103 train_loss= 1.18295 val_loss= 1.52754 train_acc= 0.68600 val_acc= 0.68600 test_acc= 0.65000\n",
      "Epoch: 0104 train_loss= 1.17556 val_loss= 1.52391 train_acc= 0.68400 val_acc= 0.68400 test_acc= 0.65000\n",
      "Epoch: 0105 train_loss= 1.16821 val_loss= 1.52029 train_acc= 0.68400 val_acc= 0.68400 test_acc= 0.65000\n",
      "Epoch: 0106 train_loss= 1.16090 val_loss= 1.51669 train_acc= 0.68600 val_acc= 0.68600 test_acc= 0.65000\n",
      "Epoch: 0107 train_loss= 1.15363 val_loss= 1.51309 train_acc= 0.68800 val_acc= 0.68800 test_acc= 0.65400\n",
      "Epoch: 0108 train_loss= 1.14641 val_loss= 1.50949 train_acc= 0.68800 val_acc= 0.68800 test_acc= 0.65400\n",
      "Epoch: 0109 train_loss= 1.13922 val_loss= 1.50590 train_acc= 0.68800 val_acc= 0.68800 test_acc= 0.65400\n",
      "Epoch: 0110 train_loss= 1.13208 val_loss= 1.50232 train_acc= 0.68800 val_acc= 0.68800 test_acc= 0.65400\n",
      "Epoch: 0111 train_loss= 1.12500 val_loss= 1.49876 train_acc= 0.68800 val_acc= 0.68800 test_acc= 0.65400\n",
      "Epoch: 0112 train_loss= 1.11795 val_loss= 1.49521 train_acc= 0.68800 val_acc= 0.68800 test_acc= 0.65400\n",
      "Epoch: 0113 train_loss= 1.11095 val_loss= 1.49168 train_acc= 0.69000 val_acc= 0.69000 test_acc= 0.65600\n",
      "Epoch: 0114 train_loss= 1.10401 val_loss= 1.48815 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.65500\n",
      "Epoch: 0115 train_loss= 1.09711 val_loss= 1.48466 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.65500\n",
      "Epoch: 0116 train_loss= 1.09026 val_loss= 1.48117 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.65500\n",
      "Epoch: 0117 train_loss= 1.08346 val_loss= 1.47770 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.65500\n",
      "Epoch: 0118 train_loss= 1.07673 val_loss= 1.47423 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.65500\n",
      "Epoch: 0119 train_loss= 1.07004 val_loss= 1.47078 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.65500\n",
      "Epoch: 0120 train_loss= 1.06339 val_loss= 1.46738 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.65500\n",
      "Epoch: 0121 train_loss= 1.05682 val_loss= 1.46398 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.65900\n",
      "Epoch: 0122 train_loss= 1.05030 val_loss= 1.46060 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.65900\n",
      "Epoch: 0123 train_loss= 1.04382 val_loss= 1.45723 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.65900\n",
      "Epoch: 0124 train_loss= 1.03741 val_loss= 1.45387 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.65900\n",
      "Epoch: 0125 train_loss= 1.03104 val_loss= 1.45053 train_acc= 0.69000 val_acc= 0.69000 test_acc= 0.65900\n",
      "Epoch: 0126 train_loss= 1.02474 val_loss= 1.44721 train_acc= 0.69000 val_acc= 0.69000 test_acc= 0.65900\n",
      "Epoch: 0127 train_loss= 1.01849 val_loss= 1.44392 train_acc= 0.69000 val_acc= 0.69000 test_acc= 0.65900\n",
      "Epoch: 0128 train_loss= 1.01229 val_loss= 1.44066 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.65900\n",
      "Epoch: 0129 train_loss= 1.00616 val_loss= 1.43743 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.65900\n",
      "Epoch: 0130 train_loss= 1.00008 val_loss= 1.43421 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66200\n",
      "Epoch: 0131 train_loss= 0.99406 val_loss= 1.43100 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66200\n",
      "Epoch: 0132 train_loss= 0.98809 val_loss= 1.42780 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66200\n",
      "Epoch: 0133 train_loss= 0.98219 val_loss= 1.42464 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66200\n",
      "Epoch: 0134 train_loss= 0.97633 val_loss= 1.42150 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66200\n",
      "Epoch: 0135 train_loss= 0.97054 val_loss= 1.41839 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66200\n",
      "Epoch: 0136 train_loss= 0.96480 val_loss= 1.41528 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66200\n",
      "Epoch: 0137 train_loss= 0.95912 val_loss= 1.41222 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66200\n",
      "Epoch: 0138 train_loss= 0.95350 val_loss= 1.40916 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66200\n",
      "Epoch: 0139 train_loss= 0.94792 val_loss= 1.40614 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66200\n",
      "Epoch: 0140 train_loss= 0.94241 val_loss= 1.40315 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66200\n",
      "Epoch: 0141 train_loss= 0.93696 val_loss= 1.40019 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66200\n",
      "Epoch: 0142 train_loss= 0.93155 val_loss= 1.39722 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66200\n",
      "Epoch: 0143 train_loss= 0.92620 val_loss= 1.39427 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66400\n",
      "Epoch: 0144 train_loss= 0.92091 val_loss= 1.39136 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66400\n",
      "Epoch: 0145 train_loss= 0.91568 val_loss= 1.38849 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66400\n",
      "Epoch: 0146 train_loss= 0.91049 val_loss= 1.38564 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66400\n",
      "Epoch: 0147 train_loss= 0.90536 val_loss= 1.38281 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66300\n",
      "Epoch: 0148 train_loss= 0.90028 val_loss= 1.37999 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66300\n",
      "Epoch: 0149 train_loss= 0.89526 val_loss= 1.37721 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66300\n",
      "Epoch: 0150 train_loss= 0.89029 val_loss= 1.37445 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66300\n",
      "Epoch: 0151 train_loss= 0.88538 val_loss= 1.37169 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66300\n",
      "Epoch: 0152 train_loss= 0.88050 val_loss= 1.36897 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66300\n",
      "Epoch: 0153 train_loss= 0.87569 val_loss= 1.36628 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66300\n",
      "Epoch: 0154 train_loss= 0.87093 val_loss= 1.36360 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66300\n",
      "Epoch: 0155 train_loss= 0.86622 val_loss= 1.36095 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66300\n",
      "Epoch: 0156 train_loss= 0.86155 val_loss= 1.35833 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0157 train_loss= 0.85693 val_loss= 1.35573 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0158 train_loss= 0.85238 val_loss= 1.35315 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0159 train_loss= 0.84785 val_loss= 1.35059 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0160 train_loss= 0.84339 val_loss= 1.34806 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0161 train_loss= 0.83897 val_loss= 1.34555 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0162 train_loss= 0.83460 val_loss= 1.34305 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0163 train_loss= 0.83027 val_loss= 1.34058 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0164 train_loss= 0.82599 val_loss= 1.33815 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0165 train_loss= 0.82176 val_loss= 1.33572 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.66300\n",
      "Epoch: 0166 train_loss= 0.81756 val_loss= 1.33332 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.66300\n",
      "Epoch: 0167 train_loss= 0.81342 val_loss= 1.33094 train_acc= 0.69200 val_acc= 0.69200 test_acc= 0.66300\n",
      "Epoch: 0168 train_loss= 0.80933 val_loss= 1.32858 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.66300\n",
      "Epoch: 0169 train_loss= 0.80526 val_loss= 1.32625 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.66300\n",
      "Epoch: 0170 train_loss= 0.80125 val_loss= 1.32392 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.66300\n",
      "Epoch: 0171 train_loss= 0.79727 val_loss= 1.32163 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.66300\n",
      "Epoch: 0172 train_loss= 0.79334 val_loss= 1.31936 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.66300\n",
      "Epoch: 0173 train_loss= 0.78946 val_loss= 1.31710 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0174 train_loss= 0.78561 val_loss= 1.31488 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0175 train_loss= 0.78180 val_loss= 1.31268 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0176 train_loss= 0.77803 val_loss= 1.31050 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0177 train_loss= 0.77429 val_loss= 1.30832 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0178 train_loss= 0.77060 val_loss= 1.30615 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0179 train_loss= 0.76696 val_loss= 1.30402 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0180 train_loss= 0.76335 val_loss= 1.30190 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0181 train_loss= 0.75977 val_loss= 1.29980 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0182 train_loss= 0.75623 val_loss= 1.29773 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0183 train_loss= 0.75273 val_loss= 1.29569 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0184 train_loss= 0.74927 val_loss= 1.29365 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0185 train_loss= 0.74585 val_loss= 1.29163 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0186 train_loss= 0.74244 val_loss= 1.28964 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0187 train_loss= 0.73909 val_loss= 1.28766 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0188 train_loss= 0.73577 val_loss= 1.28570 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0189 train_loss= 0.73248 val_loss= 1.28375 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66300\n",
      "Epoch: 0190 train_loss= 0.72922 val_loss= 1.28183 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0191 train_loss= 0.72599 val_loss= 1.27993 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0192 train_loss= 0.72280 val_loss= 1.27805 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0193 train_loss= 0.71964 val_loss= 1.27619 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0194 train_loss= 0.71652 val_loss= 1.27432 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0195 train_loss= 0.71343 val_loss= 1.27247 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0196 train_loss= 0.71037 val_loss= 1.27065 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0197 train_loss= 0.70733 val_loss= 1.26883 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0198 train_loss= 0.70432 val_loss= 1.26704 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0199 train_loss= 0.70134 val_loss= 1.26528 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0200 train_loss= 0.69840 val_loss= 1.26353 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0201 train_loss= 0.69548 val_loss= 1.26179 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0202 train_loss= 0.69259 val_loss= 1.26006 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0203 train_loss= 0.68974 val_loss= 1.25836 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0204 train_loss= 0.68691 val_loss= 1.25665 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0205 train_loss= 0.68411 val_loss= 1.25496 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0206 train_loss= 0.68133 val_loss= 1.25330 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0207 train_loss= 0.67858 val_loss= 1.25167 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0208 train_loss= 0.67585 val_loss= 1.25004 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0209 train_loss= 0.67316 val_loss= 1.24841 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0210 train_loss= 0.67047 val_loss= 1.24681 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0211 train_loss= 0.66783 val_loss= 1.24523 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0212 train_loss= 0.66521 val_loss= 1.24368 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0213 train_loss= 0.66261 val_loss= 1.24211 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0214 train_loss= 0.66003 val_loss= 1.24054 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0215 train_loss= 0.65749 val_loss= 1.23901 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0216 train_loss= 0.65496 val_loss= 1.23750 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0217 train_loss= 0.65246 val_loss= 1.23598 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0218 train_loss= 0.64998 val_loss= 1.23449 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0219 train_loss= 0.64752 val_loss= 1.23302 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0220 train_loss= 0.64509 val_loss= 1.23153 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0221 train_loss= 0.64268 val_loss= 1.23006 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0222 train_loss= 0.64028 val_loss= 1.22863 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0223 train_loss= 0.63792 val_loss= 1.22722 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0224 train_loss= 0.63557 val_loss= 1.22582 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0225 train_loss= 0.63325 val_loss= 1.22441 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0226 train_loss= 0.63094 val_loss= 1.22301 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0227 train_loss= 0.62865 val_loss= 1.22160 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0228 train_loss= 0.62639 val_loss= 1.22021 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0229 train_loss= 0.62414 val_loss= 1.21887 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0230 train_loss= 0.62191 val_loss= 1.21755 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0231 train_loss= 0.61972 val_loss= 1.21622 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0232 train_loss= 0.61753 val_loss= 1.21491 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0233 train_loss= 0.61536 val_loss= 1.21358 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0234 train_loss= 0.61321 val_loss= 1.21227 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0235 train_loss= 0.61109 val_loss= 1.21099 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0236 train_loss= 0.60897 val_loss= 1.20972 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0237 train_loss= 0.60688 val_loss= 1.20845 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0238 train_loss= 0.60481 val_loss= 1.20720 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0239 train_loss= 0.60274 val_loss= 1.20595 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0240 train_loss= 0.60070 val_loss= 1.20472 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66300\n",
      "Epoch: 0241 train_loss= 0.59868 val_loss= 1.20350 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0242 train_loss= 0.59667 val_loss= 1.20228 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0243 train_loss= 0.59469 val_loss= 1.20107 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0244 train_loss= 0.59272 val_loss= 1.19988 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0245 train_loss= 0.59076 val_loss= 1.19868 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66300\n",
      "Epoch: 0246 train_loss= 0.58882 val_loss= 1.19750 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.66300\n",
      "Epoch: 0247 train_loss= 0.58690 val_loss= 1.19634 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.66300\n",
      "Early stopping...\n"
     ]
    }
   ],
   "source": [
    "##dropedge\n",
    "from config import args\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from utils import *\n",
    "from models import GCN_dropedge\n",
    "from metrics import *\n",
    "\n",
    "# Settings\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "args.dataset='pubmed'\n",
    "\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(args.dataset)\n",
    "adj=modified_adj\n",
    "\n",
    "tuple_adj = sparse_to_tuple(adj.tocoo())\n",
    "adj_tensor = tf.SparseTensor(*tuple_adj)\n",
    "\n",
    "features = preprocess_features(features)\n",
    "\n",
    "model = GCN_dropedge(input_dim=features.shape[1], output_dim=y_train.shape[1], adj=adj_tensor)\n",
    "\n",
    "\n",
    "features_tensor = tf.convert_to_tensor(features,dtype=tf.float32)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train,dtype=tf.float32)\n",
    "train_mask_tensor = tf.convert_to_tensor(train_mask)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test,dtype=tf.float32)\n",
    "test_mask_tensor = tf.convert_to_tensor(test_mask)\n",
    "y_val_tensor = tf.convert_to_tensor(y_val,dtype=tf.float32)\n",
    "val_mask_tensor = tf.convert_to_tensor(val_mask)\n",
    "\n",
    "best_test_acc = 0\n",
    "best_val_acc = 0\n",
    "best_val_loss = 10000\n",
    "\n",
    "\n",
    "curr_step = 0\n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        output = model.call((features_tensor),training=True)\n",
    "        cross_loss = masked_softmax_cross_entropy(output, y_train_tensor,train_mask_tensor)\n",
    "        lossL2 = tf.add_n([tf.nn.l2_loss(v) for v in model.trainable_variables])\n",
    "        loss = cross_loss + args.weight_decay*lossL2\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    output = model.call((features_tensor), training=False)\n",
    "    train_acc = masked_accuracy(output, y_train_tensor,train_mask_tensor)\n",
    "    val_acc  = masked_accuracy(output, y_val_tensor,val_mask_tensor)\n",
    "    val_loss = masked_softmax_cross_entropy(output, y_val_tensor, val_mask_tensor)\n",
    "    test_acc  = masked_accuracy(output, y_test_tensor,test_mask_tensor)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        curr_step = 0\n",
    "        best_test_acc = test_acc\n",
    "        best_val_acc = val_acc\n",
    "        best_val_loss= val_loss\n",
    "        # Print results\n",
    "\n",
    "    else:\n",
    "        curr_step +=1\n",
    "    if curr_step > args.early_stop:\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cross_loss),\"val_loss=\", \"{:.5f}\".format(val_loss),\n",
    "      \"train_acc=\", \"{:.5f}\".format(val_acc), \"val_acc=\", \"{:.5f}\".format(val_acc),\n",
    "      \"test_acc=\", \"{:.5f}\".format(best_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
