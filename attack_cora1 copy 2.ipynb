{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zsp/ljx/PTDNet/utils.py:221: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n",
      "Perturbing graph:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.6922634840011597\n",
      "GCN acc on unlabled data: 0.67\n",
      "attack loss: 1.6842432022094727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:   3%|▎         | 1/30 [06:36<3:11:25, 396.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.6943943500518799\n",
      "GCN acc on unlabled data: 0.677\n",
      "attack loss: 1.6869292259216309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:   7%|▋         | 2/30 [13:23<3:07:49, 402.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.6935954093933105\n",
      "GCN acc on unlabled data: 0.669\n",
      "attack loss: 1.6844574213027954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  10%|█         | 3/30 [20:01<3:00:17, 400.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7011932134628296\n",
      "GCN acc on unlabled data: 0.675\n",
      "attack loss: 1.6929703950881958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  13%|█▎        | 4/30 [26:44<2:54:02, 401.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.6967686414718628\n",
      "GCN acc on unlabled data: 0.668\n",
      "attack loss: 1.6879160404205322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  17%|█▋        | 5/30 [33:43<2:49:58, 407.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7058812379837036\n",
      "GCN acc on unlabled data: 0.673\n",
      "attack loss: 1.6972713470458984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  20%|██        | 6/30 [40:28<2:42:44, 406.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7009214162826538\n",
      "GCN acc on unlabled data: 0.676\n",
      "attack loss: 1.6922599077224731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  23%|██▎       | 7/30 [47:13<2:35:40, 406.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.709947109222412\n",
      "GCN acc on unlabled data: 0.648\n",
      "attack loss: 1.701985478401184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  27%|██▋       | 8/30 [54:06<2:29:45, 408.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.702980875968933\n",
      "GCN acc on unlabled data: 0.67\n",
      "attack loss: 1.6949939727783203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  30%|███       | 9/30 [1:00:58<2:23:17, 409.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7054475545883179\n",
      "GCN acc on unlabled data: 0.662\n",
      "attack loss: 1.6969906091690063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  33%|███▎      | 10/30 [1:07:44<2:16:07, 408.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7079914808273315\n",
      "GCN acc on unlabled data: 0.662\n",
      "attack loss: 1.700253963470459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  37%|███▋      | 11/30 [1:14:20<2:08:10, 404.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7079408168792725\n",
      "GCN acc on unlabled data: 0.653\n",
      "attack loss: 1.6997952461242676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  40%|████      | 12/30 [1:19:56<1:55:10, 383.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7060096263885498\n",
      "GCN acc on unlabled data: 0.665\n",
      "attack loss: 1.6969232559204102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  43%|████▎     | 13/30 [1:24:42<1:40:21, 354.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7063648700714111\n",
      "GCN acc on unlabled data: 0.647\n",
      "attack loss: 1.6984854936599731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  47%|████▋     | 14/30 [1:29:21<1:28:22, 331.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.707902431488037\n",
      "GCN acc on unlabled data: 0.669\n",
      "attack loss: 1.6995694637298584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  50%|█████     | 15/30 [1:33:53<1:18:20, 313.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7079473733901978\n",
      "GCN acc on unlabled data: 0.678\n",
      "attack loss: 1.6999151706695557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  53%|█████▎    | 16/30 [1:38:35<1:10:56, 304.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7139700651168823\n",
      "GCN acc on unlabled data: 0.67\n",
      "attack loss: 1.7050840854644775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  57%|█████▋    | 17/30 [1:43:17<1:04:27, 297.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7144657373428345\n",
      "GCN acc on unlabled data: 0.663\n",
      "attack loss: 1.7062238454818726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  60%|██████    | 18/30 [1:47:55<58:17, 291.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7105119228363037\n",
      "GCN acc on unlabled data: 0.676\n",
      "attack loss: 1.70389986038208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  63%|██████▎   | 19/30 [1:52:25<52:16, 285.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7127450704574585\n",
      "GCN acc on unlabled data: 0.67\n",
      "attack loss: 1.7054979801177979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  67%|██████▋   | 20/30 [1:57:00<47:01, 282.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7106059789657593\n",
      "GCN acc on unlabled data: 0.665\n",
      "attack loss: 1.7028342485427856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  70%|███████   | 21/30 [2:01:27<41:37, 277.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.717952013015747\n",
      "GCN acc on unlabled data: 0.654\n",
      "attack loss: 1.7104650735855103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  73%|███████▎  | 22/30 [2:03:51<31:39, 237.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7105220556259155\n",
      "GCN acc on unlabled data: 0.678\n",
      "attack loss: 1.7041622400283813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  77%|███████▋  | 23/30 [2:06:13<24:22, 208.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7174311876296997\n",
      "GCN acc on unlabled data: 0.643\n",
      "attack loss: 1.7108784914016724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  80%|████████  | 24/30 [2:08:36<18:54, 189.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7162915468215942\n",
      "GCN acc on unlabled data: 0.653\n",
      "attack loss: 1.709359884262085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  83%|████████▎ | 25/30 [2:10:57<14:32, 174.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7181878089904785\n",
      "GCN acc on unlabled data: 0.63\n",
      "attack loss: 1.7105909585952759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  87%|████████▋ | 26/30 [2:13:17<10:57, 164.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7214893102645874\n",
      "GCN acc on unlabled data: 0.657\n",
      "attack loss: 1.7147250175476074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  90%|█████████ | 27/30 [2:15:35<07:48, 156.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7205487489700317\n",
      "GCN acc on unlabled data: 0.637\n",
      "attack loss: 1.7131311893463135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  93%|█████████▎| 28/30 [2:17:54<05:02, 151.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7178038358688354\n",
      "GCN acc on unlabled data: 0.647\n",
      "attack loss: 1.7110645771026611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  97%|█████████▋| 29/30 [2:20:15<02:28, 148.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7221990823745728\n",
      "GCN acc on unlabled data: 0.673\n",
      "attack loss: 1.7169256210327148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph: 100%|██████████| 30/30 [2:22:37<00:00, 285.27s/it]\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "from utils import *\n",
    "from models import GCN, PTDNetGCN\n",
    "from metrics import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "# Settings\n",
    "dataset_name='citeseer'\n",
    "args.dataset=dataset_name\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(args.dataset)\n",
    "all_labels = y_train + y_test+y_val\n",
    "single_label = np.argmax(all_labels,axis=-1)\n",
    "nodesize = features.shape[0]\n",
    "\n",
    "# Some preprocessing\n",
    "features_tmp=features.copy()\n",
    "features = preprocess_features(features).A\n",
    "support = preprocess_adj(adj)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "\n",
    "tuple_adj = sparse_to_tuple(adj.tocoo())\n",
    "features_tensor = tf.convert_to_tensor(features,dtype=dtype)\n",
    "adj_tensor = tf.SparseTensor(*tuple_adj)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train,dtype=dtype)\n",
    "train_mask_tensor = tf.convert_to_tensor(train_mask)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test,dtype=dtype)\n",
    "test_mask_tensor = tf.convert_to_tensor(test_mask)\n",
    "y_val_tensor = tf.convert_to_tensor(y_val,dtype=dtype)\n",
    "val_mask_tensor = tf.convert_to_tensor(val_mask)\n",
    "\n",
    "best_test_acc = 0\n",
    "best_val_acc_trail = 0\n",
    "best_val_loss = 10000\n",
    "\n",
    "from deeprobust.graph.data import Dataset\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.global_attack import Metattack\n",
    "# Setup Surrogate model\n",
    "idx_train=np.array(np.where(train_mask==1)).tolist()[0]\n",
    "idx_val=np.array(np.where(val_mask==1)).tolist()[0]\n",
    "idx_unlabeled=np.array(np.where(test_mask==1)).tolist()[0]\n",
    "surrogate = GCN(nfeat=features.shape[1], nclass=single_label.max().item()+1,\n",
    "                nhid=256, dropout=0, with_relu=False, with_bias=False, device='cpu').to('cpu')\n",
    "surrogate.fit(features, adj, single_label, idx_train, idx_val, patience=100)\n",
    "# Setup Attack Model\n",
    "model = Metattack(surrogate, nnodes=adj.shape[0], feature_shape=features.shape,\n",
    "        attack_structure=True, attack_features=False, device='cpu', lambda_=0).to('cpu')\n",
    "# Attack\n",
    "model.attack(features, adj, single_label, idx_train, idx_unlabeled, n_perturbations=30, ll_constraint=False)\n",
    "modified_adj = model.modified_adj\n",
    "# print(adj)\n",
    "# print(\"shiy\")\n",
    "# print(modified_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_adj=sp.csr_array(modified_adj.int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zsp/ljx/PTDNet/utils.py:221: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fac61ad9ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fac61ad9ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "edge_vol 4671.43\n",
      "Epoch: 0001 train_loss= 1.79189 val_loss= 1.79109 train_acc= 0.39167 val_acc= 0.27000 best_val_acc_trail= 0.27000 test_acc= 0.26100\n",
      "time  5.9573376178741455\n",
      "edge_vol 4659.8486\n",
      "Epoch: 0002 train_loss= 1.78970 val_loss= 1.79038 train_acc= 0.65833 val_acc= 0.33600 best_val_acc_trail= 0.33600 test_acc= 0.34200\n",
      "time  7.130953788757324\n",
      "edge_vol 4647.836\n",
      "Epoch: 0003 train_loss= 1.78745 val_loss= 1.78965 train_acc= 0.83333 val_acc= 0.39600 best_val_acc_trail= 0.39600 test_acc= 0.40600\n",
      "time  7.9679787158966064\n",
      "edge_vol 4635.4077\n",
      "Epoch: 0004 train_loss= 1.78523 val_loss= 1.78887 train_acc= 0.88333 val_acc= 0.43400 best_val_acc_trail= 0.43400 test_acc= 0.46100\n",
      "time  8.696791887283325\n",
      "edge_vol 4622.6357\n",
      "Epoch: 0005 train_loss= 1.78293 val_loss= 1.78803 train_acc= 0.89167 val_acc= 0.47000 best_val_acc_trail= 0.47000 test_acc= 0.49900\n",
      "time  9.55448055267334\n",
      "edge_vol 4609.619\n",
      "Epoch: 0006 train_loss= 1.78057 val_loss= 1.78713 train_acc= 0.89167 val_acc= 0.49800 best_val_acc_trail= 0.49800 test_acc= 0.52800\n",
      "time  10.75309157371521\n",
      "edge_vol 4596.3984\n",
      "Epoch: 0007 train_loss= 1.77802 val_loss= 1.78614 train_acc= 0.89167 val_acc= 0.53800 best_val_acc_trail= 0.53800 test_acc= 0.54400\n",
      "time  12.113321781158447\n",
      "edge_vol 4583.087\n",
      "Epoch: 0008 train_loss= 1.77540 val_loss= 1.78506 train_acc= 0.90833 val_acc= 0.55400 best_val_acc_trail= 0.55400 test_acc= 0.56000\n",
      "time  13.151908874511719\n",
      "edge_vol 4569.62\n",
      "Epoch: 0009 train_loss= 1.77268 val_loss= 1.78390 train_acc= 0.90833 val_acc= 0.55800 best_val_acc_trail= 0.55800 test_acc= 0.57000\n",
      "time  14.355727672576904\n",
      "edge_vol 4556.001\n",
      "Epoch: 0010 train_loss= 1.76960 val_loss= 1.78265 train_acc= 0.90833 val_acc= 0.56800 best_val_acc_trail= 0.56800 test_acc= 0.59500\n",
      "time  15.699389696121216\n",
      "edge_vol 4542.2393\n",
      "Epoch: 0011 train_loss= 1.76652 val_loss= 1.78133 train_acc= 0.90833 val_acc= 0.58400 best_val_acc_trail= 0.58400 test_acc= 0.60500\n",
      "time  16.46635341644287\n",
      "edge_vol 4528.325\n",
      "Epoch: 0012 train_loss= 1.76318 val_loss= 1.77993 train_acc= 0.90833 val_acc= 0.60800 best_val_acc_trail= 0.60800 test_acc= 0.61100\n",
      "time  17.624972820281982\n",
      "edge_vol 4514.265\n",
      "Epoch: 0013 train_loss= 1.75962 val_loss= 1.77847 train_acc= 0.90833 val_acc= 0.61800 best_val_acc_trail= 0.61800 test_acc= 0.61600\n",
      "time  18.66260313987732\n",
      "edge_vol 4500.026\n",
      "Epoch: 0014 train_loss= 1.75609 val_loss= 1.77693 train_acc= 0.90833 val_acc= 0.63000 best_val_acc_trail= 0.63000 test_acc= 0.61900\n",
      "time  19.939892530441284\n",
      "edge_vol 4485.624\n",
      "Epoch: 0015 train_loss= 1.75224 val_loss= 1.77535 train_acc= 0.90833 val_acc= 0.63800 best_val_acc_trail= 0.63800 test_acc= 0.62300\n",
      "time  21.107354402542114\n",
      "edge_vol 4471.0444\n",
      "Epoch: 0016 train_loss= 1.74824 val_loss= 1.77370 train_acc= 0.91667 val_acc= 0.64600 best_val_acc_trail= 0.64600 test_acc= 0.63100\n",
      "time  22.548304557800293\n",
      "edge_vol 4456.2803\n",
      "Epoch: 0017 train_loss= 1.74400 val_loss= 1.77201 train_acc= 0.90833 val_acc= 0.64800 best_val_acc_trail= 0.64800 test_acc= 0.63700\n",
      "time  23.86520528793335\n",
      "edge_vol 4441.3667\n",
      "Epoch: 0018 train_loss= 1.73920 val_loss= 1.77025 train_acc= 0.91667 val_acc= 0.65000 best_val_acc_trail= 0.65000 test_acc= 0.64500\n",
      "time  25.06196355819702\n",
      "edge_vol 4426.2617\n",
      "Epoch: 0019 train_loss= 1.73523 val_loss= 1.76843 train_acc= 0.91667 val_acc= 0.65000 best_val_acc_trail= 0.65000 test_acc= 0.64500\n",
      "time  26.343668699264526\n",
      "edge_vol 4410.9824\n",
      "Epoch: 0020 train_loss= 1.73071 val_loss= 1.76658 train_acc= 0.91667 val_acc= 0.65400 best_val_acc_trail= 0.65400 test_acc= 0.65200\n",
      "time  27.70593523979187\n",
      "edge_vol 4395.5312\n",
      "Epoch: 0021 train_loss= 1.72537 val_loss= 1.76468 train_acc= 0.91667 val_acc= 0.65600 best_val_acc_trail= 0.65600 test_acc= 0.65400\n",
      "time  28.54962658882141\n",
      "edge_vol 4379.9214\n",
      "Epoch: 0022 train_loss= 1.72089 val_loss= 1.76275 train_acc= 0.91667 val_acc= 0.65800 best_val_acc_trail= 0.65800 test_acc= 0.65500\n",
      "time  29.81167960166931\n",
      "edge_vol 4364.126\n",
      "Epoch: 0023 train_loss= 1.71577 val_loss= 1.76077 train_acc= 0.91667 val_acc= 0.66000 best_val_acc_trail= 0.66000 test_acc= 0.65700\n",
      "time  30.894782066345215\n",
      "edge_vol 4348.157\n",
      "Epoch: 0024 train_loss= 1.71088 val_loss= 1.75877 train_acc= 0.91667 val_acc= 0.66200 best_val_acc_trail= 0.66200 test_acc= 0.65300\n",
      "time  31.984084844589233\n",
      "edge_vol 4331.984\n",
      "Epoch: 0025 train_loss= 1.70500 val_loss= 1.75673 train_acc= 0.91667 val_acc= 0.65800 best_val_acc_trail= 0.66200 test_acc= 0.65300\n",
      "time  33.12785863876343\n",
      "edge_vol 4315.58\n",
      "Epoch: 0026 train_loss= 1.69970 val_loss= 1.75468 train_acc= 0.91667 val_acc= 0.65800 best_val_acc_trail= 0.66200 test_acc= 0.65300\n",
      "time  34.12263560295105\n",
      "edge_vol 4299.002\n",
      "Epoch: 0027 train_loss= 1.69399 val_loss= 1.75259 train_acc= 0.91667 val_acc= 0.66000 best_val_acc_trail= 0.66200 test_acc= 0.65300\n",
      "time  35.38043785095215\n",
      "edge_vol 4282.2427\n",
      "Epoch: 0028 train_loss= 1.68868 val_loss= 1.75045 train_acc= 0.91667 val_acc= 0.66000 best_val_acc_trail= 0.66200 test_acc= 0.65300\n",
      "time  36.56991624832153\n",
      "edge_vol 4265.2734\n",
      "Epoch: 0029 train_loss= 1.68277 val_loss= 1.74828 train_acc= 0.92500 val_acc= 0.66000 best_val_acc_trail= 0.66200 test_acc= 0.65300\n",
      "time  37.81066656112671\n",
      "edge_vol 4248.1387\n",
      "Epoch: 0030 train_loss= 1.67698 val_loss= 1.74609 train_acc= 0.92500 val_acc= 0.65600 best_val_acc_trail= 0.66200 test_acc= 0.65300\n",
      "time  39.017919301986694\n",
      "edge_vol 4230.7827\n",
      "Epoch: 0031 train_loss= 1.66996 val_loss= 1.74387 train_acc= 0.92500 val_acc= 0.65600 best_val_acc_trail= 0.66200 test_acc= 0.65300\n",
      "time  39.90815234184265\n",
      "edge_vol 4213.2217\n",
      "Epoch: 0032 train_loss= 1.66525 val_loss= 1.74162 train_acc= 0.92500 val_acc= 0.65600 best_val_acc_trail= 0.66200 test_acc= 0.65300\n",
      "time  41.06212615966797\n",
      "edge_vol 4195.4404\n",
      "Epoch: 0033 train_loss= 1.65818 val_loss= 1.73933 train_acc= 0.93333 val_acc= 0.66200 best_val_acc_trail= 0.66200 test_acc= 0.65300\n",
      "time  42.362632751464844\n",
      "edge_vol 4177.4272\n",
      "Epoch: 0034 train_loss= 1.65212 val_loss= 1.73702 train_acc= 0.93333 val_acc= 0.66600 best_val_acc_trail= 0.66600 test_acc= 0.65900\n",
      "time  43.673821210861206\n",
      "edge_vol 4159.2363\n",
      "Epoch: 0035 train_loss= 1.64525 val_loss= 1.73470 train_acc= 0.93333 val_acc= 0.66600 best_val_acc_trail= 0.66600 test_acc= 0.65900\n",
      "time  45.009772062301636\n",
      "edge_vol 4140.787\n",
      "Epoch: 0036 train_loss= 1.63867 val_loss= 1.73234 train_acc= 0.93333 val_acc= 0.66800 best_val_acc_trail= 0.66800 test_acc= 0.65800\n",
      "time  46.23869347572327\n",
      "edge_vol 4122.1084\n",
      "Epoch: 0037 train_loss= 1.63091 val_loss= 1.72997 train_acc= 0.93333 val_acc= 0.66800 best_val_acc_trail= 0.66800 test_acc= 0.65800\n",
      "time  47.32779097557068\n",
      "edge_vol 4103.283\n",
      "Epoch: 0038 train_loss= 1.62590 val_loss= 1.72757 train_acc= 0.93333 val_acc= 0.66600 best_val_acc_trail= 0.66800 test_acc= 0.65800\n",
      "time  48.590741872787476\n",
      "edge_vol 4084.3296\n",
      "Epoch: 0039 train_loss= 1.61763 val_loss= 1.72514 train_acc= 0.93333 val_acc= 0.66600 best_val_acc_trail= 0.66800 test_acc= 0.65800\n",
      "time  49.81931161880493\n",
      "edge_vol 4065.159\n",
      "Epoch: 0040 train_loss= 1.61249 val_loss= 1.72269 train_acc= 0.94167 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.66000\n",
      "time  51.15048003196716\n",
      "edge_vol 4045.7903\n",
      "Epoch: 0041 train_loss= 1.60510 val_loss= 1.72021 train_acc= 0.94167 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.66000\n",
      "time  52.353283643722534\n",
      "edge_vol 4026.269\n",
      "Epoch: 0042 train_loss= 1.59783 val_loss= 1.71771 train_acc= 0.94167 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.66000\n",
      "time  53.57150173187256\n",
      "edge_vol 4006.4858\n",
      "Epoch: 0043 train_loss= 1.59082 val_loss= 1.71521 train_acc= 0.94167 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.66000\n",
      "time  54.97766399383545\n",
      "edge_vol 3986.4639\n",
      "Epoch: 0044 train_loss= 1.58209 val_loss= 1.71268 train_acc= 0.94167 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.66000\n",
      "time  56.318052768707275\n",
      "edge_vol 3966.2678\n",
      "Epoch: 0045 train_loss= 1.57853 val_loss= 1.71016 train_acc= 0.94167 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.66000\n",
      "time  57.02537226676941\n",
      "edge_vol 3945.9248\n",
      "Epoch: 0046 train_loss= 1.56876 val_loss= 1.70766 train_acc= 0.94167 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.66000\n",
      "time  58.0266535282135\n",
      "edge_vol 3925.39\n",
      "Epoch: 0047 train_loss= 1.56051 val_loss= 1.70516 train_acc= 0.94167 val_acc= 0.67200 best_val_acc_trail= 0.67400 test_acc= 0.66000\n",
      "time  59.07976675033569\n",
      "edge_vol 3904.8125\n",
      "Epoch: 0048 train_loss= 1.55526 val_loss= 1.70266 train_acc= 0.94167 val_acc= 0.67200 best_val_acc_trail= 0.67400 test_acc= 0.66000\n",
      "time  60.004332542419434\n",
      "edge_vol 3883.994\n",
      "Epoch: 0049 train_loss= 1.54793 val_loss= 1.70018 train_acc= 0.94167 val_acc= 0.67200 best_val_acc_trail= 0.67400 test_acc= 0.66000\n",
      "time  60.82073974609375\n",
      "edge_vol 3862.9915\n",
      "Epoch: 0050 train_loss= 1.53936 val_loss= 1.69773 train_acc= 0.94167 val_acc= 0.67200 best_val_acc_trail= 0.67400 test_acc= 0.66000\n",
      "time  61.65754699707031\n",
      "edge_vol 3841.738\n",
      "Epoch: 0051 train_loss= 1.53005 val_loss= 1.69529 train_acc= 0.94167 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.66300\n",
      "time  62.20902228355408\n",
      "edge_vol 3820.4133\n",
      "Epoch: 0052 train_loss= 1.52418 val_loss= 1.69287 train_acc= 0.94167 val_acc= 0.67600 best_val_acc_trail= 0.67600 test_acc= 0.66300\n",
      "time  63.0743203163147\n",
      "edge_vol 3798.9397\n",
      "Epoch: 0053 train_loss= 1.51774 val_loss= 1.69047 train_acc= 0.95000 val_acc= 0.67200 best_val_acc_trail= 0.67600 test_acc= 0.66300\n",
      "time  64.1890754699707\n",
      "edge_vol 3777.228\n",
      "Epoch: 0054 train_loss= 1.50965 val_loss= 1.68811 train_acc= 0.95000 val_acc= 0.67400 best_val_acc_trail= 0.67600 test_acc= 0.66300\n",
      "time  65.47090864181519\n",
      "edge_vol 3755.273\n",
      "Epoch: 0055 train_loss= 1.50028 val_loss= 1.68579 train_acc= 0.95000 val_acc= 0.67400 best_val_acc_trail= 0.67600 test_acc= 0.66300\n",
      "time  66.44081258773804\n",
      "edge_vol 3733.2124\n",
      "Epoch: 0056 train_loss= 1.49197 val_loss= 1.68353 train_acc= 0.96667 val_acc= 0.67400 best_val_acc_trail= 0.67600 test_acc= 0.66300\n",
      "time  67.66722249984741\n",
      "edge_vol 3710.8975\n",
      "Epoch: 0057 train_loss= 1.48531 val_loss= 1.68130 train_acc= 0.96667 val_acc= 0.67200 best_val_acc_trail= 0.67600 test_acc= 0.66300\n",
      "time  68.64510560035706\n",
      "edge_vol 3688.366\n",
      "Epoch: 0058 train_loss= 1.47673 val_loss= 1.67908 train_acc= 0.96667 val_acc= 0.67400 best_val_acc_trail= 0.67600 test_acc= 0.66300\n",
      "time  69.8458321094513\n",
      "edge_vol 3665.699\n",
      "Epoch: 0059 train_loss= 1.47188 val_loss= 1.67691 train_acc= 0.96667 val_acc= 0.67200 best_val_acc_trail= 0.67600 test_acc= 0.66300\n",
      "time  70.94779300689697\n",
      "edge_vol 3642.8984\n",
      "Epoch: 0060 train_loss= 1.46145 val_loss= 1.67482 train_acc= 0.96667 val_acc= 0.67200 best_val_acc_trail= 0.67600 test_acc= 0.66300\n",
      "time  72.29131364822388\n",
      "edge_vol 3619.8643\n",
      "Epoch: 0061 train_loss= 1.45626 val_loss= 1.67276 train_acc= 0.96667 val_acc= 0.67400 best_val_acc_trail= 0.67600 test_acc= 0.66300\n",
      "time  73.41923975944519\n",
      "edge_vol 3596.6548\n",
      "Epoch: 0062 train_loss= 1.44618 val_loss= 1.67072 train_acc= 0.96667 val_acc= 0.67400 best_val_acc_trail= 0.67600 test_acc= 0.66300\n",
      "time  74.29143929481506\n",
      "edge_vol 3573.166\n",
      "Epoch: 0063 train_loss= 1.43476 val_loss= 1.66872 train_acc= 0.97500 val_acc= 0.67800 best_val_acc_trail= 0.67800 test_acc= 0.67100\n",
      "time  75.48202681541443\n",
      "edge_vol 3549.7476\n",
      "Epoch: 0064 train_loss= 1.43333 val_loss= 1.66676 train_acc= 0.97500 val_acc= 0.67800 best_val_acc_trail= 0.67800 test_acc= 0.67100\n",
      "time  76.82789421081543\n",
      "edge_vol 3526.2822\n",
      "Epoch: 0065 train_loss= 1.42463 val_loss= 1.66488 train_acc= 0.97500 val_acc= 0.67600 best_val_acc_trail= 0.67800 test_acc= 0.67100\n",
      "time  78.02218747138977\n",
      "edge_vol 3502.6946\n",
      "Epoch: 0066 train_loss= 1.42135 val_loss= 1.66312 train_acc= 0.98333 val_acc= 0.67800 best_val_acc_trail= 0.67800 test_acc= 0.67100\n",
      "time  79.50229597091675\n",
      "edge_vol 3478.9824\n",
      "Epoch: 0067 train_loss= 1.41129 val_loss= 1.66147 train_acc= 0.99167 val_acc= 0.67600 best_val_acc_trail= 0.67800 test_acc= 0.67100\n",
      "time  80.5724663734436\n",
      "edge_vol 3455.097\n",
      "Epoch: 0068 train_loss= 1.40356 val_loss= 1.65992 train_acc= 0.99167 val_acc= 0.67600 best_val_acc_trail= 0.67800 test_acc= 0.67100\n",
      "time  82.0661952495575\n",
      "edge_vol 3431.1377\n",
      "Epoch: 0069 train_loss= 1.39813 val_loss= 1.65838 train_acc= 0.99167 val_acc= 0.67800 best_val_acc_trail= 0.67800 test_acc= 0.67100\n",
      "time  83.33267593383789\n",
      "edge_vol 3406.9119\n",
      "Epoch: 0070 train_loss= 1.38624 val_loss= 1.65695 train_acc= 0.99167 val_acc= 0.67800 best_val_acc_trail= 0.67800 test_acc= 0.67100\n",
      "time  84.72922825813293\n",
      "edge_vol 3382.4116\n",
      "Epoch: 0071 train_loss= 1.38135 val_loss= 1.65557 train_acc= 0.99167 val_acc= 0.67800 best_val_acc_trail= 0.67800 test_acc= 0.67100\n",
      "time  86.00451135635376\n",
      "edge_vol 3357.678\n",
      "Epoch: 0072 train_loss= 1.37362 val_loss= 1.65428 train_acc= 0.99167 val_acc= 0.68000 best_val_acc_trail= 0.68000 test_acc= 0.67000\n",
      "time  87.32015776634216\n",
      "edge_vol 3332.6943\n",
      "Epoch: 0073 train_loss= 1.36591 val_loss= 1.65302 train_acc= 0.99167 val_acc= 0.67800 best_val_acc_trail= 0.68000 test_acc= 0.67000\n",
      "time  88.75966572761536\n",
      "edge_vol 3307.4802\n",
      "Epoch: 0074 train_loss= 1.36063 val_loss= 1.65189 train_acc= 0.99167 val_acc= 0.68000 best_val_acc_trail= 0.68000 test_acc= 0.67000\n",
      "time  89.98812055587769\n",
      "edge_vol 3282.0024\n",
      "Epoch: 0075 train_loss= 1.35157 val_loss= 1.65080 train_acc= 0.99167 val_acc= 0.67800 best_val_acc_trail= 0.68000 test_acc= 0.67000\n",
      "time  91.50692939758301\n",
      "edge_vol 3255.9478\n",
      "Epoch: 0076 train_loss= 1.34595 val_loss= 1.64980 train_acc= 0.99167 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.67100\n",
      "time  92.66534662246704\n",
      "edge_vol 3229.425\n",
      "Epoch: 0077 train_loss= 1.34473 val_loss= 1.64899 train_acc= 0.99167 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.67100\n",
      "time  94.27291250228882\n",
      "edge_vol 3202.398\n",
      "Epoch: 0078 train_loss= 1.33456 val_loss= 1.64819 train_acc= 0.99167 val_acc= 0.68000 best_val_acc_trail= 0.68200 test_acc= 0.67100\n",
      "time  95.59529733657837\n",
      "edge_vol 3175.2585\n",
      "Epoch: 0079 train_loss= 1.32960 val_loss= 1.64757 train_acc= 0.99167 val_acc= 0.68000 best_val_acc_trail= 0.68200 test_acc= 0.67100\n",
      "time  96.75813746452332\n",
      "edge_vol 3147.6963\n",
      "Epoch: 0080 train_loss= 1.31971 val_loss= 1.64703 train_acc= 0.99167 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.67100\n",
      "time  98.15960478782654\n",
      "edge_vol 3119.627\n",
      "Epoch: 0081 train_loss= 1.31824 val_loss= 1.64652 train_acc= 0.99167 val_acc= 0.68400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  99.40299773216248\n",
      "edge_vol 3091.102\n",
      "Epoch: 0082 train_loss= 1.30652 val_loss= 1.64599 train_acc= 0.99167 val_acc= 0.68200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  100.80910992622375\n",
      "edge_vol 3062.3984\n",
      "Epoch: 0083 train_loss= 1.30515 val_loss= 1.64548 train_acc= 0.99167 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  102.37166404724121\n",
      "edge_vol 3033.6653\n",
      "Epoch: 0084 train_loss= 1.29963 val_loss= 1.64516 train_acc= 0.99167 val_acc= 0.68200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  104.27505731582642\n",
      "edge_vol 3004.6562\n",
      "Epoch: 0085 train_loss= 1.29391 val_loss= 1.64488 train_acc= 0.99167 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  105.93090391159058\n",
      "edge_vol 2975.1733\n",
      "Epoch: 0086 train_loss= 1.28769 val_loss= 1.64465 train_acc= 0.99167 val_acc= 0.68200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  107.02018427848816\n",
      "edge_vol 2945.1367\n",
      "Epoch: 0087 train_loss= 1.28193 val_loss= 1.64447 train_acc= 0.99167 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  108.41214847564697\n",
      "edge_vol 2915.1292\n",
      "Epoch: 0088 train_loss= 1.27530 val_loss= 1.64430 train_acc= 0.99167 val_acc= 0.68000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  109.66355180740356\n",
      "edge_vol 2885.1245\n",
      "Epoch: 0089 train_loss= 1.26467 val_loss= 1.64414 train_acc= 0.99167 val_acc= 0.67400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  110.82842755317688\n",
      "edge_vol 2854.4736\n",
      "Epoch: 0090 train_loss= 1.26601 val_loss= 1.64391 train_acc= 0.99167 val_acc= 0.67200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  112.09393787384033\n",
      "edge_vol 2823.6267\n",
      "Epoch: 0091 train_loss= 1.25983 val_loss= 1.64379 train_acc= 0.99167 val_acc= 0.67400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  113.74329209327698\n",
      "edge_vol 2792.895\n",
      "Epoch: 0092 train_loss= 1.25194 val_loss= 1.64373 train_acc= 0.99167 val_acc= 0.67200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  114.51993370056152\n",
      "edge_vol 2761.6587\n",
      "Epoch: 0093 train_loss= 1.25223 val_loss= 1.64371 train_acc= 0.99167 val_acc= 0.67400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  115.29638242721558\n",
      "edge_vol 2729.9702\n",
      "Epoch: 0094 train_loss= 1.24046 val_loss= 1.64363 train_acc= 0.99167 val_acc= 0.67400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  117.1713457107544\n",
      "edge_vol 2697.2974\n",
      "Epoch: 0095 train_loss= 1.23914 val_loss= 1.64362 train_acc= 0.99167 val_acc= 0.67600 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  118.79340195655823\n",
      "edge_vol 2664.2646\n",
      "Epoch: 0096 train_loss= 1.24212 val_loss= 1.64362 train_acc= 1.00000 val_acc= 0.67400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  120.00939798355103\n",
      "edge_vol 2630.8228\n",
      "Epoch: 0097 train_loss= 1.23402 val_loss= 1.64372 train_acc= 1.00000 val_acc= 0.67200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  121.30867052078247\n",
      "edge_vol 2596.7393\n",
      "Epoch: 0098 train_loss= 1.22183 val_loss= 1.64376 train_acc= 1.00000 val_acc= 0.66800 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  122.1740186214447\n",
      "edge_vol 2562.2014\n",
      "Epoch: 0099 train_loss= 1.21305 val_loss= 1.64376 train_acc= 1.00000 val_acc= 0.67000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  123.66576957702637\n",
      "edge_vol 2526.3372\n",
      "Epoch: 0100 train_loss= 1.20970 val_loss= 1.64365 train_acc= 1.00000 val_acc= 0.66800 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  124.97540307044983\n",
      "edge_vol 2489.768\n",
      "Epoch: 0101 train_loss= 1.21514 val_loss= 1.64354 train_acc= 1.00000 val_acc= 0.66800 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  126.75716376304626\n",
      "edge_vol 2452.731\n",
      "Epoch: 0102 train_loss= 1.20569 val_loss= 1.64353 train_acc= 1.00000 val_acc= 0.67000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  128.45245003700256\n",
      "edge_vol 2414.8838\n",
      "Epoch: 0103 train_loss= 1.19469 val_loss= 1.64352 train_acc= 1.00000 val_acc= 0.67000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  129.0194172859192\n",
      "edge_vol 2376.5283\n",
      "Epoch: 0104 train_loss= 1.19442 val_loss= 1.64348 train_acc= 1.00000 val_acc= 0.66800 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  129.90272188186646\n",
      "edge_vol 2337.9517\n",
      "Epoch: 0105 train_loss= 1.18705 val_loss= 1.64346 train_acc= 1.00000 val_acc= 0.67000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  131.3662269115448\n",
      "edge_vol 2298.957\n",
      "Epoch: 0106 train_loss= 1.18762 val_loss= 1.64355 train_acc= 1.00000 val_acc= 0.66800 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  132.81626272201538\n",
      "edge_vol 2259.132\n",
      "Epoch: 0107 train_loss= 1.18115 val_loss= 1.64360 train_acc= 1.00000 val_acc= 0.66600 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  134.3869824409485\n",
      "edge_vol 2219.3328\n",
      "Epoch: 0108 train_loss= 1.18179 val_loss= 1.64375 train_acc= 1.00000 val_acc= 0.66600 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  135.53482365608215\n",
      "edge_vol 2178.634\n",
      "Epoch: 0109 train_loss= 1.16137 val_loss= 1.64383 train_acc= 1.00000 val_acc= 0.66200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  136.71970558166504\n",
      "edge_vol 2137.3022\n",
      "Epoch: 0110 train_loss= 1.16640 val_loss= 1.64387 train_acc= 1.00000 val_acc= 0.66200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  137.52798295021057\n",
      "edge_vol 2095.5098\n",
      "Epoch: 0111 train_loss= 1.15770 val_loss= 1.64412 train_acc= 1.00000 val_acc= 0.66400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  138.38099122047424\n",
      "edge_vol 2053.457\n",
      "Epoch: 0112 train_loss= 1.15439 val_loss= 1.64420 train_acc= 1.00000 val_acc= 0.65800 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  140.45232367515564\n",
      "edge_vol 2010.8159\n",
      "Epoch: 0113 train_loss= 1.15031 val_loss= 1.64428 train_acc= 1.00000 val_acc= 0.65600 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  141.8770079612732\n",
      "edge_vol 1967.6135\n",
      "Epoch: 0114 train_loss= 1.14654 val_loss= 1.64420 train_acc= 1.00000 val_acc= 0.65800 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  143.20749473571777\n",
      "edge_vol 1924.4873\n",
      "Epoch: 0115 train_loss= 1.14676 val_loss= 1.64409 train_acc= 1.00000 val_acc= 0.66000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  144.4611530303955\n",
      "edge_vol 1881.3936\n",
      "Epoch: 0116 train_loss= 1.14335 val_loss= 1.64376 train_acc= 1.00000 val_acc= 0.65600 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  145.73567128181458\n",
      "edge_vol 1838.259\n",
      "Epoch: 0117 train_loss= 1.12625 val_loss= 1.64335 train_acc= 1.00000 val_acc= 0.65200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  146.50353717803955\n",
      "edge_vol 1794.8108\n",
      "Epoch: 0118 train_loss= 1.12073 val_loss= 1.64289 train_acc= 1.00000 val_acc= 0.65400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  147.62228798866272\n",
      "edge_vol 1751.9019\n",
      "Epoch: 0119 train_loss= 1.12054 val_loss= 1.64244 train_acc= 1.00000 val_acc= 0.65200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  148.8100242614746\n",
      "edge_vol 1708.535\n",
      "Epoch: 0120 train_loss= 1.11633 val_loss= 1.64201 train_acc= 1.00000 val_acc= 0.65200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  150.11645364761353\n",
      "edge_vol 1665.1694\n",
      "Epoch: 0121 train_loss= 1.10900 val_loss= 1.64164 train_acc= 1.00000 val_acc= 0.65400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  152.26213216781616\n",
      "edge_vol 1622.0061\n",
      "Epoch: 0122 train_loss= 1.09876 val_loss= 1.64135 train_acc= 1.00000 val_acc= 0.65200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  153.86032819747925\n",
      "edge_vol 1579.1387\n",
      "Epoch: 0123 train_loss= 1.09201 val_loss= 1.64101 train_acc= 1.00000 val_acc= 0.65600 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  155.3011553287506\n",
      "edge_vol 1536.3538\n",
      "Epoch: 0124 train_loss= 1.09431 val_loss= 1.64082 train_acc= 1.00000 val_acc= 0.65600 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  156.70771408081055\n",
      "edge_vol 1494.1423\n",
      "Epoch: 0125 train_loss= 1.09013 val_loss= 1.64067 train_acc= 1.00000 val_acc= 0.65400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  158.1711504459381\n",
      "edge_vol 1452.2268\n",
      "Epoch: 0126 train_loss= 1.08181 val_loss= 1.64063 train_acc= 1.00000 val_acc= 0.65400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  159.72251057624817\n",
      "edge_vol 1410.489\n",
      "Epoch: 0127 train_loss= 1.07399 val_loss= 1.64052 train_acc= 1.00000 val_acc= 0.65400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  161.22805094718933\n",
      "edge_vol 1369.0624\n",
      "Epoch: 0128 train_loss= 1.06968 val_loss= 1.64031 train_acc= 1.00000 val_acc= 0.65200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  163.12046480178833\n",
      "edge_vol 1327.9321\n",
      "Epoch: 0129 train_loss= 1.07149 val_loss= 1.64015 train_acc= 1.00000 val_acc= 0.65000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  164.22355365753174\n",
      "edge_vol 1287.596\n",
      "Epoch: 0130 train_loss= 1.06087 val_loss= 1.63996 train_acc= 1.00000 val_acc= 0.65200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  166.07887029647827\n",
      "edge_vol 1247.6041\n",
      "Epoch: 0131 train_loss= 1.05180 val_loss= 1.63981 train_acc= 1.00000 val_acc= 0.65400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  168.09209203720093\n",
      "edge_vol 1208.1501\n",
      "Epoch: 0132 train_loss= 1.05650 val_loss= 1.63980 train_acc= 1.00000 val_acc= 0.65600 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  169.0365023612976\n",
      "edge_vol 1169.2732\n",
      "Epoch: 0133 train_loss= 1.05202 val_loss= 1.63987 train_acc= 1.00000 val_acc= 0.65200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  171.08222651481628\n",
      "edge_vol 1130.8152\n",
      "Epoch: 0134 train_loss= 1.03696 val_loss= 1.63991 train_acc= 1.00000 val_acc= 0.65400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  172.01250433921814\n",
      "edge_vol 1093.5381\n",
      "Epoch: 0135 train_loss= 1.02984 val_loss= 1.63972 train_acc= 1.00000 val_acc= 0.65800 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  175.6428325176239\n",
      "edge_vol 1056.658\n",
      "Epoch: 0136 train_loss= 1.02338 val_loss= 1.63951 train_acc= 1.00000 val_acc= 0.65600 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  176.456130027771\n",
      "edge_vol 1020.19055\n",
      "Epoch: 0137 train_loss= 1.02830 val_loss= 1.63921 train_acc= 1.00000 val_acc= 0.65400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  177.9399712085724\n",
      "edge_vol 984.4394\n",
      "Epoch: 0138 train_loss= 1.01601 val_loss= 1.63889 train_acc= 1.00000 val_acc= 0.65200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  180.1908221244812\n",
      "edge_vol 949.30664\n",
      "Epoch: 0139 train_loss= 1.00415 val_loss= 1.63856 train_acc= 1.00000 val_acc= 0.65000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  181.53332924842834\n",
      "edge_vol 915.063\n",
      "Epoch: 0140 train_loss= 1.00880 val_loss= 1.63797 train_acc= 1.00000 val_acc= 0.64600 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  183.2462441921234\n",
      "edge_vol 881.7371\n",
      "Epoch: 0141 train_loss= 0.99680 val_loss= 1.63714 train_acc= 1.00000 val_acc= 0.64400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  184.60765528678894\n",
      "edge_vol 849.1748\n",
      "Epoch: 0142 train_loss= 0.98733 val_loss= 1.63631 train_acc= 1.00000 val_acc= 0.64400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  185.7716784477234\n",
      "edge_vol 817.58765\n",
      "Epoch: 0143 train_loss= 0.97442 val_loss= 1.63533 train_acc= 1.00000 val_acc= 0.64600 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  188.43821835517883\n",
      "edge_vol 786.9172\n",
      "Epoch: 0144 train_loss= 0.96531 val_loss= 1.63429 train_acc= 1.00000 val_acc= 0.64200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  191.01792192459106\n",
      "edge_vol 757.1127\n",
      "Epoch: 0145 train_loss= 0.96252 val_loss= 1.63321 train_acc= 1.00000 val_acc= 0.64000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  193.12398052215576\n",
      "edge_vol 728.1756\n",
      "Epoch: 0146 train_loss= 0.95670 val_loss= 1.63211 train_acc= 1.00000 val_acc= 0.64000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  193.9070770740509\n",
      "edge_vol 699.9153\n",
      "Epoch: 0147 train_loss= 0.93786 val_loss= 1.63090 train_acc= 1.00000 val_acc= 0.63600 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  195.6136360168457\n",
      "edge_vol 672.53735\n",
      "Epoch: 0148 train_loss= 0.94139 val_loss= 1.62976 train_acc= 1.00000 val_acc= 0.63000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  197.22849202156067\n",
      "edge_vol 646.02484\n",
      "Epoch: 0149 train_loss= 0.92723 val_loss= 1.62879 train_acc= 1.00000 val_acc= 0.63000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  199.7406871318817\n",
      "edge_vol 620.1846\n",
      "Epoch: 0150 train_loss= 0.91010 val_loss= 1.62759 train_acc= 1.00000 val_acc= 0.63200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  201.3968026638031\n",
      "edge_vol 594.90784\n",
      "Epoch: 0151 train_loss= 0.90765 val_loss= 1.62629 train_acc= 1.00000 val_acc= 0.63200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  203.5323097705841\n",
      "edge_vol 570.3335\n",
      "Epoch: 0152 train_loss= 0.89453 val_loss= 1.62498 train_acc= 1.00000 val_acc= 0.63000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  204.55874252319336\n",
      "edge_vol 546.9026\n",
      "Epoch: 0153 train_loss= 0.88431 val_loss= 1.62349 train_acc= 1.00000 val_acc= 0.62800 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  206.3366916179657\n",
      "edge_vol 524.1474\n",
      "Epoch: 0154 train_loss= 0.87138 val_loss= 1.62201 train_acc= 1.00000 val_acc= 0.62400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  207.02852201461792\n",
      "edge_vol 502.3806\n",
      "Epoch: 0155 train_loss= 0.87603 val_loss= 1.62071 train_acc= 1.00000 val_acc= 0.62800 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  209.4914309978485\n",
      "edge_vol 481.52948\n",
      "Epoch: 0156 train_loss= 0.85089 val_loss= 1.61931 train_acc= 1.00000 val_acc= 0.62800 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  211.71517276763916\n",
      "edge_vol 461.25854\n",
      "Epoch: 0157 train_loss= 0.85093 val_loss= 1.61796 train_acc= 1.00000 val_acc= 0.62400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  213.60999035835266\n",
      "edge_vol 441.76318\n",
      "Epoch: 0158 train_loss= 0.82782 val_loss= 1.61654 train_acc= 1.00000 val_acc= 0.62600 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  215.41603469848633\n",
      "edge_vol 422.86298\n",
      "Epoch: 0159 train_loss= 0.83090 val_loss= 1.61512 train_acc= 1.00000 val_acc= 0.62200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  217.00259637832642\n",
      "edge_vol 404.82797\n",
      "Epoch: 0160 train_loss= 0.81547 val_loss= 1.61378 train_acc= 1.00000 val_acc= 0.61800 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  219.78056406974792\n",
      "edge_vol 387.49927\n",
      "Epoch: 0161 train_loss= 0.80091 val_loss= 1.61199 train_acc= 1.00000 val_acc= 0.61600 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  221.96920728683472\n",
      "edge_vol 370.86752\n",
      "Epoch: 0162 train_loss= 0.79226 val_loss= 1.61015 train_acc= 1.00000 val_acc= 0.61400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  223.37822461128235\n",
      "edge_vol 354.98468\n",
      "Epoch: 0163 train_loss= 0.77410 val_loss= 1.60820 train_acc= 1.00000 val_acc= 0.61400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  225.6197772026062\n",
      "edge_vol 339.75797\n",
      "Epoch: 0164 train_loss= 0.76465 val_loss= 1.60638 train_acc= 1.00000 val_acc= 0.61400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  227.40644478797913\n",
      "edge_vol 325.18\n",
      "Epoch: 0165 train_loss= 0.75675 val_loss= 1.60435 train_acc= 1.00000 val_acc= 0.61400 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  228.676575422287\n",
      "edge_vol 311.15396\n",
      "Epoch: 0166 train_loss= 0.75994 val_loss= 1.60241 train_acc= 1.00000 val_acc= 0.62000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  230.5527834892273\n",
      "edge_vol 297.663\n",
      "Epoch: 0167 train_loss= 0.73782 val_loss= 1.60049 train_acc= 1.00000 val_acc= 0.61800 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  232.01138544082642\n",
      "edge_vol 284.77573\n",
      "Epoch: 0168 train_loss= 0.71988 val_loss= 1.59854 train_acc= 1.00000 val_acc= 0.61600 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  233.37836623191833\n",
      "edge_vol 272.34653\n",
      "Epoch: 0169 train_loss= 0.71485 val_loss= 1.59662 train_acc= 1.00000 val_acc= 0.61600 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  235.81259036064148\n",
      "edge_vol 260.47412\n",
      "Epoch: 0170 train_loss= 0.70552 val_loss= 1.59472 train_acc= 1.00000 val_acc= 0.61800 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  237.05279421806335\n",
      "edge_vol 249.13063\n",
      "Epoch: 0171 train_loss= 0.68964 val_loss= 1.59272 train_acc= 1.00000 val_acc= 0.62200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  238.5597903728485\n",
      "edge_vol 238.26442\n",
      "Epoch: 0172 train_loss= 0.68589 val_loss= 1.59047 train_acc= 1.00000 val_acc= 0.62200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  240.1344678401947\n",
      "edge_vol 227.87405\n",
      "Epoch: 0173 train_loss= 0.67227 val_loss= 1.58822 train_acc= 1.00000 val_acc= 0.62000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  241.77259135246277\n",
      "edge_vol 217.93475\n",
      "Epoch: 0174 train_loss= 0.65400 val_loss= 1.58596 train_acc= 1.00000 val_acc= 0.62200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  243.89813089370728\n",
      "edge_vol 208.52449\n",
      "Epoch: 0175 train_loss= 0.64763 val_loss= 1.58341 train_acc= 1.00000 val_acc= 0.62200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  245.35576796531677\n",
      "edge_vol 199.46936\n",
      "Epoch: 0176 train_loss= 0.64116 val_loss= 1.58074 train_acc= 1.00000 val_acc= 0.62000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  246.9512460231781\n",
      "edge_vol 190.61145\n",
      "Epoch: 0177 train_loss= 0.62954 val_loss= 1.57830 train_acc= 1.00000 val_acc= 0.62000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  248.39896631240845\n",
      "edge_vol 182.31319\n",
      "Epoch: 0178 train_loss= 0.61535 val_loss= 1.57586 train_acc= 1.00000 val_acc= 0.61800 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  250.06386828422546\n",
      "edge_vol 174.241\n",
      "Epoch: 0179 train_loss= 0.61132 val_loss= 1.57349 train_acc= 1.00000 val_acc= 0.61800 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  251.42046523094177\n",
      "edge_vol 166.44424\n",
      "Epoch: 0180 train_loss= 0.60320 val_loss= 1.57106 train_acc= 1.00000 val_acc= 0.62000 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  252.8358564376831\n",
      "edge_vol 159.22845\n",
      "Epoch: 0181 train_loss= 0.58746 val_loss= 1.56836 train_acc= 1.00000 val_acc= 0.62200 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "time  254.40424633026123\n",
      "edge_vol 152.45331\n",
      "Epoch: 0182 train_loss= 0.57502 val_loss= 1.56566 train_acc= 1.00000 val_acc= 0.61800 best_val_acc_trail= 0.68400 test_acc= 0.66400\n",
      "Early stopping...\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "from utils import *\n",
    "from models import GCN, PTDNetGCN\n",
    "from metrics import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "# Settings\n",
    "args.dataset=dataset_name\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(args.dataset)\n",
    "adj=modified_adj\n",
    "all_labels = y_train + y_test+y_val\n",
    "single_label = np.argmax(all_labels,axis=-1)\n",
    "\n",
    "nodesize = features.shape[0]\n",
    "\n",
    "# Some preprocessing\n",
    "features = preprocess_features(features)\n",
    "support = preprocess_adj(adj)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "\n",
    "tuple_adj = sparse_to_tuple(adj.tocoo())\n",
    "features_tensor = tf.convert_to_tensor(features,dtype=dtype)\n",
    "adj_tensor = tf.SparseTensor(*tuple_adj)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train,dtype=dtype)\n",
    "train_mask_tensor = tf.convert_to_tensor(train_mask)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test,dtype=dtype)\n",
    "test_mask_tensor = tf.convert_to_tensor(test_mask)\n",
    "y_val_tensor = tf.convert_to_tensor(y_val,dtype=dtype)\n",
    "val_mask_tensor = tf.convert_to_tensor(val_mask)\n",
    "\n",
    "\n",
    "\n",
    "best_test_acc = 0\n",
    "best_val_acc_trail = 0\n",
    "best_val_loss = 10000\n",
    "import time\n",
    "begin = time.time()\n",
    "\n",
    "model = PTDNetGCN(input_dim=features.shape[1], output_dim=y_train.shape[1])\n",
    "model.set_fea_adj(np.array(range(adj.shape[0])), features_tensor, adj_tensor)\n",
    "\n",
    "best_epoch = 0\n",
    "curr_step = 0\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    temperature = max(0.05,args.init_temperature * pow(args.temperature_decay, epoch))\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = []\n",
    "        for l in range(args.outL):\n",
    "            output = model.call(temperature,training=True)\n",
    "            preds.append(tf.expand_dims(output,0))\n",
    "        all_preds = tf.concat(preds,axis=0)\n",
    "        mean_preds = tf.reduce_mean(preds,axis=0)\n",
    "        consistency_loss = tf.nn.l2_loss(mean_preds-all_preds)\n",
    "\n",
    "        cross_loss = masked_softmax_cross_entropy(mean_preds, y_train_tensor,train_mask_tensor)\n",
    "        lossL2 = tf.add_n([tf.nn.l2_loss(v) for v in model.trainable_variables])\n",
    "        lossl0 = model.lossl0(temperature)\n",
    "        #nuclear = model.my_nuclear()\n",
    "        nuclear = model.nuclear()\n",
    "        loss = cross_loss + args.weight_decay*lossL2 + args.lambda1*lossl0 + args.lambda3*nuclear + args.coff_consis*consistency_loss\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    output = model.call(None, training=False)\n",
    "    edges_volumn = tf.reduce_sum(model.maskes[0])\n",
    "    print('edge_vol',edges_volumn.numpy())\n",
    "\n",
    "    train_acc = masked_accuracy(output, y_train_tensor,train_mask_tensor)\n",
    "    val_acc  = masked_accuracy(output, y_val_tensor,val_mask_tensor)\n",
    "    val_loss = masked_softmax_cross_entropy(output, y_val_tensor, val_mask_tensor)\n",
    "    test_acc  = masked_accuracy(output, y_test_tensor,test_mask_tensor)\n",
    "    if val_acc > best_val_acc:\n",
    "        curr_step = 0\n",
    "        best_epoch = epoch\n",
    "        best_val_acc = val_acc\n",
    "        best_val_loss= val_loss\n",
    "        if val_acc>best_val_acc_trail:\n",
    "            best_test_acc = test_acc\n",
    "            best_val_acc_trail = val_acc\n",
    "    else:\n",
    "        curr_step +=1\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cross_loss),\"val_loss=\", \"{:.5f}\".format(val_loss),\n",
    "      \"train_acc=\", \"{:.5f}\".format(train_acc), \"val_acc=\", \"{:.5f}\".format(val_acc),\"best_val_acc_trail=\", \"{:.5f}\".format(best_val_acc_trail),\n",
    "      \"test_acc=\", \"{:.5f}\".format(best_test_acc))\n",
    "\n",
    "    if curr_step > args.early_stop:\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "    end = time.time()\n",
    "    print('time ',(end-begin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_vol 4686.4883\n",
      "Epoch: 0001 train_loss= 1.79187 val_loss= 1.79135 train_acc= 0.41667 val_acc= 0.18200 best_val_acc_trail= 0.18200 test_acc= 0.20100\n",
      "time  3.7035741806030273\n",
      "edge_vol 4682.6943\n",
      "Epoch: 0002 train_loss= 1.78966 val_loss= 1.79062 train_acc= 0.64167 val_acc= 0.28000 best_val_acc_trail= 0.28000 test_acc= 0.29700\n",
      "time  4.431981325149536\n",
      "edge_vol 4676.705\n",
      "Epoch: 0003 train_loss= 1.78746 val_loss= 1.78989 train_acc= 0.79167 val_acc= 0.35400 best_val_acc_trail= 0.35400 test_acc= 0.37700\n",
      "time  5.1718645095825195\n",
      "edge_vol 4669.4854\n",
      "Epoch: 0004 train_loss= 1.78521 val_loss= 1.78912 train_acc= 0.87500 val_acc= 0.40400 best_val_acc_trail= 0.40400 test_acc= 0.44900\n",
      "time  5.8780505657196045\n",
      "edge_vol 4661.4463\n",
      "Epoch: 0005 train_loss= 1.78294 val_loss= 1.78831 train_acc= 0.90000 val_acc= 0.45600 best_val_acc_trail= 0.45600 test_acc= 0.49500\n",
      "time  6.589176893234253\n",
      "edge_vol 4652.9023\n",
      "Epoch: 0006 train_loss= 1.78060 val_loss= 1.78743 train_acc= 0.91667 val_acc= 0.49200 best_val_acc_trail= 0.49200 test_acc= 0.52900\n",
      "time  7.340360641479492\n",
      "edge_vol 4644.078\n",
      "Epoch: 0007 train_loss= 1.77800 val_loss= 1.78648 train_acc= 0.91667 val_acc= 0.53400 best_val_acc_trail= 0.53400 test_acc= 0.55000\n",
      "time  8.060240507125854\n",
      "edge_vol 4634.9766\n",
      "Epoch: 0008 train_loss= 1.77550 val_loss= 1.78545 train_acc= 0.91667 val_acc= 0.54400 best_val_acc_trail= 0.54400 test_acc= 0.57600\n",
      "time  8.773150444030762\n",
      "edge_vol 4625.6807\n",
      "Epoch: 0009 train_loss= 1.77286 val_loss= 1.78434 train_acc= 0.93333 val_acc= 0.57000 best_val_acc_trail= 0.57000 test_acc= 0.58900\n",
      "time  9.506986618041992\n",
      "edge_vol 4616.244\n",
      "Epoch: 0010 train_loss= 1.76986 val_loss= 1.78315 train_acc= 0.92500 val_acc= 0.58800 best_val_acc_trail= 0.58800 test_acc= 0.60300\n",
      "time  10.235649585723877\n",
      "edge_vol 4606.6543\n",
      "Epoch: 0011 train_loss= 1.76676 val_loss= 1.78189 train_acc= 0.92500 val_acc= 0.60200 best_val_acc_trail= 0.60200 test_acc= 0.61000\n",
      "time  10.957221031188965\n",
      "edge_vol 4596.9336\n",
      "Epoch: 0012 train_loss= 1.76362 val_loss= 1.78056 train_acc= 0.92500 val_acc= 0.60800 best_val_acc_trail= 0.60800 test_acc= 0.61700\n",
      "time  11.848013162612915\n",
      "edge_vol 4587.1113\n",
      "Epoch: 0013 train_loss= 1.76019 val_loss= 1.77916 train_acc= 0.93333 val_acc= 0.61200 best_val_acc_trail= 0.61200 test_acc= 0.62300\n",
      "time  12.724797487258911\n",
      "edge_vol 4577.1475\n",
      "Epoch: 0014 train_loss= 1.75635 val_loss= 1.77771 train_acc= 0.92500 val_acc= 0.61400 best_val_acc_trail= 0.61400 test_acc= 0.62500\n",
      "time  13.580094337463379\n",
      "edge_vol 4567.0557\n",
      "Epoch: 0015 train_loss= 1.75259 val_loss= 1.77621 train_acc= 0.92500 val_acc= 0.61200 best_val_acc_trail= 0.61400 test_acc= 0.62500\n",
      "time  14.423073291778564\n",
      "edge_vol 4556.813\n",
      "Epoch: 0016 train_loss= 1.74893 val_loss= 1.77466 train_acc= 0.92500 val_acc= 0.61400 best_val_acc_trail= 0.61400 test_acc= 0.62600\n",
      "time  15.302758932113647\n",
      "edge_vol 4546.4404\n",
      "Epoch: 0017 train_loss= 1.74441 val_loss= 1.77305 train_acc= 0.93333 val_acc= 0.61600 best_val_acc_trail= 0.61600 test_acc= 0.62400\n",
      "time  16.163004159927368\n",
      "edge_vol 4535.952\n",
      "Epoch: 0018 train_loss= 1.74057 val_loss= 1.77140 train_acc= 0.93333 val_acc= 0.61600 best_val_acc_trail= 0.61600 test_acc= 0.62400\n",
      "time  17.037618398666382\n",
      "edge_vol 4525.369\n",
      "Epoch: 0019 train_loss= 1.73625 val_loss= 1.76969 train_acc= 0.93333 val_acc= 0.62200 best_val_acc_trail= 0.62200 test_acc= 0.63100\n",
      "time  17.90016198158264\n",
      "edge_vol 4514.6704\n",
      "Epoch: 0020 train_loss= 1.73122 val_loss= 1.76794 train_acc= 0.94167 val_acc= 0.62600 best_val_acc_trail= 0.62600 test_acc= 0.63300\n",
      "time  18.737574577331543\n",
      "edge_vol 4503.8438\n",
      "Epoch: 0021 train_loss= 1.72669 val_loss= 1.76615 train_acc= 0.94167 val_acc= 0.63000 best_val_acc_trail= 0.63000 test_acc= 0.63300\n",
      "time  19.613112211227417\n",
      "edge_vol 4492.9355\n",
      "Epoch: 0022 train_loss= 1.72191 val_loss= 1.76432 train_acc= 0.95000 val_acc= 0.63200 best_val_acc_trail= 0.63200 test_acc= 0.63600\n",
      "time  20.476922750473022\n",
      "edge_vol 4481.9604\n",
      "Epoch: 0023 train_loss= 1.71709 val_loss= 1.76246 train_acc= 0.95000 val_acc= 0.63400 best_val_acc_trail= 0.63400 test_acc= 0.63600\n",
      "time  21.314685583114624\n",
      "edge_vol 4470.898\n",
      "Epoch: 0024 train_loss= 1.71144 val_loss= 1.76056 train_acc= 0.95000 val_acc= 0.63600 best_val_acc_trail= 0.63600 test_acc= 0.63600\n",
      "time  22.086820602416992\n",
      "edge_vol 4459.737\n",
      "Epoch: 0025 train_loss= 1.70583 val_loss= 1.75862 train_acc= 0.95000 val_acc= 0.63800 best_val_acc_trail= 0.63800 test_acc= 0.63600\n",
      "time  22.924068212509155\n",
      "edge_vol 4448.4985\n",
      "Epoch: 0026 train_loss= 1.70126 val_loss= 1.75665 train_acc= 0.95000 val_acc= 0.63800 best_val_acc_trail= 0.63800 test_acc= 0.63600\n",
      "time  23.76874852180481\n",
      "edge_vol 4437.175\n",
      "Epoch: 0027 train_loss= 1.69530 val_loss= 1.75466 train_acc= 0.95000 val_acc= 0.64200 best_val_acc_trail= 0.64200 test_acc= 0.63700\n",
      "time  24.508936882019043\n",
      "edge_vol 4425.7236\n",
      "Epoch: 0028 train_loss= 1.68979 val_loss= 1.75265 train_acc= 0.95833 val_acc= 0.64200 best_val_acc_trail= 0.64200 test_acc= 0.63700\n",
      "time  25.33598780632019\n",
      "edge_vol 4414.1914\n",
      "Epoch: 0029 train_loss= 1.68427 val_loss= 1.75061 train_acc= 0.95000 val_acc= 0.64200 best_val_acc_trail= 0.64200 test_acc= 0.63700\n",
      "time  26.116273164749146\n",
      "edge_vol 4402.624\n",
      "Epoch: 0030 train_loss= 1.67837 val_loss= 1.74854 train_acc= 0.95000 val_acc= 0.64200 best_val_acc_trail= 0.64200 test_acc= 0.63700\n",
      "time  26.853861570358276\n",
      "edge_vol 4390.924\n",
      "Epoch: 0031 train_loss= 1.67290 val_loss= 1.74644 train_acc= 0.95833 val_acc= 0.64200 best_val_acc_trail= 0.64200 test_acc= 0.63700\n",
      "time  27.555263996124268\n",
      "edge_vol 4379.1045\n",
      "Epoch: 0032 train_loss= 1.66569 val_loss= 1.74433 train_acc= 0.95833 val_acc= 0.64200 best_val_acc_trail= 0.64200 test_acc= 0.63700\n",
      "time  28.298959732055664\n",
      "edge_vol 4367.211\n",
      "Epoch: 0033 train_loss= 1.65919 val_loss= 1.74217 train_acc= 0.95833 val_acc= 0.64400 best_val_acc_trail= 0.64400 test_acc= 0.63800\n",
      "time  29.056785821914673\n",
      "edge_vol 4355.2344\n",
      "Epoch: 0034 train_loss= 1.65362 val_loss= 1.74000 train_acc= 0.95833 val_acc= 0.64400 best_val_acc_trail= 0.64400 test_acc= 0.63800\n",
      "time  29.782925367355347\n",
      "edge_vol 4343.2056\n",
      "Epoch: 0035 train_loss= 1.64614 val_loss= 1.73780 train_acc= 0.95833 val_acc= 0.64400 best_val_acc_trail= 0.64400 test_acc= 0.63800\n",
      "time  30.533717393875122\n",
      "edge_vol 4331.1655\n",
      "Epoch: 0036 train_loss= 1.64106 val_loss= 1.73559 train_acc= 0.95833 val_acc= 0.64400 best_val_acc_trail= 0.64400 test_acc= 0.64300\n",
      "time  31.281200647354126\n",
      "edge_vol 4319.0103\n",
      "Epoch: 0037 train_loss= 1.63492 val_loss= 1.73335 train_acc= 0.95833 val_acc= 0.64400 best_val_acc_trail= 0.64400 test_acc= 0.64300\n",
      "time  31.973049640655518\n",
      "edge_vol 4306.776\n",
      "Epoch: 0038 train_loss= 1.62784 val_loss= 1.73109 train_acc= 0.95833 val_acc= 0.64400 best_val_acc_trail= 0.64400 test_acc= 0.64300\n",
      "time  32.69003486633301\n",
      "edge_vol 4294.586\n",
      "Epoch: 0039 train_loss= 1.62256 val_loss= 1.72880 train_acc= 0.95833 val_acc= 0.64800 best_val_acc_trail= 0.64800 test_acc= 0.64200\n",
      "time  33.71203279495239\n",
      "edge_vol 4282.302\n",
      "Epoch: 0040 train_loss= 1.61586 val_loss= 1.72649 train_acc= 0.95833 val_acc= 0.65000 best_val_acc_trail= 0.65000 test_acc= 0.64300\n",
      "time  34.469080686569214\n",
      "edge_vol 4270.077\n",
      "Epoch: 0041 train_loss= 1.60900 val_loss= 1.72417 train_acc= 0.95833 val_acc= 0.65400 best_val_acc_trail= 0.65400 test_acc= 0.64500\n",
      "time  35.203749656677246\n",
      "edge_vol 4257.8247\n",
      "Epoch: 0042 train_loss= 1.60238 val_loss= 1.72184 train_acc= 0.95833 val_acc= 0.65200 best_val_acc_trail= 0.65400 test_acc= 0.64500\n",
      "time  35.930604457855225\n",
      "edge_vol 4245.598\n",
      "Epoch: 0043 train_loss= 1.59501 val_loss= 1.71950 train_acc= 0.95833 val_acc= 0.65200 best_val_acc_trail= 0.65400 test_acc= 0.64500\n",
      "time  36.81193661689758\n",
      "edge_vol 4233.5845\n",
      "Epoch: 0044 train_loss= 1.58814 val_loss= 1.71716 train_acc= 0.95833 val_acc= 0.65400 best_val_acc_trail= 0.65400 test_acc= 0.64500\n",
      "time  37.69618368148804\n",
      "edge_vol 4221.674\n",
      "Epoch: 0045 train_loss= 1.58064 val_loss= 1.71481 train_acc= 0.95833 val_acc= 0.65400 best_val_acc_trail= 0.65400 test_acc= 0.64500\n",
      "time  38.46795868873596\n",
      "edge_vol 4209.7666\n",
      "Epoch: 0046 train_loss= 1.57498 val_loss= 1.71244 train_acc= 0.95833 val_acc= 0.65600 best_val_acc_trail= 0.65600 test_acc= 0.64500\n",
      "time  39.28468322753906\n",
      "edge_vol 4197.983\n",
      "Epoch: 0047 train_loss= 1.56722 val_loss= 1.71007 train_acc= 0.95833 val_acc= 0.65800 best_val_acc_trail= 0.65800 test_acc= 0.64500\n",
      "time  39.95610165596008\n",
      "edge_vol 4186.2295\n",
      "Epoch: 0048 train_loss= 1.56081 val_loss= 1.70767 train_acc= 0.95833 val_acc= 0.66400 best_val_acc_trail= 0.66400 test_acc= 0.64400\n",
      "time  40.645822048187256\n",
      "edge_vol 4174.848\n",
      "Epoch: 0049 train_loss= 1.55131 val_loss= 1.70528 train_acc= 0.95833 val_acc= 0.66400 best_val_acc_trail= 0.66400 test_acc= 0.64400\n",
      "time  41.33455801010132\n",
      "edge_vol 4163.5674\n",
      "Epoch: 0050 train_loss= 1.54717 val_loss= 1.70291 train_acc= 0.95833 val_acc= 0.66400 best_val_acc_trail= 0.66400 test_acc= 0.64400\n",
      "time  42.139936685562134\n",
      "edge_vol 4152.622\n",
      "Epoch: 0051 train_loss= 1.53914 val_loss= 1.70055 train_acc= 0.95833 val_acc= 0.66800 best_val_acc_trail= 0.66800 test_acc= 0.64200\n",
      "time  42.87228727340698\n",
      "edge_vol 4142.124\n",
      "Epoch: 0052 train_loss= 1.53118 val_loss= 1.69817 train_acc= 0.95833 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.64200\n",
      "time  43.569456577301025\n",
      "edge_vol 4131.686\n",
      "Epoch: 0053 train_loss= 1.52503 val_loss= 1.69580 train_acc= 0.95833 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.64200\n",
      "time  44.23160767555237\n",
      "edge_vol 4121.665\n",
      "Epoch: 0054 train_loss= 1.51681 val_loss= 1.69345 train_acc= 0.96667 val_acc= 0.66800 best_val_acc_trail= 0.67000 test_acc= 0.64200\n",
      "time  44.88372254371643\n",
      "edge_vol 4112.3115\n",
      "Epoch: 0055 train_loss= 1.51253 val_loss= 1.69113 train_acc= 0.96667 val_acc= 0.67000 best_val_acc_trail= 0.67000 test_acc= 0.64200\n",
      "time  45.72517442703247\n",
      "edge_vol 4102.607\n",
      "Epoch: 0056 train_loss= 1.50420 val_loss= 1.68880 train_acc= 0.96667 val_acc= 0.67200 best_val_acc_trail= 0.67200 test_acc= 0.65100\n",
      "time  46.39179539680481\n",
      "edge_vol 4093.4907\n",
      "Epoch: 0057 train_loss= 1.49669 val_loss= 1.68649 train_acc= 0.96667 val_acc= 0.67000 best_val_acc_trail= 0.67200 test_acc= 0.65100\n",
      "time  47.111828565597534\n",
      "edge_vol 4085.5005\n",
      "Epoch: 0058 train_loss= 1.49031 val_loss= 1.68415 train_acc= 0.96667 val_acc= 0.67000 best_val_acc_trail= 0.67200 test_acc= 0.65100\n",
      "time  47.789289712905884\n",
      "edge_vol 4078.1243\n",
      "Epoch: 0059 train_loss= 1.48106 val_loss= 1.68184 train_acc= 0.96667 val_acc= 0.67200 best_val_acc_trail= 0.67200 test_acc= 0.65600\n",
      "time  48.419655323028564\n",
      "edge_vol 4071.1206\n",
      "Epoch: 0060 train_loss= 1.47628 val_loss= 1.67954 train_acc= 0.96667 val_acc= 0.67400 best_val_acc_trail= 0.67400 test_acc= 0.65600\n",
      "time  49.09715414047241\n",
      "edge_vol 4066.268\n",
      "Epoch: 0061 train_loss= 1.46866 val_loss= 1.67730 train_acc= 0.96667 val_acc= 0.67600 best_val_acc_trail= 0.67600 test_acc= 0.65600\n",
      "time  49.72527718544006\n",
      "edge_vol 4062.5867\n",
      "Epoch: 0062 train_loss= 1.46252 val_loss= 1.67511 train_acc= 0.96667 val_acc= 0.67800 best_val_acc_trail= 0.67800 test_acc= 0.65700\n",
      "time  50.51910591125488\n",
      "edge_vol 4059.9453\n",
      "Epoch: 0063 train_loss= 1.45581 val_loss= 1.67293 train_acc= 0.96667 val_acc= 0.68000 best_val_acc_trail= 0.68000 test_acc= 0.65800\n",
      "time  51.35999846458435\n",
      "edge_vol 4058.8406\n",
      "Epoch: 0064 train_loss= 1.44855 val_loss= 1.67081 train_acc= 0.97500 val_acc= 0.67400 best_val_acc_trail= 0.68000 test_acc= 0.65800\n",
      "time  52.038278579711914\n",
      "edge_vol 4059.478\n",
      "Epoch: 0065 train_loss= 1.44171 val_loss= 1.66874 train_acc= 0.97500 val_acc= 0.67600 best_val_acc_trail= 0.68000 test_acc= 0.65800\n",
      "time  52.762407302856445\n",
      "edge_vol 4060.6375\n",
      "Epoch: 0066 train_loss= 1.43367 val_loss= 1.66670 train_acc= 0.96667 val_acc= 0.67800 best_val_acc_trail= 0.68000 test_acc= 0.65800\n",
      "time  53.37847423553467\n",
      "edge_vol 4063.3916\n",
      "Epoch: 0067 train_loss= 1.42980 val_loss= 1.66470 train_acc= 0.96667 val_acc= 0.67800 best_val_acc_trail= 0.68000 test_acc= 0.65800\n",
      "time  54.11591076850891\n",
      "edge_vol 4067.1714\n",
      "Epoch: 0068 train_loss= 1.42319 val_loss= 1.66274 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.65800\n",
      "time  54.87532091140747\n",
      "edge_vol 4072.0974\n",
      "Epoch: 0069 train_loss= 1.41457 val_loss= 1.66079 train_acc= 0.96667 val_acc= 0.68000 best_val_acc_trail= 0.68200 test_acc= 0.65800\n",
      "time  55.54043698310852\n",
      "edge_vol 4079.5593\n",
      "Epoch: 0070 train_loss= 1.40839 val_loss= 1.65888 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.68200 test_acc= 0.66200\n",
      "time  56.263729095458984\n",
      "edge_vol 4088.3518\n",
      "Epoch: 0071 train_loss= 1.40712 val_loss= 1.65704 train_acc= 0.96667 val_acc= 0.68400 best_val_acc_trail= 0.68400 test_acc= 0.66200\n",
      "time  56.98402547836304\n",
      "edge_vol 4098.384\n",
      "Epoch: 0072 train_loss= 1.39461 val_loss= 1.65523 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.68800 test_acc= 0.66200\n",
      "time  57.703914642333984\n",
      "edge_vol 4108.6445\n",
      "Epoch: 0073 train_loss= 1.39068 val_loss= 1.65346 train_acc= 0.96667 val_acc= 0.68600 best_val_acc_trail= 0.68800 test_acc= 0.66200\n",
      "time  58.568246364593506\n",
      "edge_vol 4120.787\n",
      "Epoch: 0074 train_loss= 1.39156 val_loss= 1.65181 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.68800 test_acc= 0.66200\n",
      "time  59.262402296066284\n",
      "edge_vol 4133.9927\n",
      "Epoch: 0075 train_loss= 1.38050 val_loss= 1.65024 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.68800 test_acc= 0.66200\n",
      "time  60.08822822570801\n",
      "edge_vol 4148.318\n",
      "Epoch: 0076 train_loss= 1.37528 val_loss= 1.64871 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  60.92932176589966\n",
      "edge_vol 4163.029\n",
      "Epoch: 0077 train_loss= 1.37108 val_loss= 1.64723 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  61.76733374595642\n",
      "edge_vol 4178.5273\n",
      "Epoch: 0078 train_loss= 1.36441 val_loss= 1.64586 train_acc= 0.95833 val_acc= 0.68400 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  62.608832359313965\n",
      "edge_vol 4194.805\n",
      "Epoch: 0079 train_loss= 1.36035 val_loss= 1.64461 train_acc= 0.95833 val_acc= 0.68400 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  63.41848945617676\n",
      "edge_vol 4211.786\n",
      "Epoch: 0080 train_loss= 1.35345 val_loss= 1.64336 train_acc= 0.96667 val_acc= 0.68400 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  64.26174688339233\n",
      "edge_vol 4230.401\n",
      "Epoch: 0081 train_loss= 1.35073 val_loss= 1.64218 train_acc= 0.96667 val_acc= 0.68400 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  65.0045235157013\n",
      "edge_vol 4249.874\n",
      "Epoch: 0082 train_loss= 1.34210 val_loss= 1.64096 train_acc= 0.96667 val_acc= 0.68600 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  65.79843759536743\n",
      "edge_vol 4270.4336\n",
      "Epoch: 0083 train_loss= 1.34217 val_loss= 1.63983 train_acc= 0.96667 val_acc= 0.68600 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  66.6236834526062\n",
      "edge_vol 4291.514\n",
      "Epoch: 0084 train_loss= 1.33815 val_loss= 1.63874 train_acc= 0.96667 val_acc= 0.68600 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  67.48144674301147\n",
      "edge_vol 4313.0444\n",
      "Epoch: 0085 train_loss= 1.33189 val_loss= 1.63770 train_acc= 0.96667 val_acc= 0.68600 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  68.32526707649231\n",
      "edge_vol 4334.96\n",
      "Epoch: 0086 train_loss= 1.32379 val_loss= 1.63663 train_acc= 0.96667 val_acc= 0.68400 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  69.18843126296997\n",
      "edge_vol 4357.5684\n",
      "Epoch: 0087 train_loss= 1.32353 val_loss= 1.63558 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  70.04209351539612\n",
      "edge_vol 4380.798\n",
      "Epoch: 0088 train_loss= 1.32121 val_loss= 1.63457 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  70.88588356971741\n",
      "edge_vol 4403.949\n",
      "Epoch: 0089 train_loss= 1.31301 val_loss= 1.63359 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  71.75907373428345\n",
      "edge_vol 4427.561\n",
      "Epoch: 0090 train_loss= 1.31322 val_loss= 1.63269 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  72.48924994468689\n",
      "edge_vol 4450.9443\n",
      "Epoch: 0091 train_loss= 1.30731 val_loss= 1.63187 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  73.21039175987244\n",
      "edge_vol 4474.441\n",
      "Epoch: 0092 train_loss= 1.30346 val_loss= 1.63108 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  74.0805139541626\n",
      "edge_vol 4498.1484\n",
      "Epoch: 0093 train_loss= 1.29718 val_loss= 1.63027 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  74.88674139976501\n",
      "edge_vol 4521.916\n",
      "Epoch: 0094 train_loss= 1.30043 val_loss= 1.62942 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  75.62587332725525\n",
      "edge_vol 4545.9844\n",
      "Epoch: 0095 train_loss= 1.29200 val_loss= 1.62865 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  76.32871747016907\n",
      "edge_vol 4570.4126\n",
      "Epoch: 0096 train_loss= 1.29382 val_loss= 1.62796 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  77.06483626365662\n",
      "edge_vol 4595.1504\n",
      "Epoch: 0097 train_loss= 1.28589 val_loss= 1.62735 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  77.93940162658691\n",
      "edge_vol 4619.882\n",
      "Epoch: 0098 train_loss= 1.28725 val_loss= 1.62678 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  78.64776492118835\n",
      "edge_vol 4644.5977\n",
      "Epoch: 0099 train_loss= 1.27889 val_loss= 1.62613 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  79.39022302627563\n",
      "edge_vol 4669.218\n",
      "Epoch: 0100 train_loss= 1.27950 val_loss= 1.62547 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  80.16639399528503\n",
      "edge_vol 4693.6855\n",
      "Epoch: 0101 train_loss= 1.27522 val_loss= 1.62491 train_acc= 0.95833 val_acc= 0.67600 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  80.88378763198853\n",
      "edge_vol 4717.925\n",
      "Epoch: 0102 train_loss= 1.26935 val_loss= 1.62436 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  81.66091275215149\n",
      "edge_vol 4742.599\n",
      "Epoch: 0103 train_loss= 1.26682 val_loss= 1.62383 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  82.31496453285217\n",
      "edge_vol 4767.398\n",
      "Epoch: 0104 train_loss= 1.26181 val_loss= 1.62324 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  83.1896402835846\n",
      "edge_vol 4792.246\n",
      "Epoch: 0105 train_loss= 1.26329 val_loss= 1.62273 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  83.98827290534973\n",
      "edge_vol 4816.905\n",
      "Epoch: 0106 train_loss= 1.25808 val_loss= 1.62223 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  84.73422479629517\n",
      "edge_vol 4840.657\n",
      "Epoch: 0107 train_loss= 1.25536 val_loss= 1.62173 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  85.52028226852417\n",
      "edge_vol 4863.4336\n",
      "Epoch: 0108 train_loss= 1.25169 val_loss= 1.62122 train_acc= 0.96667 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  86.22092366218567\n",
      "edge_vol 4884.6055\n",
      "Epoch: 0109 train_loss= 1.24971 val_loss= 1.62059 train_acc= 0.96667 val_acc= 0.67600 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  86.9653868675232\n",
      "edge_vol 4903.541\n",
      "Epoch: 0110 train_loss= 1.24861 val_loss= 1.61989 train_acc= 0.96667 val_acc= 0.68000 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  87.65098309516907\n",
      "edge_vol 4920.7793\n",
      "Epoch: 0111 train_loss= 1.24601 val_loss= 1.61914 train_acc= 0.96667 val_acc= 0.68000 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  88.37316536903381\n",
      "edge_vol 4937.809\n",
      "Epoch: 0112 train_loss= 1.23876 val_loss= 1.61825 train_acc= 0.96667 val_acc= 0.68000 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  89.08043551445007\n",
      "edge_vol 4955.078\n",
      "Epoch: 0113 train_loss= 1.23851 val_loss= 1.61724 train_acc= 0.96667 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  89.83285427093506\n",
      "edge_vol 4972.6963\n",
      "Epoch: 0114 train_loss= 1.24092 val_loss= 1.61610 train_acc= 0.97500 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  90.550626039505\n",
      "edge_vol 4990.267\n",
      "Epoch: 0115 train_loss= 1.22970 val_loss= 1.61483 train_acc= 0.96667 val_acc= 0.68000 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  91.24375224113464\n",
      "edge_vol 5007.879\n",
      "Epoch: 0116 train_loss= 1.23001 val_loss= 1.61353 train_acc= 0.96667 val_acc= 0.68000 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  92.02013373374939\n",
      "edge_vol 5026.0854\n",
      "Epoch: 0117 train_loss= 1.22555 val_loss= 1.61219 train_acc= 0.96667 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  92.72959756851196\n",
      "edge_vol 5044.671\n",
      "Epoch: 0118 train_loss= 1.22210 val_loss= 1.61083 train_acc= 0.95000 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  93.358243227005\n",
      "edge_vol 5063.843\n",
      "Epoch: 0119 train_loss= 1.22504 val_loss= 1.60957 train_acc= 0.95000 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  94.01202368736267\n",
      "edge_vol 5083.421\n",
      "Epoch: 0120 train_loss= 1.21831 val_loss= 1.60833 train_acc= 0.95000 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  94.83692240715027\n",
      "edge_vol 5103.3574\n",
      "Epoch: 0121 train_loss= 1.21410 val_loss= 1.60699 train_acc= 0.95000 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  95.61960911750793\n",
      "edge_vol 5123.6396\n",
      "Epoch: 0122 train_loss= 1.20809 val_loss= 1.60565 train_acc= 0.95000 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  96.30229449272156\n",
      "edge_vol 5144.3354\n",
      "Epoch: 0123 train_loss= 1.20350 val_loss= 1.60419 train_acc= 0.95000 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  96.9236249923706\n",
      "edge_vol 5165.1665\n",
      "Epoch: 0124 train_loss= 1.19992 val_loss= 1.60271 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  97.57981181144714\n",
      "edge_vol 5186.286\n",
      "Epoch: 0125 train_loss= 1.19930 val_loss= 1.60111 train_acc= 0.95833 val_acc= 0.67600 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  98.24421787261963\n",
      "edge_vol 5207.415\n",
      "Epoch: 0126 train_loss= 1.19667 val_loss= 1.59937 train_acc= 0.95833 val_acc= 0.67600 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  98.90419673919678\n",
      "edge_vol 5229.15\n",
      "Epoch: 0127 train_loss= 1.19240 val_loss= 1.59752 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  99.51128721237183\n",
      "edge_vol 5251.4043\n",
      "Epoch: 0128 train_loss= 1.18355 val_loss= 1.59572 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  100.14398384094238\n",
      "edge_vol 5274.202\n",
      "Epoch: 0129 train_loss= 1.18421 val_loss= 1.59384 train_acc= 0.95833 val_acc= 0.67800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  100.79380011558533\n",
      "edge_vol 5297.537\n",
      "Epoch: 0130 train_loss= 1.18405 val_loss= 1.59188 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  101.4498028755188\n",
      "edge_vol 5321.2925\n",
      "Epoch: 0131 train_loss= 1.17808 val_loss= 1.58992 train_acc= 0.95833 val_acc= 0.68000 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  102.13079190254211\n",
      "edge_vol 5345.6494\n",
      "Epoch: 0132 train_loss= 1.17126 val_loss= 1.58789 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  102.73108625411987\n",
      "edge_vol 5370.415\n",
      "Epoch: 0133 train_loss= 1.16727 val_loss= 1.58577 train_acc= 0.95833 val_acc= 0.68200 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  103.40365862846375\n",
      "edge_vol 5395.6094\n",
      "Epoch: 0134 train_loss= 1.16509 val_loss= 1.58359 train_acc= 0.96667 val_acc= 0.68200 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  104.0930986404419\n",
      "edge_vol 5421.011\n",
      "Epoch: 0135 train_loss= 1.15733 val_loss= 1.58136 train_acc= 0.96667 val_acc= 0.68400 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  104.86736869812012\n",
      "edge_vol 5447.008\n",
      "Epoch: 0136 train_loss= 1.15493 val_loss= 1.57912 train_acc= 0.96667 val_acc= 0.68400 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  105.68069005012512\n",
      "edge_vol 5473.5854\n",
      "Epoch: 0137 train_loss= 1.14705 val_loss= 1.57687 train_acc= 0.96667 val_acc= 0.68600 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  106.41263031959534\n",
      "edge_vol 5500.4297\n",
      "Epoch: 0138 train_loss= 1.14555 val_loss= 1.57447 train_acc= 0.95833 val_acc= 0.68600 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  107.16135048866272\n",
      "edge_vol 5527.961\n",
      "Epoch: 0139 train_loss= 1.13471 val_loss= 1.57203 train_acc= 0.95833 val_acc= 0.68600 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  107.91545176506042\n",
      "edge_vol 5556.3506\n",
      "Epoch: 0140 train_loss= 1.13306 val_loss= 1.56942 train_acc= 0.95833 val_acc= 0.68600 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  108.68946552276611\n",
      "edge_vol 5586.187\n",
      "Epoch: 0141 train_loss= 1.13389 val_loss= 1.56672 train_acc= 0.95833 val_acc= 0.68800 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  109.53397369384766\n",
      "edge_vol 5617.2026\n",
      "Epoch: 0142 train_loss= 1.12584 val_loss= 1.56403 train_acc= 0.95833 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  110.3837022781372\n",
      "edge_vol 5649.012\n",
      "Epoch: 0143 train_loss= 1.11371 val_loss= 1.56129 train_acc= 0.95833 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  111.16444063186646\n",
      "edge_vol 5681.911\n",
      "Epoch: 0144 train_loss= 1.11596 val_loss= 1.55860 train_acc= 0.95833 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  111.97926449775696\n",
      "edge_vol 5715.341\n",
      "Epoch: 0145 train_loss= 1.11142 val_loss= 1.55591 train_acc= 0.95833 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  112.81256914138794\n",
      "edge_vol 5749.6187\n",
      "Epoch: 0146 train_loss= 1.10286 val_loss= 1.55325 train_acc= 0.95833 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  113.59063506126404\n",
      "edge_vol 5784.4653\n",
      "Epoch: 0147 train_loss= 1.09718 val_loss= 1.55056 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  114.43324184417725\n",
      "edge_vol 5820.007\n",
      "Epoch: 0148 train_loss= 1.09311 val_loss= 1.54791 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69000 test_acc= 0.66300\n",
      "time  115.28268694877625\n",
      "edge_vol 5856.3906\n",
      "Epoch: 0149 train_loss= 1.08969 val_loss= 1.54529 train_acc= 0.96667 val_acc= 0.69200 best_val_acc_trail= 0.69200 test_acc= 0.67300\n",
      "time  116.08875942230225\n",
      "edge_vol 5893.993\n",
      "Epoch: 0150 train_loss= 1.08503 val_loss= 1.54270 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69200 test_acc= 0.67300\n",
      "time  116.93017315864563\n",
      "edge_vol 5932.323\n",
      "Epoch: 0151 train_loss= 1.08149 val_loss= 1.54010 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.69200 test_acc= 0.67300\n",
      "time  117.74206280708313\n",
      "edge_vol 5971.631\n",
      "Epoch: 0152 train_loss= 1.07615 val_loss= 1.53745 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.69200 test_acc= 0.67300\n",
      "time  118.56205558776855\n",
      "edge_vol 6011.572\n",
      "Epoch: 0153 train_loss= 1.06690 val_loss= 1.53483 train_acc= 0.96667 val_acc= 0.68600 best_val_acc_trail= 0.69200 test_acc= 0.67300\n",
      "time  119.45475482940674\n",
      "edge_vol 6051.881\n",
      "Epoch: 0154 train_loss= 1.06583 val_loss= 1.53232 train_acc= 0.96667 val_acc= 0.68600 best_val_acc_trail= 0.69200 test_acc= 0.67300\n",
      "time  120.27618169784546\n",
      "edge_vol 6092.969\n",
      "Epoch: 0155 train_loss= 1.06188 val_loss= 1.52991 train_acc= 0.96667 val_acc= 0.68600 best_val_acc_trail= 0.69200 test_acc= 0.67300\n",
      "time  121.0633716583252\n",
      "edge_vol 6134.745\n",
      "Epoch: 0156 train_loss= 1.05762 val_loss= 1.52757 train_acc= 0.96667 val_acc= 0.68400 best_val_acc_trail= 0.69200 test_acc= 0.67300\n",
      "time  121.86561608314514\n",
      "edge_vol 6177.09\n",
      "Epoch: 0157 train_loss= 1.05501 val_loss= 1.52521 train_acc= 0.96667 val_acc= 0.68400 best_val_acc_trail= 0.69200 test_acc= 0.67300\n",
      "time  122.58231782913208\n",
      "edge_vol 6219.5703\n",
      "Epoch: 0158 train_loss= 1.05219 val_loss= 1.52284 train_acc= 0.96667 val_acc= 0.68400 best_val_acc_trail= 0.69200 test_acc= 0.67300\n",
      "time  123.38133835792542\n",
      "edge_vol 6262.452\n",
      "Epoch: 0159 train_loss= 1.04872 val_loss= 1.52054 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.69200 test_acc= 0.67300\n",
      "time  124.07784461975098\n",
      "edge_vol 6305.8623\n",
      "Epoch: 0160 train_loss= 1.04171 val_loss= 1.51822 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.69200 test_acc= 0.67300\n",
      "time  124.80418491363525\n",
      "edge_vol 6349.0176\n",
      "Epoch: 0161 train_loss= 1.03801 val_loss= 1.51594 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.69200 test_acc= 0.67300\n",
      "time  125.50634384155273\n",
      "edge_vol 6392.451\n",
      "Epoch: 0162 train_loss= 1.03391 val_loss= 1.51368 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.69200 test_acc= 0.67300\n",
      "time  126.17173433303833\n",
      "edge_vol 6436.0264\n",
      "Epoch: 0163 train_loss= 1.03159 val_loss= 1.51143 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69200 test_acc= 0.67300\n",
      "time  126.9190502166748\n",
      "edge_vol 6479.92\n",
      "Epoch: 0164 train_loss= 1.02607 val_loss= 1.50931 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.69200 test_acc= 0.67300\n",
      "time  127.72126626968384\n",
      "edge_vol 6524.3496\n",
      "Epoch: 0165 train_loss= 1.01907 val_loss= 1.50723 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.69200 test_acc= 0.67300\n",
      "time  128.4070222377777\n",
      "edge_vol 6569.126\n",
      "Epoch: 0166 train_loss= 1.02172 val_loss= 1.50526 train_acc= 0.96667 val_acc= 0.68800 best_val_acc_trail= 0.69200 test_acc= 0.67300\n",
      "time  129.12212252616882\n",
      "edge_vol 6614.366\n",
      "Epoch: 0167 train_loss= 1.01752 val_loss= 1.50329 train_acc= 0.96667 val_acc= 0.69200 best_val_acc_trail= 0.69200 test_acc= 0.68200\n",
      "time  129.89259457588196\n",
      "edge_vol 6659.6562\n",
      "Epoch: 0168 train_loss= 1.01159 val_loss= 1.50141 train_acc= 0.96667 val_acc= 0.69200 best_val_acc_trail= 0.69200 test_acc= 0.68200\n",
      "time  130.56431221961975\n",
      "edge_vol 6704.796\n",
      "Epoch: 0169 train_loss= 1.00816 val_loss= 1.49950 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69200 test_acc= 0.68200\n",
      "time  131.28146171569824\n",
      "edge_vol 6750.362\n",
      "Epoch: 0170 train_loss= 1.00326 val_loss= 1.49761 train_acc= 0.96667 val_acc= 0.69000 best_val_acc_trail= 0.69200 test_acc= 0.68200\n",
      "time  131.95723867416382\n",
      "edge_vol 6796.3003\n",
      "Epoch: 0171 train_loss= 1.00125 val_loss= 1.49577 train_acc= 0.96667 val_acc= 0.69400 best_val_acc_trail= 0.69400 test_acc= 0.68400\n",
      "time  132.6754024028778\n",
      "edge_vol 6841.916\n",
      "Epoch: 0172 train_loss= 0.99983 val_loss= 1.49397 train_acc= 0.96667 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68400\n",
      "time  133.39563250541687\n",
      "edge_vol 6887.6875\n",
      "Epoch: 0173 train_loss= 0.99648 val_loss= 1.49213 train_acc= 0.96667 val_acc= 0.69600 best_val_acc_trail= 0.69600 test_acc= 0.68400\n",
      "time  134.0916543006897\n",
      "edge_vol 6934.108\n",
      "Epoch: 0174 train_loss= 0.99467 val_loss= 1.49031 train_acc= 0.96667 val_acc= 0.69800 best_val_acc_trail= 0.69800 test_acc= 0.68400\n",
      "time  134.87979316711426\n",
      "edge_vol 6980.843\n",
      "Epoch: 0175 train_loss= 0.99046 val_loss= 1.48851 train_acc= 0.96667 val_acc= 0.70000 best_val_acc_trail= 0.70000 test_acc= 0.68300\n",
      "time  135.86859369277954\n",
      "edge_vol 7027.4766\n",
      "Epoch: 0176 train_loss= 0.98163 val_loss= 1.48676 train_acc= 0.96667 val_acc= 0.70000 best_val_acc_trail= 0.70000 test_acc= 0.68300\n",
      "time  136.55200743675232\n",
      "edge_vol 7073.851\n",
      "Epoch: 0177 train_loss= 0.98176 val_loss= 1.48507 train_acc= 0.96667 val_acc= 0.70200 best_val_acc_trail= 0.70200 test_acc= 0.68400\n",
      "time  137.30526399612427\n",
      "edge_vol 7119.754\n",
      "Epoch: 0178 train_loss= 0.97650 val_loss= 1.48339 train_acc= 0.96667 val_acc= 0.70200 best_val_acc_trail= 0.70200 test_acc= 0.68400\n",
      "time  138.1242482662201\n",
      "edge_vol 7165.3945\n",
      "Epoch: 0179 train_loss= 0.97687 val_loss= 1.48164 train_acc= 0.96667 val_acc= 0.69800 best_val_acc_trail= 0.70200 test_acc= 0.68400\n",
      "time  138.95111727714539\n",
      "edge_vol 7211.329\n",
      "Epoch: 0180 train_loss= 0.97114 val_loss= 1.47990 train_acc= 0.96667 val_acc= 0.69600 best_val_acc_trail= 0.70200 test_acc= 0.68400\n",
      "time  139.64134120941162\n",
      "edge_vol 7256.6606\n",
      "Epoch: 0181 train_loss= 0.96921 val_loss= 1.47816 train_acc= 0.96667 val_acc= 0.69600 best_val_acc_trail= 0.70200 test_acc= 0.68400\n",
      "time  140.42987203598022\n",
      "edge_vol 7301.7783\n",
      "Epoch: 0182 train_loss= 0.96814 val_loss= 1.47637 train_acc= 0.96667 val_acc= 0.70000 best_val_acc_trail= 0.70200 test_acc= 0.68400\n",
      "time  141.1398787498474\n",
      "edge_vol 7346.9204\n",
      "Epoch: 0183 train_loss= 0.96214 val_loss= 1.47460 train_acc= 0.96667 val_acc= 0.70400 best_val_acc_trail= 0.70400 test_acc= 0.68400\n",
      "time  141.79993510246277\n",
      "edge_vol 7391.9927\n",
      "Epoch: 0184 train_loss= 0.95745 val_loss= 1.47282 train_acc= 0.96667 val_acc= 0.70400 best_val_acc_trail= 0.70400 test_acc= 0.68400\n",
      "time  142.60597157478333\n",
      "edge_vol 7437.004\n",
      "Epoch: 0185 train_loss= 0.95470 val_loss= 1.47102 train_acc= 0.96667 val_acc= 0.70400 best_val_acc_trail= 0.70400 test_acc= 0.68400\n",
      "time  143.2346396446228\n",
      "edge_vol 7481.8086\n",
      "Epoch: 0186 train_loss= 0.95407 val_loss= 1.46911 train_acc= 0.96667 val_acc= 0.70400 best_val_acc_trail= 0.70400 test_acc= 0.68400\n",
      "time  143.8746201992035\n",
      "edge_vol 7525.7603\n",
      "Epoch: 0187 train_loss= 0.94943 val_loss= 1.46707 train_acc= 0.96667 val_acc= 0.70600 best_val_acc_trail= 0.70600 test_acc= 0.68500\n",
      "time  144.48356533050537\n",
      "edge_vol 7569.049\n",
      "Epoch: 0188 train_loss= 0.94736 val_loss= 1.46499 train_acc= 0.96667 val_acc= 0.70600 best_val_acc_trail= 0.70600 test_acc= 0.68500\n",
      "time  145.11617422103882\n",
      "edge_vol 7611.3345\n",
      "Epoch: 0189 train_loss= 0.94276 val_loss= 1.46281 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70600 test_acc= 0.68500\n",
      "time  145.84893918037415\n",
      "edge_vol 7653.42\n",
      "Epoch: 0190 train_loss= 0.93970 val_loss= 1.46068 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.70600 test_acc= 0.68500\n",
      "time  146.63107132911682\n",
      "edge_vol 7694.667\n",
      "Epoch: 0191 train_loss= 0.93567 val_loss= 1.45856 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.70600 test_acc= 0.68500\n",
      "time  147.44585752487183\n",
      "edge_vol 7735.3594\n",
      "Epoch: 0192 train_loss= 0.93117 val_loss= 1.45644 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70600 test_acc= 0.68300\n",
      "time  148.2087423801422\n",
      "edge_vol 7775.117\n",
      "Epoch: 0193 train_loss= 0.92738 val_loss= 1.45420 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  148.98487544059753\n",
      "edge_vol 7814.209\n",
      "Epoch: 0194 train_loss= 0.92585 val_loss= 1.45199 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  149.70986223220825\n",
      "edge_vol 7852.5767\n",
      "Epoch: 0195 train_loss= 0.92231 val_loss= 1.44979 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  150.44219660758972\n",
      "edge_vol 7890.549\n",
      "Epoch: 0196 train_loss= 0.91325 val_loss= 1.44755 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  151.263521194458\n",
      "edge_vol 7928.2485\n",
      "Epoch: 0197 train_loss= 0.90926 val_loss= 1.44535 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  151.9476330280304\n",
      "edge_vol 7965.5693\n",
      "Epoch: 0198 train_loss= 0.90501 val_loss= 1.44316 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  152.59939408302307\n",
      "edge_vol 8002.4956\n",
      "Epoch: 0199 train_loss= 0.90581 val_loss= 1.44097 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  153.3520700931549\n",
      "edge_vol 8039.1445\n",
      "Epoch: 0200 train_loss= 0.90473 val_loss= 1.43869 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  154.06574177742004\n",
      "edge_vol 8074.9746\n",
      "Epoch: 0201 train_loss= 0.89916 val_loss= 1.43638 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  154.77801322937012\n",
      "edge_vol 8110.208\n",
      "Epoch: 0202 train_loss= 0.89195 val_loss= 1.43417 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  155.52535557746887\n",
      "edge_vol 8144.8286\n",
      "Epoch: 0203 train_loss= 0.89122 val_loss= 1.43195 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  156.20132875442505\n",
      "edge_vol 8178.741\n",
      "Epoch: 0204 train_loss= 0.88226 val_loss= 1.42972 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  157.05077171325684\n",
      "edge_vol 8211.727\n",
      "Epoch: 0205 train_loss= 0.87960 val_loss= 1.42739 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  157.91132497787476\n",
      "edge_vol 8243.838\n",
      "Epoch: 0206 train_loss= 0.87527 val_loss= 1.42501 train_acc= 0.97500 val_acc= 0.70200 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  158.92393445968628\n",
      "edge_vol 8275.172\n",
      "Epoch: 0207 train_loss= 0.87274 val_loss= 1.42265 train_acc= 0.97500 val_acc= 0.70000 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  159.82421493530273\n",
      "edge_vol 8305.467\n",
      "Epoch: 0208 train_loss= 0.86531 val_loss= 1.42018 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  160.6848270893097\n",
      "edge_vol 8335.42\n",
      "Epoch: 0209 train_loss= 0.86360 val_loss= 1.41771 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  161.5413248538971\n",
      "edge_vol 8364.762\n",
      "Epoch: 0210 train_loss= 0.85928 val_loss= 1.41519 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  162.40319228172302\n",
      "edge_vol 8393.445\n",
      "Epoch: 0211 train_loss= 0.85673 val_loss= 1.41252 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  163.2628517150879\n",
      "edge_vol 8421.018\n",
      "Epoch: 0212 train_loss= 0.84939 val_loss= 1.40979 train_acc= 0.97500 val_acc= 0.70000 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  164.11977219581604\n",
      "edge_vol 8447.945\n",
      "Epoch: 0213 train_loss= 0.84621 val_loss= 1.40706 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  164.8548722267151\n",
      "edge_vol 8474.371\n",
      "Epoch: 0214 train_loss= 0.84203 val_loss= 1.40434 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  165.555029630661\n",
      "edge_vol 8500.504\n",
      "Epoch: 0215 train_loss= 0.83762 val_loss= 1.40154 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  166.2964859008789\n",
      "edge_vol 8526.309\n",
      "Epoch: 0216 train_loss= 0.83543 val_loss= 1.39871 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  167.07581233978271\n",
      "edge_vol 8551.05\n",
      "Epoch: 0217 train_loss= 0.82893 val_loss= 1.39589 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  167.90473771095276\n",
      "edge_vol 8575.462\n",
      "Epoch: 0218 train_loss= 0.82780 val_loss= 1.39299 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  168.76593112945557\n",
      "edge_vol 8599.496\n",
      "Epoch: 0219 train_loss= 0.82126 val_loss= 1.39004 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  169.45412397384644\n",
      "edge_vol 8623.051\n",
      "Epoch: 0220 train_loss= 0.81711 val_loss= 1.38722 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  170.18607234954834\n",
      "edge_vol 8645.788\n",
      "Epoch: 0221 train_loss= 0.81303 val_loss= 1.38434 train_acc= 0.97500 val_acc= 0.69800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  170.90557050704956\n",
      "edge_vol 8667.705\n",
      "Epoch: 0222 train_loss= 0.80889 val_loss= 1.38138 train_acc= 0.97500 val_acc= 0.70000 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  171.71810269355774\n",
      "edge_vol 8689.062\n",
      "Epoch: 0223 train_loss= 0.80322 val_loss= 1.37830 train_acc= 0.97500 val_acc= 0.70000 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  172.48548769950867\n",
      "edge_vol 8710.16\n",
      "Epoch: 0224 train_loss= 0.79869 val_loss= 1.37527 train_acc= 0.97500 val_acc= 0.70200 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  173.17486882209778\n",
      "edge_vol 8730.531\n",
      "Epoch: 0225 train_loss= 0.79749 val_loss= 1.37216 train_acc= 0.97500 val_acc= 0.70000 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  173.8242597579956\n",
      "edge_vol 8750.539\n",
      "Epoch: 0226 train_loss= 0.79202 val_loss= 1.36910 train_acc= 0.97500 val_acc= 0.70200 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  174.44819259643555\n",
      "edge_vol 8769.483\n",
      "Epoch: 0227 train_loss= 0.78481 val_loss= 1.36604 train_acc= 0.97500 val_acc= 0.70000 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  175.20774292945862\n",
      "edge_vol 8787.924\n",
      "Epoch: 0228 train_loss= 0.78230 val_loss= 1.36298 train_acc= 0.97500 val_acc= 0.70000 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  176.01336240768433\n",
      "edge_vol 8805.966\n",
      "Epoch: 0229 train_loss= 0.77822 val_loss= 1.35985 train_acc= 0.97500 val_acc= 0.70000 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  176.69129014015198\n",
      "edge_vol 8823.303\n",
      "Epoch: 0230 train_loss= 0.77612 val_loss= 1.35669 train_acc= 0.97500 val_acc= 0.70000 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  177.3855721950531\n",
      "edge_vol 8840.206\n",
      "Epoch: 0231 train_loss= 0.76964 val_loss= 1.35343 train_acc= 0.97500 val_acc= 0.70000 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  178.09661412239075\n",
      "edge_vol 8856.493\n",
      "Epoch: 0232 train_loss= 0.76801 val_loss= 1.35018 train_acc= 0.97500 val_acc= 0.70400 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  178.81618762016296\n",
      "edge_vol 8872.268\n",
      "Epoch: 0233 train_loss= 0.76092 val_loss= 1.34688 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  179.49669098854065\n",
      "edge_vol 8887.458\n",
      "Epoch: 0234 train_loss= 0.75584 val_loss= 1.34369 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  180.2594645023346\n",
      "edge_vol 8902.166\n",
      "Epoch: 0235 train_loss= 0.75146 val_loss= 1.34051 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  180.97230219841003\n",
      "edge_vol 8916.753\n",
      "Epoch: 0236 train_loss= 0.74942 val_loss= 1.33730 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  181.62973713874817\n",
      "edge_vol 8930.835\n",
      "Epoch: 0237 train_loss= 0.74224 val_loss= 1.33406 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  182.3223078250885\n",
      "edge_vol 8944.519\n",
      "Epoch: 0238 train_loss= 0.73895 val_loss= 1.33077 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  183.15874123573303\n",
      "edge_vol 8957.892\n",
      "Epoch: 0239 train_loss= 0.73528 val_loss= 1.32752 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  183.85330986976624\n",
      "edge_vol 8970.965\n",
      "Epoch: 0240 train_loss= 0.73247 val_loss= 1.32424 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  184.61477732658386\n",
      "edge_vol 8983.654\n",
      "Epoch: 0241 train_loss= 0.72725 val_loss= 1.32099 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  185.42448568344116\n",
      "edge_vol 8995.922\n",
      "Epoch: 0242 train_loss= 0.72151 val_loss= 1.31776 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  186.28339982032776\n",
      "edge_vol 9007.846\n",
      "Epoch: 0243 train_loss= 0.71687 val_loss= 1.31455 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  187.03009271621704\n",
      "edge_vol 9019.339\n",
      "Epoch: 0244 train_loss= 0.71414 val_loss= 1.31134 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  187.7496373653412\n",
      "edge_vol 9030.674\n",
      "Epoch: 0245 train_loss= 0.70730 val_loss= 1.30817 train_acc= 0.97500 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  188.53846740722656\n",
      "edge_vol 9041.588\n",
      "Epoch: 0246 train_loss= 0.70510 val_loss= 1.30503 train_acc= 0.97500 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  189.28436255455017\n",
      "edge_vol 9052.114\n",
      "Epoch: 0247 train_loss= 0.70105 val_loss= 1.30197 train_acc= 0.98333 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  190.00022101402283\n",
      "edge_vol 9062.493\n",
      "Epoch: 0248 train_loss= 0.69833 val_loss= 1.29909 train_acc= 0.98333 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  190.70569324493408\n",
      "edge_vol 9072.409\n",
      "Epoch: 0249 train_loss= 0.69249 val_loss= 1.29631 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  191.41356563568115\n",
      "edge_vol 9081.827\n",
      "Epoch: 0250 train_loss= 0.68909 val_loss= 1.29349 train_acc= 0.98333 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  192.13972401618958\n",
      "edge_vol 9091.053\n",
      "Epoch: 0251 train_loss= 0.68766 val_loss= 1.29074 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  192.852685213089\n",
      "edge_vol 9099.8955\n",
      "Epoch: 0252 train_loss= 0.68171 val_loss= 1.28806 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  193.59989595413208\n",
      "edge_vol 9108.387\n",
      "Epoch: 0253 train_loss= 0.67783 val_loss= 1.28535 train_acc= 0.98333 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  194.31545209884644\n",
      "edge_vol 9116.916\n",
      "Epoch: 0254 train_loss= 0.67303 val_loss= 1.28260 train_acc= 0.98333 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  194.94944548606873\n",
      "edge_vol 9125.041\n",
      "Epoch: 0255 train_loss= 0.66994 val_loss= 1.27982 train_acc= 0.98333 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  195.75654983520508\n",
      "edge_vol 9132.801\n",
      "Epoch: 0256 train_loss= 0.66560 val_loss= 1.27696 train_acc= 0.98333 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  196.3482129573822\n",
      "edge_vol 9140.378\n",
      "Epoch: 0257 train_loss= 0.66302 val_loss= 1.27419 train_acc= 0.98333 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  197.00500011444092\n",
      "edge_vol 9147.686\n",
      "Epoch: 0258 train_loss= 0.65938 val_loss= 1.27144 train_acc= 0.98333 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  197.64913368225098\n",
      "edge_vol 9154.815\n",
      "Epoch: 0259 train_loss= 0.65738 val_loss= 1.26876 train_acc= 0.98333 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  198.25003480911255\n",
      "edge_vol 9161.701\n",
      "Epoch: 0260 train_loss= 0.65189 val_loss= 1.26615 train_acc= 0.98333 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  198.89240527153015\n",
      "edge_vol 9168.093\n",
      "Epoch: 0261 train_loss= 0.64804 val_loss= 1.26351 train_acc= 0.98333 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  199.58937072753906\n",
      "edge_vol 9174.213\n",
      "Epoch: 0262 train_loss= 0.64527 val_loss= 1.26087 train_acc= 0.98333 val_acc= 0.70600 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  200.3688018321991\n",
      "edge_vol 9180.092\n",
      "Epoch: 0263 train_loss= 0.64106 val_loss= 1.25828 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  201.02452731132507\n",
      "edge_vol 9186.066\n",
      "Epoch: 0264 train_loss= 0.63713 val_loss= 1.25562 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  201.6559135913849\n",
      "edge_vol 9191.914\n",
      "Epoch: 0265 train_loss= 0.63444 val_loss= 1.25302 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  202.40008687973022\n",
      "edge_vol 9197.451\n",
      "Epoch: 0266 train_loss= 0.63075 val_loss= 1.25031 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  203.0306658744812\n",
      "edge_vol 9202.781\n",
      "Epoch: 0267 train_loss= 0.62772 val_loss= 1.24753 train_acc= 0.98333 val_acc= 0.70800 best_val_acc_trail= 0.70800 test_acc= 0.68400\n",
      "time  203.6890857219696\n",
      "edge_vol 9208.105\n",
      "Epoch: 0268 train_loss= 0.62483 val_loss= 1.24481 train_acc= 0.98333 val_acc= 0.71000 best_val_acc_trail= 0.71000 test_acc= 0.69800\n",
      "time  204.44112586975098\n",
      "edge_vol 9213.285\n",
      "Epoch: 0269 train_loss= 0.62039 val_loss= 1.24215 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71200 test_acc= 0.69900\n",
      "time  205.11956405639648\n",
      "edge_vol 9218.101\n",
      "Epoch: 0270 train_loss= 0.61865 val_loss= 1.23939 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71200 test_acc= 0.69900\n",
      "time  205.92560029029846\n",
      "edge_vol 9222.6045\n",
      "Epoch: 0271 train_loss= 0.61549 val_loss= 1.23657 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71200 test_acc= 0.69900\n",
      "time  206.66395139694214\n",
      "edge_vol 9227.052\n",
      "Epoch: 0272 train_loss= 0.61193 val_loss= 1.23377 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71200 test_acc= 0.69900\n",
      "time  207.47641110420227\n",
      "edge_vol 9231.274\n",
      "Epoch: 0273 train_loss= 0.60751 val_loss= 1.23101 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71200 test_acc= 0.69900\n",
      "time  208.31983971595764\n",
      "edge_vol 9235.3125\n",
      "Epoch: 0274 train_loss= 0.60346 val_loss= 1.22836 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71200 test_acc= 0.69900\n",
      "time  209.16241908073425\n",
      "edge_vol 9239.219\n",
      "Epoch: 0275 train_loss= 0.60205 val_loss= 1.22572 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71200 test_acc= 0.69900\n",
      "time  209.9939193725586\n",
      "edge_vol 9242.959\n",
      "Epoch: 0276 train_loss= 0.59881 val_loss= 1.22315 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71200 test_acc= 0.69900\n",
      "time  210.83143401145935\n",
      "edge_vol 9246.585\n",
      "Epoch: 0277 train_loss= 0.59709 val_loss= 1.22064 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71200 test_acc= 0.69900\n",
      "time  211.67437076568604\n",
      "edge_vol 9250.038\n",
      "Epoch: 0278 train_loss= 0.59273 val_loss= 1.21815 train_acc= 0.98333 val_acc= 0.71000 best_val_acc_trail= 0.71200 test_acc= 0.69900\n",
      "time  212.46794533729553\n",
      "edge_vol 9253.324\n",
      "Epoch: 0279 train_loss= 0.58960 val_loss= 1.21567 train_acc= 0.98333 val_acc= 0.71000 best_val_acc_trail= 0.71200 test_acc= 0.69900\n",
      "time  213.2595019340515\n",
      "edge_vol 9256.434\n",
      "Epoch: 0280 train_loss= 0.58681 val_loss= 1.21315 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71400 test_acc= 0.70000\n",
      "time  214.02763485908508\n",
      "edge_vol 9259.321\n",
      "Epoch: 0281 train_loss= 0.58436 val_loss= 1.21065 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71400 test_acc= 0.70000\n",
      "time  214.8519368171692\n",
      "edge_vol 9262.084\n",
      "Epoch: 0282 train_loss= 0.58122 val_loss= 1.20821 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71400 test_acc= 0.70000\n",
      "time  215.71392464637756\n",
      "edge_vol 9264.806\n",
      "Epoch: 0283 train_loss= 0.57701 val_loss= 1.20578 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71400 test_acc= 0.70000\n",
      "time  216.57656908035278\n",
      "edge_vol 9267.385\n",
      "Epoch: 0284 train_loss= 0.57407 val_loss= 1.20344 train_acc= 0.98333 val_acc= 0.71600 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  217.36347198486328\n",
      "edge_vol 9269.758\n",
      "Epoch: 0285 train_loss= 0.57153 val_loss= 1.20121 train_acc= 0.98333 val_acc= 0.71600 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  218.2042863368988\n",
      "edge_vol 9271.99\n",
      "Epoch: 0286 train_loss= 0.56923 val_loss= 1.19897 train_acc= 0.98333 val_acc= 0.71600 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  219.01863932609558\n",
      "edge_vol 9274.09\n",
      "Epoch: 0287 train_loss= 0.56684 val_loss= 1.19669 train_acc= 0.98333 val_acc= 0.71600 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  219.79442381858826\n",
      "edge_vol 9276.037\n",
      "Epoch: 0288 train_loss= 0.56303 val_loss= 1.19437 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  220.50549578666687\n",
      "edge_vol 9277.988\n",
      "Epoch: 0289 train_loss= 0.56062 val_loss= 1.19209 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  221.82188487052917\n",
      "edge_vol 9279.803\n",
      "Epoch: 0290 train_loss= 0.55826 val_loss= 1.18983 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  222.56302285194397\n",
      "edge_vol 9281.433\n",
      "Epoch: 0291 train_loss= 0.55517 val_loss= 1.18760 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  223.42144131660461\n",
      "edge_vol 9282.902\n",
      "Epoch: 0292 train_loss= 0.55231 val_loss= 1.18553 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  224.12664604187012\n",
      "edge_vol 9284.139\n",
      "Epoch: 0293 train_loss= 0.54881 val_loss= 1.18352 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  224.82198214530945\n",
      "edge_vol 9285.127\n",
      "Epoch: 0294 train_loss= 0.54694 val_loss= 1.18152 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  225.64818024635315\n",
      "edge_vol 9285.924\n",
      "Epoch: 0295 train_loss= 0.54377 val_loss= 1.17947 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  226.34541535377502\n",
      "edge_vol 9286.572\n",
      "Epoch: 0296 train_loss= 0.54070 val_loss= 1.17751 train_acc= 0.98333 val_acc= 0.71600 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  227.12063717842102\n",
      "edge_vol 9287.063\n",
      "Epoch: 0297 train_loss= 0.53835 val_loss= 1.17546 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  227.81983518600464\n",
      "edge_vol 9287.406\n",
      "Epoch: 0298 train_loss= 0.53594 val_loss= 1.17342 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  228.60755395889282\n",
      "edge_vol 9287.631\n",
      "Epoch: 0299 train_loss= 0.53445 val_loss= 1.17144 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  229.32753920555115\n",
      "edge_vol 9287.788\n",
      "Epoch: 0300 train_loss= 0.53111 val_loss= 1.16959 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  230.34299302101135\n",
      "edge_vol 9287.881\n",
      "Epoch: 0301 train_loss= 0.53041 val_loss= 1.16779 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  231.04494643211365\n",
      "edge_vol 9287.928\n",
      "Epoch: 0302 train_loss= 0.52776 val_loss= 1.16603 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  231.78985595703125\n",
      "edge_vol 9287.954\n",
      "Epoch: 0303 train_loss= 0.52496 val_loss= 1.16444 train_acc= 0.98333 val_acc= 0.71000 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  232.5698037147522\n",
      "edge_vol 9287.969\n",
      "Epoch: 0304 train_loss= 0.52315 val_loss= 1.16280 train_acc= 0.98333 val_acc= 0.71000 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  233.4098207950592\n",
      "edge_vol 9287.979\n",
      "Epoch: 0305 train_loss= 0.52102 val_loss= 1.16120 train_acc= 0.98333 val_acc= 0.71000 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  234.15047883987427\n",
      "edge_vol 9287.985\n",
      "Epoch: 0306 train_loss= 0.51894 val_loss= 1.15962 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  234.85961413383484\n",
      "edge_vol 9287.99\n",
      "Epoch: 0307 train_loss= 0.51710 val_loss= 1.15798 train_acc= 0.98333 val_acc= 0.71000 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  235.59935784339905\n",
      "edge_vol 9287.994\n",
      "Epoch: 0308 train_loss= 0.51481 val_loss= 1.15646 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  236.43571209907532\n",
      "edge_vol 9287.997\n",
      "Epoch: 0309 train_loss= 0.51259 val_loss= 1.15485 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  237.20328831672668\n",
      "edge_vol 9287.998\n",
      "Epoch: 0310 train_loss= 0.51281 val_loss= 1.15327 train_acc= 0.98333 val_acc= 0.71200 best_val_acc_trail= 0.71600 test_acc= 0.70100\n",
      "time  237.88460326194763\n",
      "edge_vol 9288.0\n",
      "Epoch: 0311 train_loss= 0.50966 val_loss= 1.15181 train_acc= 0.98333 val_acc= 0.71600 best_val_acc_trail= 0.71600 test_acc= 0.70300\n",
      "time  238.76966094970703\n",
      "edge_vol 9288.0\n",
      "Epoch: 0312 train_loss= 0.50767 val_loss= 1.15031 train_acc= 0.98333 val_acc= 0.71600 best_val_acc_trail= 0.71600 test_acc= 0.70300\n",
      "time  239.49067950248718\n",
      "edge_vol 9288.0\n",
      "Epoch: 0313 train_loss= 0.50547 val_loss= 1.14888 train_acc= 0.98333 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  240.1818516254425\n",
      "edge_vol 9288.0\n",
      "Epoch: 0314 train_loss= 0.50446 val_loss= 1.14745 train_acc= 0.98333 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  240.8733401298523\n",
      "edge_vol 9288.0\n",
      "Epoch: 0315 train_loss= 0.50194 val_loss= 1.14600 train_acc= 0.98333 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  241.57421565055847\n",
      "edge_vol 9288.0\n",
      "Epoch: 0316 train_loss= 0.50036 val_loss= 1.14453 train_acc= 0.98333 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  242.26648688316345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zsp/ljx/PTDNet/models.py:14: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_vol 9288.0\n",
      "Epoch: 0317 train_loss= 0.49827 val_loss= 1.14308 train_acc= 0.98333 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  242.93161344528198\n",
      "edge_vol 9288.0\n",
      "Epoch: 0318 train_loss= 0.49624 val_loss= 1.14153 train_acc= 0.98333 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  243.67471385002136\n",
      "edge_vol 9288.0\n",
      "Epoch: 0319 train_loss= 0.49425 val_loss= 1.14002 train_acc= 0.98333 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  244.3078317642212\n",
      "edge_vol 9288.0\n",
      "Epoch: 0320 train_loss= 0.49323 val_loss= 1.13848 train_acc= 0.98333 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  245.13775634765625\n",
      "edge_vol 9288.0\n",
      "Epoch: 0321 train_loss= 0.49006 val_loss= 1.13696 train_acc= 0.98333 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  245.78100562095642\n",
      "edge_vol 9288.0\n",
      "Epoch: 0322 train_loss= 0.48896 val_loss= 1.13548 train_acc= 0.98333 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  246.5656042098999\n",
      "edge_vol 9288.0\n",
      "Epoch: 0323 train_loss= 0.48738 val_loss= 1.13401 train_acc= 0.98333 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  247.26861000061035\n",
      "edge_vol 9288.0\n",
      "Epoch: 0324 train_loss= 0.48469 val_loss= 1.13263 train_acc= 0.98333 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  247.96696424484253\n",
      "edge_vol 9288.0\n",
      "Epoch: 0325 train_loss= 0.48386 val_loss= 1.13120 train_acc= 0.98333 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  248.75485730171204\n",
      "edge_vol 9288.0\n",
      "Epoch: 0326 train_loss= 0.48272 val_loss= 1.12966 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  249.52708101272583\n",
      "edge_vol 9288.0\n",
      "Epoch: 0327 train_loss= 0.48071 val_loss= 1.12810 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  250.19328784942627\n",
      "edge_vol 9288.0\n",
      "Epoch: 0328 train_loss= 0.47898 val_loss= 1.12660 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  250.98008942604065\n",
      "edge_vol 9288.0\n",
      "Epoch: 0329 train_loss= 0.47641 val_loss= 1.12505 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  251.58680176734924\n",
      "edge_vol 9288.0\n",
      "Epoch: 0330 train_loss= 0.47495 val_loss= 1.12352 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  252.21232557296753\n",
      "edge_vol 9288.0\n",
      "Epoch: 0331 train_loss= 0.47299 val_loss= 1.12197 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  252.85364031791687\n",
      "edge_vol 9288.0\n",
      "Epoch: 0332 train_loss= 0.47127 val_loss= 1.12040 train_acc= 0.98333 val_acc= 0.71400 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  253.47651886940002\n",
      "edge_vol 9288.0\n",
      "Epoch: 0333 train_loss= 0.46977 val_loss= 1.11886 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  254.17573761940002\n",
      "edge_vol 9288.0\n",
      "Epoch: 0334 train_loss= 0.46813 val_loss= 1.11732 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  254.90299797058105\n",
      "edge_vol 9288.0\n",
      "Epoch: 0335 train_loss= 0.46577 val_loss= 1.11582 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  255.63827347755432\n",
      "edge_vol 9288.0\n",
      "Epoch: 0336 train_loss= 0.46459 val_loss= 1.11446 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  256.48793268203735\n",
      "edge_vol 9288.0\n",
      "Epoch: 0337 train_loss= 0.46273 val_loss= 1.11313 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  257.30034923553467\n",
      "edge_vol 9288.0\n",
      "Epoch: 0338 train_loss= 0.46120 val_loss= 1.11182 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  258.1175150871277\n",
      "edge_vol 9288.0\n",
      "Epoch: 0339 train_loss= 0.45918 val_loss= 1.11055 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  258.964421749115\n",
      "edge_vol 9288.0\n",
      "Epoch: 0340 train_loss= 0.45800 val_loss= 1.10940 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  259.8009867668152\n",
      "edge_vol 9288.0\n",
      "Epoch: 0341 train_loss= 0.45655 val_loss= 1.10818 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  260.60353326797485\n",
      "edge_vol 9288.0\n",
      "Epoch: 0342 train_loss= 0.45514 val_loss= 1.10694 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  261.36241817474365\n",
      "edge_vol 9288.0\n",
      "Epoch: 0343 train_loss= 0.45269 val_loss= 1.10559 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  262.21307158470154\n",
      "edge_vol 9288.0\n",
      "Epoch: 0344 train_loss= 0.45128 val_loss= 1.10425 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  263.08967542648315\n",
      "edge_vol 9288.0\n",
      "Epoch: 0345 train_loss= 0.44950 val_loss= 1.10290 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  263.97540068626404\n",
      "edge_vol 9288.0\n",
      "Epoch: 0346 train_loss= 0.44781 val_loss= 1.10154 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  264.8430211544037\n",
      "edge_vol 9288.0\n",
      "Epoch: 0347 train_loss= 0.44576 val_loss= 1.10028 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  265.7119491100311\n",
      "edge_vol 9288.0\n",
      "Epoch: 0348 train_loss= 0.44591 val_loss= 1.09918 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  266.6011142730713\n",
      "edge_vol 9288.0\n",
      "Epoch: 0349 train_loss= 0.44308 val_loss= 1.09817 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  267.46264600753784\n",
      "edge_vol 9288.0\n",
      "Epoch: 0350 train_loss= 0.44165 val_loss= 1.09710 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  268.23425102233887\n",
      "edge_vol 9288.0\n",
      "Epoch: 0351 train_loss= 0.44042 val_loss= 1.09601 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  269.01220655441284\n",
      "edge_vol 9288.0\n",
      "Epoch: 0352 train_loss= 0.43920 val_loss= 1.09487 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  269.82543754577637\n",
      "edge_vol 9288.0\n",
      "Epoch: 0353 train_loss= 0.43740 val_loss= 1.09373 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  270.5540506839752\n",
      "edge_vol 9288.0\n",
      "Epoch: 0354 train_loss= 0.43655 val_loss= 1.09262 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  271.2633137702942\n",
      "edge_vol 9288.0\n",
      "Epoch: 0355 train_loss= 0.43453 val_loss= 1.09150 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  271.9564907550812\n",
      "edge_vol 9288.0\n",
      "Epoch: 0356 train_loss= 0.43313 val_loss= 1.09050 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  272.7251148223877\n",
      "edge_vol 9288.0\n",
      "Epoch: 0357 train_loss= 0.43292 val_loss= 1.08936 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  273.47048830986023\n",
      "edge_vol 9288.0\n",
      "Epoch: 0358 train_loss= 0.43085 val_loss= 1.08836 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  274.2132725715637\n",
      "edge_vol 9288.0\n",
      "Epoch: 0359 train_loss= 0.42997 val_loss= 1.08738 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  274.88505005836487\n",
      "edge_vol 9288.0\n",
      "Epoch: 0360 train_loss= 0.42840 val_loss= 1.08640 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  275.7053415775299\n",
      "edge_vol 9288.0\n",
      "Epoch: 0361 train_loss= 0.42845 val_loss= 1.08540 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  276.41319513320923\n",
      "edge_vol 9288.0\n",
      "Epoch: 0362 train_loss= 0.42625 val_loss= 1.08428 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  277.10069370269775\n",
      "edge_vol 9288.0\n",
      "Epoch: 0363 train_loss= 0.42503 val_loss= 1.08326 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  277.8419301509857\n",
      "edge_vol 9288.0\n",
      "Epoch: 0364 train_loss= 0.42327 val_loss= 1.08236 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  278.59307646751404\n",
      "edge_vol 9288.0\n",
      "Epoch: 0365 train_loss= 0.42301 val_loss= 1.08140 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  279.33777475357056\n",
      "edge_vol 9288.0\n",
      "Epoch: 0366 train_loss= 0.42129 val_loss= 1.08049 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  280.04274010658264\n",
      "edge_vol 9288.0\n",
      "Epoch: 0367 train_loss= 0.41995 val_loss= 1.07958 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  280.7840197086334\n",
      "edge_vol 9288.0\n",
      "Epoch: 0368 train_loss= 0.41847 val_loss= 1.07855 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  281.5195472240448\n",
      "edge_vol 9288.0\n",
      "Epoch: 0369 train_loss= 0.41766 val_loss= 1.07750 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  282.21272230148315\n",
      "edge_vol 9288.0\n",
      "Epoch: 0370 train_loss= 0.41700 val_loss= 1.07646 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  282.9455876350403\n",
      "edge_vol 9288.0\n",
      "Epoch: 0371 train_loss= 0.41588 val_loss= 1.07553 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  283.7799656391144\n",
      "edge_vol 9288.0\n",
      "Epoch: 0372 train_loss= 0.41459 val_loss= 1.07463 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  284.5260570049286\n",
      "edge_vol 9288.0\n",
      "Epoch: 0373 train_loss= 0.41350 val_loss= 1.07374 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  285.278195142746\n",
      "edge_vol 9288.0\n",
      "Epoch: 0374 train_loss= 0.41230 val_loss= 1.07285 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  286.11212849617004\n",
      "edge_vol 9288.0\n",
      "Epoch: 0375 train_loss= 0.41095 val_loss= 1.07199 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  286.84053134918213\n",
      "edge_vol 9288.0\n",
      "Epoch: 0376 train_loss= 0.40978 val_loss= 1.07116 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  287.6069710254669\n",
      "edge_vol 9288.0\n",
      "Epoch: 0377 train_loss= 0.40926 val_loss= 1.07039 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  288.3094251155853\n",
      "edge_vol 9288.0\n",
      "Epoch: 0378 train_loss= 0.40745 val_loss= 1.06958 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  289.02357387542725\n",
      "edge_vol 9288.0\n",
      "Epoch: 0379 train_loss= 0.40680 val_loss= 1.06872 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  289.7102155685425\n",
      "edge_vol 9288.0\n",
      "Epoch: 0380 train_loss= 0.40585 val_loss= 1.06798 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  290.42535972595215\n",
      "edge_vol 9288.0\n",
      "Epoch: 0381 train_loss= 0.40478 val_loss= 1.06713 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  291.27063488960266\n",
      "edge_vol 9288.0\n",
      "Epoch: 0382 train_loss= 0.40345 val_loss= 1.06632 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  292.132435798645\n",
      "edge_vol 9288.0\n",
      "Epoch: 0383 train_loss= 0.40271 val_loss= 1.06551 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  292.847327709198\n",
      "edge_vol 9288.0\n",
      "Epoch: 0384 train_loss= 0.40145 val_loss= 1.06474 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  293.4960618019104\n",
      "edge_vol 9288.0\n",
      "Epoch: 0385 train_loss= 0.40029 val_loss= 1.06391 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  294.1386749744415\n",
      "edge_vol 9288.0\n",
      "Epoch: 0386 train_loss= 0.39902 val_loss= 1.06308 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  294.77929186820984\n",
      "edge_vol 9288.0\n",
      "Epoch: 0387 train_loss= 0.39839 val_loss= 1.06225 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  295.4613468647003\n",
      "edge_vol 9288.0\n",
      "Epoch: 0388 train_loss= 0.39747 val_loss= 1.06144 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  296.08272528648376\n",
      "edge_vol 9288.0\n",
      "Epoch: 0389 train_loss= 0.39651 val_loss= 1.06065 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  296.70656275749207\n",
      "edge_vol 9288.0\n",
      "Epoch: 0390 train_loss= 0.39652 val_loss= 1.05993 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  297.3873312473297\n",
      "edge_vol 9288.0\n",
      "Epoch: 0391 train_loss= 0.39439 val_loss= 1.05912 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  298.0693621635437\n",
      "edge_vol 9288.0\n",
      "Epoch: 0392 train_loss= 0.39349 val_loss= 1.05827 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  298.8449070453644\n",
      "edge_vol 9288.0\n",
      "Epoch: 0393 train_loss= 0.39276 val_loss= 1.05738 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  299.55379581451416\n",
      "edge_vol 9288.0\n",
      "Epoch: 0394 train_loss= 0.39174 val_loss= 1.05650 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  300.2837381362915\n",
      "edge_vol 9288.0\n",
      "Epoch: 0395 train_loss= 0.38945 val_loss= 1.05557 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  300.8811459541321\n",
      "edge_vol 9288.0\n",
      "Epoch: 0396 train_loss= 0.39020 val_loss= 1.05465 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  301.54380893707275\n",
      "edge_vol 9288.0\n",
      "Epoch: 0397 train_loss= 0.38796 val_loss= 1.05378 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  302.2686984539032\n",
      "edge_vol 9288.0\n",
      "Epoch: 0398 train_loss= 0.38647 val_loss= 1.05297 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  302.896372795105\n",
      "edge_vol 9288.0\n",
      "Epoch: 0399 train_loss= 0.38637 val_loss= 1.05215 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  303.56769490242004\n",
      "edge_vol 9288.0\n",
      "Epoch: 0400 train_loss= 0.38483 val_loss= 1.05130 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  304.2356333732605\n",
      "edge_vol 9288.0\n",
      "Epoch: 0401 train_loss= 0.38357 val_loss= 1.05043 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  304.86770606040955\n",
      "edge_vol 9288.0\n",
      "Epoch: 0402 train_loss= 0.38246 val_loss= 1.04962 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  305.6720700263977\n",
      "edge_vol 9288.0\n",
      "Epoch: 0403 train_loss= 0.38160 val_loss= 1.04877 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  306.5034010410309\n",
      "edge_vol 9288.0\n",
      "Epoch: 0404 train_loss= 0.38063 val_loss= 1.04788 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  307.39577436447144\n",
      "edge_vol 9288.0\n",
      "Epoch: 0405 train_loss= 0.37914 val_loss= 1.04716 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  308.229864358902\n",
      "edge_vol 9288.0\n",
      "Epoch: 0406 train_loss= 0.37863 val_loss= 1.04643 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  309.095623254776\n",
      "edge_vol 9288.0\n",
      "Epoch: 0407 train_loss= 0.37755 val_loss= 1.04572 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  309.90625166893005\n",
      "edge_vol 9288.0\n",
      "Epoch: 0408 train_loss= 0.37651 val_loss= 1.04502 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  310.7564113140106\n",
      "edge_vol 9288.0\n",
      "Epoch: 0409 train_loss= 0.37494 val_loss= 1.04430 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  311.55486941337585\n",
      "edge_vol 9288.0\n",
      "Epoch: 0410 train_loss= 0.37482 val_loss= 1.04363 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  312.3977952003479\n",
      "edge_vol 9288.0\n",
      "Epoch: 0411 train_loss= 0.37404 val_loss= 1.04300 train_acc= 0.99167 val_acc= 0.71600 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  313.2477676868439\n",
      "edge_vol 9288.0\n",
      "Epoch: 0412 train_loss= 0.37285 val_loss= 1.04236 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  314.0831890106201\n",
      "edge_vol 9288.0\n",
      "Epoch: 0413 train_loss= 0.37284 val_loss= 1.04174 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72000 test_acc= 0.70200\n",
      "time  314.9260802268982\n",
      "edge_vol 9288.0\n",
      "Epoch: 0414 train_loss= 0.37135 val_loss= 1.04115 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  315.7333116531372\n",
      "edge_vol 9288.0\n",
      "Epoch: 0415 train_loss= 0.37016 val_loss= 1.04052 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  316.5814137458801\n",
      "edge_vol 9288.0\n",
      "Epoch: 0416 train_loss= 0.36980 val_loss= 1.03993 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  317.31650733947754\n",
      "edge_vol 9288.0\n",
      "Epoch: 0417 train_loss= 0.36928 val_loss= 1.03936 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  318.06774830818176\n",
      "edge_vol 9288.0\n",
      "Epoch: 0418 train_loss= 0.36818 val_loss= 1.03876 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  318.8628799915314\n",
      "edge_vol 9288.0\n",
      "Epoch: 0419 train_loss= 0.36737 val_loss= 1.03816 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  319.6783230304718\n",
      "edge_vol 9288.0\n",
      "Epoch: 0420 train_loss= 0.36662 val_loss= 1.03758 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  320.42008423805237\n",
      "edge_vol 9288.0\n",
      "Epoch: 0421 train_loss= 0.36578 val_loss= 1.03699 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  321.18951416015625\n",
      "edge_vol 9288.0\n",
      "Epoch: 0422 train_loss= 0.36514 val_loss= 1.03645 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  321.88480591773987\n",
      "edge_vol 9288.0\n",
      "Epoch: 0423 train_loss= 0.36448 val_loss= 1.03597 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  322.67392897605896\n",
      "edge_vol 9288.0\n",
      "Epoch: 0424 train_loss= 0.36376 val_loss= 1.03545 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  323.4064028263092\n",
      "edge_vol 9288.0\n",
      "Epoch: 0425 train_loss= 0.36268 val_loss= 1.03490 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  324.15738582611084\n",
      "edge_vol 9288.0\n",
      "Epoch: 0426 train_loss= 0.36208 val_loss= 1.03442 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  324.8664219379425\n",
      "edge_vol 9288.0\n",
      "Epoch: 0427 train_loss= 0.36170 val_loss= 1.03390 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  325.6589126586914\n",
      "edge_vol 9288.0\n",
      "Epoch: 0428 train_loss= 0.36215 val_loss= 1.03343 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  326.4013342857361\n",
      "edge_vol 9288.0\n",
      "Epoch: 0429 train_loss= 0.36024 val_loss= 1.03300 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  327.15182304382324\n",
      "edge_vol 9288.0\n",
      "Epoch: 0430 train_loss= 0.35905 val_loss= 1.03255 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  327.8433287143707\n",
      "edge_vol 9288.0\n",
      "Epoch: 0431 train_loss= 0.35904 val_loss= 1.03215 train_acc= 0.99167 val_acc= 0.71800 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  328.6604902744293\n",
      "edge_vol 9288.0\n",
      "Epoch: 0432 train_loss= 0.35852 val_loss= 1.03180 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  329.36237144470215\n",
      "edge_vol 9288.0\n",
      "Epoch: 0433 train_loss= 0.35755 val_loss= 1.03151 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  330.12352561950684\n",
      "edge_vol 9288.0\n",
      "Epoch: 0434 train_loss= 0.35744 val_loss= 1.03122 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  330.867876291275\n",
      "edge_vol 9288.0\n",
      "Epoch: 0435 train_loss= 0.35699 val_loss= 1.03088 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  331.60233879089355\n",
      "edge_vol 9288.0\n",
      "Epoch: 0436 train_loss= 0.35645 val_loss= 1.03049 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  332.4413285255432\n",
      "edge_vol 9288.0\n",
      "Epoch: 0437 train_loss= 0.35570 val_loss= 1.03008 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  333.15998935699463\n",
      "edge_vol 9288.0\n",
      "Epoch: 0438 train_loss= 0.35508 val_loss= 1.02969 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  333.94095849990845\n",
      "edge_vol 9288.0\n",
      "Epoch: 0439 train_loss= 0.35457 val_loss= 1.02938 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  334.6900134086609\n",
      "edge_vol 9288.0\n",
      "Epoch: 0440 train_loss= 0.35480 val_loss= 1.02900 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  335.3886113166809\n",
      "edge_vol 9288.0\n",
      "Epoch: 0441 train_loss= 0.35322 val_loss= 1.02864 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  336.1381022930145\n",
      "edge_vol 9288.0\n",
      "Epoch: 0442 train_loss= 0.35276 val_loss= 1.02825 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  336.8499448299408\n",
      "edge_vol 9288.0\n",
      "Epoch: 0443 train_loss= 0.35189 val_loss= 1.02781 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  337.5354583263397\n",
      "edge_vol 9288.0\n",
      "Epoch: 0444 train_loss= 0.35117 val_loss= 1.02737 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  338.32368421554565\n",
      "edge_vol 9288.0\n",
      "Epoch: 0445 train_loss= 0.35075 val_loss= 1.02701 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  339.1926474571228\n",
      "edge_vol 9288.0\n",
      "Epoch: 0446 train_loss= 0.35009 val_loss= 1.02672 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  340.02155661582947\n",
      "edge_vol 9288.0\n",
      "Epoch: 0447 train_loss= 0.34943 val_loss= 1.02645 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  340.74840474128723\n",
      "edge_vol 9288.0\n",
      "Epoch: 0448 train_loss= 0.34879 val_loss= 1.02610 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  341.458536863327\n",
      "edge_vol 9288.0\n",
      "Epoch: 0449 train_loss= 0.34804 val_loss= 1.02570 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  342.18947315216064\n",
      "edge_vol 9288.0\n",
      "Epoch: 0450 train_loss= 0.34771 val_loss= 1.02524 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  342.8862888813019\n",
      "edge_vol 9288.0\n",
      "Epoch: 0451 train_loss= 0.34651 val_loss= 1.02476 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  343.65570306777954\n",
      "edge_vol 9288.0\n",
      "Epoch: 0452 train_loss= 0.34549 val_loss= 1.02429 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  344.27757716178894\n",
      "edge_vol 9288.0\n",
      "Epoch: 0453 train_loss= 0.34531 val_loss= 1.02385 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  344.92903423309326\n",
      "edge_vol 9288.0\n",
      "Epoch: 0454 train_loss= 0.34471 val_loss= 1.02343 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  345.68707752227783\n",
      "edge_vol 9288.0\n",
      "Epoch: 0455 train_loss= 0.34426 val_loss= 1.02306 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  346.352082490921\n",
      "edge_vol 9288.0\n",
      "Epoch: 0456 train_loss= 0.34357 val_loss= 1.02267 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  347.0001666545868\n",
      "edge_vol 9288.0\n",
      "Epoch: 0457 train_loss= 0.34287 val_loss= 1.02224 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  347.62133026123047\n",
      "edge_vol 9288.0\n",
      "Epoch: 0458 train_loss= 0.34224 val_loss= 1.02180 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  348.3122932910919\n",
      "edge_vol 9288.0\n",
      "Epoch: 0459 train_loss= 0.34141 val_loss= 1.02131 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  349.0874590873718\n",
      "edge_vol 9288.0\n",
      "Epoch: 0460 train_loss= 0.34077 val_loss= 1.02089 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  349.78706765174866\n",
      "edge_vol 9288.0\n",
      "Epoch: 0461 train_loss= 0.33992 val_loss= 1.02047 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  350.49597120285034\n",
      "edge_vol 9288.0\n",
      "Epoch: 0462 train_loss= 0.33951 val_loss= 1.02000 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  351.14011096954346\n",
      "edge_vol 9288.0\n",
      "Epoch: 0463 train_loss= 0.33861 val_loss= 1.01952 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  351.8298692703247\n",
      "edge_vol 9288.0\n",
      "Epoch: 0464 train_loss= 0.33768 val_loss= 1.01905 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  352.44962072372437\n",
      "edge_vol 9288.0\n",
      "Epoch: 0465 train_loss= 0.33719 val_loss= 1.01863 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  353.2399046421051\n",
      "edge_vol 9288.0\n",
      "Epoch: 0466 train_loss= 0.33631 val_loss= 1.01815 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  353.9251158237457\n",
      "edge_vol 9288.0\n",
      "Epoch: 0467 train_loss= 0.33567 val_loss= 1.01772 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  354.79966044425964\n",
      "edge_vol 9288.0\n",
      "Epoch: 0468 train_loss= 0.33502 val_loss= 1.01729 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  355.5225875377655\n",
      "edge_vol 9288.0\n",
      "Epoch: 0469 train_loss= 0.33413 val_loss= 1.01684 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  356.26784086227417\n",
      "edge_vol 9288.0\n",
      "Epoch: 0470 train_loss= 0.33361 val_loss= 1.01643 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  357.1194062232971\n",
      "edge_vol 9288.0\n",
      "Epoch: 0471 train_loss= 0.33307 val_loss= 1.01609 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  357.9837529659271\n",
      "edge_vol 9288.0\n",
      "Epoch: 0472 train_loss= 0.33236 val_loss= 1.01574 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  358.9201204776764\n",
      "edge_vol 9288.0\n",
      "Epoch: 0473 train_loss= 0.33142 val_loss= 1.01543 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  359.77540159225464\n",
      "edge_vol 9288.0\n",
      "Epoch: 0474 train_loss= 0.33121 val_loss= 1.01502 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  360.63293838500977\n",
      "edge_vol 9288.0\n",
      "Epoch: 0475 train_loss= 0.33060 val_loss= 1.01460 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  361.4766869544983\n",
      "edge_vol 9288.0\n",
      "Epoch: 0476 train_loss= 0.33015 val_loss= 1.01420 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  362.3208568096161\n",
      "edge_vol 9288.0\n",
      "Epoch: 0477 train_loss= 0.32970 val_loss= 1.01380 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  363.20037484169006\n",
      "edge_vol 9288.0\n",
      "Epoch: 0478 train_loss= 0.32925 val_loss= 1.01340 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  364.0549156665802\n",
      "edge_vol 9288.0\n",
      "Epoch: 0479 train_loss= 0.32876 val_loss= 1.01305 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  364.9088222980499\n",
      "edge_vol 9288.0\n",
      "Epoch: 0480 train_loss= 0.32836 val_loss= 1.01274 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  365.68110966682434\n",
      "edge_vol 9288.0\n",
      "Epoch: 0481 train_loss= 0.32797 val_loss= 1.01242 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  366.4564390182495\n",
      "edge_vol 9288.0\n",
      "Epoch: 0482 train_loss= 0.32734 val_loss= 1.01213 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  367.1796054840088\n",
      "edge_vol 9288.0\n",
      "Epoch: 0483 train_loss= 0.32770 val_loss= 1.01180 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  367.96287393569946\n",
      "edge_vol 9288.0\n",
      "Epoch: 0484 train_loss= 0.32677 val_loss= 1.01144 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  368.71929574012756\n",
      "edge_vol 9288.0\n",
      "Epoch: 0485 train_loss= 0.32642 val_loss= 1.01105 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  369.3967001438141\n",
      "edge_vol 9288.0\n",
      "Epoch: 0486 train_loss= 0.32588 val_loss= 1.01069 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  370.09240794181824\n",
      "edge_vol 9288.0\n",
      "Epoch: 0487 train_loss= 0.32552 val_loss= 1.01036 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  370.817538022995\n",
      "edge_vol 9288.0\n",
      "Epoch: 0488 train_loss= 0.32494 val_loss= 1.00999 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  371.5553629398346\n",
      "edge_vol 9288.0\n",
      "Epoch: 0489 train_loss= 0.32458 val_loss= 1.00960 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72200 test_acc= 0.70600\n",
      "time  372.33551478385925\n",
      "edge_vol 9288.0\n",
      "Epoch: 0490 train_loss= 0.32353 val_loss= 1.00925 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  373.23424077033997\n",
      "edge_vol 9288.0\n",
      "Epoch: 0491 train_loss= 0.32319 val_loss= 1.00889 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  373.9206829071045\n",
      "edge_vol 9288.0\n",
      "Epoch: 0492 train_loss= 0.32300 val_loss= 1.00857 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  374.6129491329193\n",
      "edge_vol 9288.0\n",
      "Epoch: 0493 train_loss= 0.32221 val_loss= 1.00822 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  375.3234579563141\n",
      "edge_vol 9288.0\n",
      "Epoch: 0494 train_loss= 0.32169 val_loss= 1.00785 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  376.02121233940125\n",
      "edge_vol 9288.0\n",
      "Epoch: 0495 train_loss= 0.32100 val_loss= 1.00751 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  376.64542961120605\n",
      "edge_vol 9288.0\n",
      "Epoch: 0496 train_loss= 0.32084 val_loss= 1.00715 train_acc= 0.99167 val_acc= 0.72200 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  377.3288950920105\n",
      "edge_vol 9288.0\n",
      "Epoch: 0497 train_loss= 0.32011 val_loss= 1.00687 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  378.0480718612671\n",
      "edge_vol 9288.0\n",
      "Epoch: 0498 train_loss= 0.31964 val_loss= 1.00654 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  378.7159297466278\n",
      "edge_vol 9288.0\n",
      "Epoch: 0499 train_loss= 0.31911 val_loss= 1.00618 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  379.35855317115784\n",
      "edge_vol 9288.0\n",
      "Epoch: 0500 train_loss= 0.31860 val_loss= 1.00584 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  380.0306935310364\n",
      "edge_vol 9288.0\n",
      "Epoch: 0501 train_loss= 0.31788 val_loss= 1.00555 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  380.9042191505432\n",
      "edge_vol 9288.0\n",
      "Epoch: 0502 train_loss= 0.31766 val_loss= 1.00526 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  381.65034461021423\n",
      "edge_vol 9288.0\n",
      "Epoch: 0503 train_loss= 0.31709 val_loss= 1.00495 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  382.29632234573364\n",
      "edge_vol 9288.0\n",
      "Epoch: 0504 train_loss= 0.31659 val_loss= 1.00460 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  383.05242705345154\n",
      "edge_vol 9288.0\n",
      "Epoch: 0505 train_loss= 0.31588 val_loss= 1.00425 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  383.779639005661\n",
      "edge_vol 9288.0\n",
      "Epoch: 0506 train_loss= 0.31554 val_loss= 1.00395 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  384.4838800430298\n",
      "edge_vol 9288.0\n",
      "Epoch: 0507 train_loss= 0.31497 val_loss= 1.00366 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  385.21732664108276\n",
      "edge_vol 9288.0\n",
      "Epoch: 0508 train_loss= 0.31484 val_loss= 1.00338 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  385.9548411369324\n",
      "edge_vol 9288.0\n",
      "Epoch: 0509 train_loss= 0.31414 val_loss= 1.00312 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  386.76514983177185\n",
      "edge_vol 9288.0\n",
      "Epoch: 0510 train_loss= 0.31364 val_loss= 1.00285 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  387.45802116394043\n",
      "edge_vol 9288.0\n",
      "Epoch: 0511 train_loss= 0.31317 val_loss= 1.00259 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  388.29574275016785\n",
      "edge_vol 9288.0\n",
      "Epoch: 0512 train_loss= 0.31263 val_loss= 1.00234 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  389.027259349823\n",
      "edge_vol 9288.0\n",
      "Epoch: 0513 train_loss= 0.31223 val_loss= 1.00211 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  389.79750776290894\n",
      "edge_vol 9288.0\n",
      "Epoch: 0514 train_loss= 0.31181 val_loss= 1.00185 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  390.50802636146545\n",
      "edge_vol 9288.0\n",
      "Epoch: 0515 train_loss= 0.31106 val_loss= 1.00163 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  391.16066098213196\n",
      "edge_vol 9288.0\n",
      "Epoch: 0516 train_loss= 0.31095 val_loss= 1.00141 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  391.9493887424469\n",
      "edge_vol 9288.0\n",
      "Epoch: 0517 train_loss= 0.31058 val_loss= 1.00107 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  392.7125928401947\n",
      "edge_vol 9288.0\n",
      "Epoch: 0518 train_loss= 0.31019 val_loss= 1.00079 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  393.40743112564087\n",
      "edge_vol 9288.0\n",
      "Epoch: 0519 train_loss= 0.30987 val_loss= 1.00043 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  394.326265335083\n",
      "edge_vol 9288.0\n",
      "Epoch: 0520 train_loss= 0.30930 val_loss= 1.00007 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  395.0546646118164\n",
      "edge_vol 9288.0\n",
      "Epoch: 0521 train_loss= 0.30886 val_loss= 0.99972 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  395.6959114074707\n",
      "edge_vol 9288.0\n",
      "Epoch: 0522 train_loss= 0.30836 val_loss= 0.99937 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  396.32773995399475\n",
      "edge_vol 9288.0\n",
      "Epoch: 0523 train_loss= 0.30781 val_loss= 0.99906 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  397.13747239112854\n",
      "edge_vol 9288.0\n",
      "Epoch: 0524 train_loss= 0.30746 val_loss= 0.99878 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  397.78590512275696\n",
      "edge_vol 9288.0\n",
      "Epoch: 0525 train_loss= 0.30719 val_loss= 0.99845 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  398.43529653549194\n",
      "edge_vol 9288.0\n",
      "Epoch: 0526 train_loss= 0.30596 val_loss= 0.99810 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  399.0538284778595\n",
      "edge_vol 9288.0\n",
      "Epoch: 0527 train_loss= 0.30641 val_loss= 0.99775 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  399.7124893665314\n",
      "edge_vol 9288.0\n",
      "Epoch: 0528 train_loss= 0.30590 val_loss= 0.99746 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  400.4326012134552\n",
      "edge_vol 9288.0\n",
      "Epoch: 0529 train_loss= 0.30534 val_loss= 0.99724 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  401.15538477897644\n",
      "edge_vol 9288.0\n",
      "Epoch: 0530 train_loss= 0.30509 val_loss= 0.99706 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  401.6590790748596\n",
      "edge_vol 9288.0\n",
      "Epoch: 0531 train_loss= 0.30441 val_loss= 0.99675 train_acc= 0.99167 val_acc= 0.72400 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  402.07243394851685\n",
      "edge_vol 9288.0\n",
      "Epoch: 0532 train_loss= 0.30408 val_loss= 0.99648 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  402.49085235595703\n",
      "edge_vol 9288.0\n",
      "Epoch: 0533 train_loss= 0.30383 val_loss= 0.99628 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  402.91807413101196\n",
      "edge_vol 9288.0\n",
      "Epoch: 0534 train_loss= 0.30352 val_loss= 0.99609 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  403.35786390304565\n",
      "edge_vol 9288.0\n",
      "Epoch: 0535 train_loss= 0.30313 val_loss= 0.99589 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  403.9216356277466\n",
      "edge_vol 9288.0\n",
      "Epoch: 0536 train_loss= 0.30271 val_loss= 0.99572 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  404.32979941368103\n",
      "edge_vol 9288.0\n",
      "Epoch: 0537 train_loss= 0.30261 val_loss= 0.99555 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  404.74097299575806\n",
      "edge_vol 9288.0\n",
      "Epoch: 0538 train_loss= 0.30231 val_loss= 0.99540 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  405.1476743221283\n",
      "edge_vol 9288.0\n",
      "Epoch: 0539 train_loss= 0.30223 val_loss= 0.99531 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  405.57633781433105\n",
      "edge_vol 9288.0\n",
      "Epoch: 0540 train_loss= 0.30179 val_loss= 0.99522 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  406.17596673965454\n",
      "edge_vol 9288.0\n",
      "Epoch: 0541 train_loss= 0.30146 val_loss= 0.99511 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  406.7953555583954\n",
      "edge_vol 9288.0\n",
      "Epoch: 0542 train_loss= 0.30104 val_loss= 0.99498 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  407.25895500183105\n",
      "edge_vol 9288.0\n",
      "Epoch: 0543 train_loss= 0.30081 val_loss= 0.99483 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  407.71571230888367\n",
      "edge_vol 9288.0\n",
      "Epoch: 0544 train_loss= 0.30035 val_loss= 0.99471 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  408.3226704597473\n",
      "edge_vol 9288.0\n",
      "Epoch: 0545 train_loss= 0.30035 val_loss= 0.99463 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  408.88022780418396\n",
      "edge_vol 9288.0\n",
      "Epoch: 0546 train_loss= 0.29997 val_loss= 0.99448 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  409.4096555709839\n",
      "edge_vol 9288.0\n",
      "Epoch: 0547 train_loss= 0.29968 val_loss= 0.99430 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  409.97499084472656\n",
      "edge_vol 9288.0\n",
      "Epoch: 0548 train_loss= 0.29939 val_loss= 0.99409 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  410.5726499557495\n",
      "edge_vol 9288.0\n",
      "Epoch: 0549 train_loss= 0.29875 val_loss= 0.99388 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  411.1762990951538\n",
      "edge_vol 9288.0\n",
      "Epoch: 0550 train_loss= 0.29837 val_loss= 0.99366 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  411.82015347480774\n",
      "edge_vol 9288.0\n",
      "Epoch: 0551 train_loss= 0.29803 val_loss= 0.99343 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  412.56518030166626\n",
      "edge_vol 9288.0\n",
      "Epoch: 0552 train_loss= 0.29757 val_loss= 0.99313 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  413.15159702301025\n",
      "edge_vol 9288.0\n",
      "Epoch: 0553 train_loss= 0.29698 val_loss= 0.99288 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  413.7739005088806\n",
      "edge_vol 9288.0\n",
      "Epoch: 0554 train_loss= 0.29636 val_loss= 0.99261 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  414.4577076435089\n",
      "edge_vol 9288.0\n",
      "Epoch: 0555 train_loss= 0.29637 val_loss= 0.99248 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  415.1312298774719\n",
      "edge_vol 9288.0\n",
      "Epoch: 0556 train_loss= 0.29597 val_loss= 0.99234 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  415.7199113368988\n",
      "edge_vol 9288.0\n",
      "Epoch: 0557 train_loss= 0.29563 val_loss= 0.99216 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  416.3453588485718\n",
      "edge_vol 9288.0\n",
      "Epoch: 0558 train_loss= 0.29536 val_loss= 0.99192 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  417.13569951057434\n",
      "edge_vol 9288.0\n",
      "Epoch: 0559 train_loss= 0.29488 val_loss= 0.99167 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  417.7597644329071\n",
      "edge_vol 9288.0\n",
      "Epoch: 0560 train_loss= 0.29463 val_loss= 0.99140 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  418.365309715271\n",
      "edge_vol 9288.0\n",
      "Epoch: 0561 train_loss= 0.29429 val_loss= 0.99112 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  419.0137574672699\n",
      "edge_vol 9288.0\n",
      "Epoch: 0562 train_loss= 0.29398 val_loss= 0.99084 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  419.60328221321106\n",
      "edge_vol 9288.0\n",
      "Epoch: 0563 train_loss= 0.29357 val_loss= 0.99066 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  420.4078104496002\n",
      "edge_vol 9288.0\n",
      "Epoch: 0564 train_loss= 0.29306 val_loss= 0.99049 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  421.10130047798157\n",
      "edge_vol 9288.0\n",
      "Epoch: 0565 train_loss= 0.29296 val_loss= 0.99033 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  421.66348338127136\n",
      "edge_vol 9288.0\n",
      "Epoch: 0566 train_loss= 0.29238 val_loss= 0.99021 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  422.18945121765137\n",
      "edge_vol 9288.0\n",
      "Epoch: 0567 train_loss= 0.29207 val_loss= 0.99007 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  422.8887550830841\n",
      "edge_vol 9288.0\n",
      "Epoch: 0568 train_loss= 0.29188 val_loss= 0.98990 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  423.5385479927063\n",
      "edge_vol 9288.0\n",
      "Epoch: 0569 train_loss= 0.29124 val_loss= 0.98972 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  424.25509762763977\n",
      "edge_vol 9288.0\n",
      "Epoch: 0570 train_loss= 0.29099 val_loss= 0.98952 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  425.066899061203\n",
      "edge_vol 9288.0\n",
      "Epoch: 0571 train_loss= 0.29063 val_loss= 0.98931 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  425.64069533348083\n",
      "edge_vol 9288.0\n",
      "Epoch: 0572 train_loss= 0.28991 val_loss= 0.98913 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  426.48989725112915\n",
      "edge_vol 9288.0\n",
      "Epoch: 0573 train_loss= 0.28959 val_loss= 0.98897 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  427.0966992378235\n",
      "edge_vol 9288.0\n",
      "Epoch: 0574 train_loss= 0.28932 val_loss= 0.98877 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  427.6994261741638\n",
      "edge_vol 9288.0\n",
      "Epoch: 0575 train_loss= 0.28910 val_loss= 0.98854 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  428.34773874282837\n",
      "edge_vol 9288.0\n",
      "Epoch: 0576 train_loss= 0.28867 val_loss= 0.98828 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  428.9699079990387\n",
      "edge_vol 9288.0\n",
      "Epoch: 0577 train_loss= 0.28849 val_loss= 0.98807 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  429.71232748031616\n",
      "edge_vol 9288.0\n",
      "Epoch: 0578 train_loss= 0.28815 val_loss= 0.98795 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  430.51983857154846\n",
      "edge_vol 9288.0\n",
      "Epoch: 0579 train_loss= 0.28770 val_loss= 0.98775 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  431.08949041366577\n",
      "edge_vol 9288.0\n",
      "Epoch: 0580 train_loss= 0.28727 val_loss= 0.98756 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  431.66650557518005\n",
      "edge_vol 9288.0\n",
      "Epoch: 0581 train_loss= 0.28718 val_loss= 0.98734 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  432.48439145088196\n",
      "edge_vol 9288.0\n",
      "Epoch: 0582 train_loss= 0.28667 val_loss= 0.98709 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  433.30315113067627\n",
      "edge_vol 9288.0\n",
      "Epoch: 0583 train_loss= 0.28644 val_loss= 0.98694 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  433.9414734840393\n",
      "edge_vol 9288.0\n",
      "Epoch: 0584 train_loss= 0.28621 val_loss= 0.98676 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  434.6111915111542\n",
      "edge_vol 9288.0\n",
      "Epoch: 0585 train_loss= 0.28594 val_loss= 0.98651 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  435.21370911598206\n",
      "edge_vol 9288.0\n",
      "Epoch: 0586 train_loss= 0.28578 val_loss= 0.98639 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  436.1408214569092\n",
      "edge_vol 9288.0\n",
      "Epoch: 0587 train_loss= 0.28526 val_loss= 0.98628 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  436.82261848449707\n",
      "edge_vol 9288.0\n",
      "Epoch: 0588 train_loss= 0.28538 val_loss= 0.98630 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  437.474901676178\n",
      "edge_vol 9288.0\n",
      "Epoch: 0589 train_loss= 0.28511 val_loss= 0.98634 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  438.3427224159241\n",
      "edge_vol 9288.0\n",
      "Epoch: 0590 train_loss= 0.28458 val_loss= 0.98633 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "time  439.03997135162354\n",
      "edge_vol 9288.0\n",
      "Epoch: 0591 train_loss= 0.28442 val_loss= 0.98626 train_acc= 0.99167 val_acc= 0.72000 best_val_acc_trail= 0.72400 test_acc= 0.70800\n",
      "Early stopping...\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "from utils import *\n",
    "from models import GCN, PTDNetGCN\n",
    "from metrics import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "# Settings\n",
    "args.dataset=dataset_name\n",
    "\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(args.dataset)\n",
    "adj=modified_adj\n",
    "all_labels = y_train + y_test+y_val\n",
    "single_label = np.argmax(all_labels,axis=-1)\n",
    "\n",
    "nodesize = features.shape[0]\n",
    "\n",
    "# Some preprocessing\n",
    "features = preprocess_features(features)\n",
    "support = preprocess_adj(adj)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "\n",
    "tuple_adj = sparse_to_tuple(adj.tocoo())\n",
    "features_tensor = tf.convert_to_tensor(features,dtype=dtype)\n",
    "adj_tensor = tf.SparseTensor(*tuple_adj)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train,dtype=dtype)\n",
    "train_mask_tensor = tf.convert_to_tensor(train_mask)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test,dtype=dtype)\n",
    "test_mask_tensor = tf.convert_to_tensor(test_mask)\n",
    "y_val_tensor = tf.convert_to_tensor(y_val,dtype=dtype)\n",
    "val_mask_tensor = tf.convert_to_tensor(val_mask)\n",
    "\n",
    "\n",
    "\n",
    "best_test_acc = 0\n",
    "best_val_acc_trail = 0\n",
    "best_val_loss = 10000\n",
    "import time\n",
    "begin = time.time()\n",
    "\n",
    "model = PTDNetGCN(input_dim=features.shape[1], output_dim=y_train.shape[1])\n",
    "model.set_fea_adj(np.array(range(adj.shape[0])), features_tensor, adj_tensor)\n",
    "\n",
    "best_epoch = 0\n",
    "curr_step = 0\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    temperature = max(0.05,args.init_temperature * pow(args.temperature_decay, epoch))\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = []\n",
    "        for l in range(args.outL):\n",
    "            output = model.call(temperature,training=True)\n",
    "            preds.append(tf.expand_dims(output,0))\n",
    "        all_preds = tf.concat(preds,axis=0)\n",
    "        mean_preds = tf.reduce_mean(preds,axis=0)\n",
    "        consistency_loss = tf.nn.l2_loss(mean_preds-all_preds)\n",
    "\n",
    "        cross_loss = masked_softmax_cross_entropy(mean_preds, y_train_tensor,train_mask_tensor)\n",
    "        lossL2 = tf.add_n([tf.nn.l2_loss(v) for v in model.trainable_variables])\n",
    "        lossl0 = model.lossl0(temperature)\n",
    "        nuclear = model.my_nuclear()\n",
    "        #nuclear = model.nuclear()\n",
    "        loss = cross_loss + args.weight_decay*lossL2 + args.lambda1*lossl0 + args.lambda3*nuclear + args.coff_consis*consistency_loss\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    output = model.call(None, training=False)\n",
    "    edges_volumn = tf.reduce_sum(model.maskes[0])\n",
    "    print('edge_vol',edges_volumn.numpy())\n",
    "\n",
    "    train_acc = masked_accuracy(output, y_train_tensor,train_mask_tensor)\n",
    "    val_acc  = masked_accuracy(output, y_val_tensor,val_mask_tensor)\n",
    "    val_loss = masked_softmax_cross_entropy(output, y_val_tensor, val_mask_tensor)\n",
    "    test_acc  = masked_accuracy(output, y_test_tensor,test_mask_tensor)\n",
    "    if val_acc > best_val_acc:\n",
    "        curr_step = 0\n",
    "        best_epoch = epoch\n",
    "        best_val_acc = val_acc\n",
    "        best_val_loss= val_loss\n",
    "        if val_acc>best_val_acc_trail:\n",
    "            best_test_acc = test_acc\n",
    "            best_val_acc_trail = val_acc\n",
    "    else:\n",
    "        curr_step +=1\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cross_loss),\"val_loss=\", \"{:.5f}\".format(val_loss),\n",
    "      \"train_acc=\", \"{:.5f}\".format(train_acc), \"val_acc=\", \"{:.5f}\".format(val_acc),\"best_val_acc_trail=\", \"{:.5f}\".format(best_val_acc_trail),\n",
    "      \"test_acc=\", \"{:.5f}\".format(best_test_acc))\n",
    "\n",
    "    if curr_step > args.early_stop:\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "    end = time.time()\n",
    "    print('time ',(end-begin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.79161 val_loss= 1.79104 train_acc= 0.25800 val_acc= 0.25800 test_acc= 0.26400\n",
      "Epoch: 0002 train_loss= 1.78957 val_loss= 1.79033 train_acc= 0.35600 val_acc= 0.35600 test_acc= 0.37000\n",
      "Epoch: 0003 train_loss= 1.78751 val_loss= 1.78959 train_acc= 0.42600 val_acc= 0.42600 test_acc= 0.45600\n",
      "Epoch: 0004 train_loss= 1.78543 val_loss= 1.78881 train_acc= 0.50200 val_acc= 0.50200 test_acc= 0.53500\n",
      "Epoch: 0005 train_loss= 1.78330 val_loss= 1.78798 train_acc= 0.55600 val_acc= 0.55600 test_acc= 0.57800\n",
      "Epoch: 0006 train_loss= 1.78107 val_loss= 1.78707 train_acc= 0.59600 val_acc= 0.59600 test_acc= 0.61100\n",
      "Epoch: 0007 train_loss= 1.77871 val_loss= 1.78609 train_acc= 0.62800 val_acc= 0.62800 test_acc= 0.63300\n",
      "Epoch: 0008 train_loss= 1.77622 val_loss= 1.78501 train_acc= 0.65200 val_acc= 0.65200 test_acc= 0.65100\n",
      "Epoch: 0009 train_loss= 1.77357 val_loss= 1.78386 train_acc= 0.66600 val_acc= 0.66600 test_acc= 0.65400\n",
      "Epoch: 0010 train_loss= 1.77076 val_loss= 1.78262 train_acc= 0.68200 val_acc= 0.68200 test_acc= 0.65700\n",
      "Epoch: 0011 train_loss= 1.76780 val_loss= 1.78131 train_acc= 0.68800 val_acc= 0.68800 test_acc= 0.65700\n",
      "Epoch: 0012 train_loss= 1.76467 val_loss= 1.77993 train_acc= 0.68800 val_acc= 0.68800 test_acc= 0.65900\n",
      "Epoch: 0013 train_loss= 1.76138 val_loss= 1.77848 train_acc= 0.69000 val_acc= 0.69000 test_acc= 0.66200\n",
      "Epoch: 0014 train_loss= 1.75793 val_loss= 1.77697 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66000\n",
      "Epoch: 0015 train_loss= 1.75432 val_loss= 1.77541 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66000\n",
      "Epoch: 0016 train_loss= 1.75056 val_loss= 1.77380 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66000\n",
      "Epoch: 0017 train_loss= 1.74664 val_loss= 1.77213 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.66000\n",
      "Epoch: 0018 train_loss= 1.74257 val_loss= 1.77041 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.66000\n",
      "Epoch: 0019 train_loss= 1.73835 val_loss= 1.76865 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66000\n",
      "Epoch: 0020 train_loss= 1.73400 val_loss= 1.76684 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.67500\n",
      "Epoch: 0021 train_loss= 1.72952 val_loss= 1.76499 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67500\n",
      "Epoch: 0022 train_loss= 1.72490 val_loss= 1.76310 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.67500\n",
      "Epoch: 0023 train_loss= 1.72016 val_loss= 1.76117 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.67500\n",
      "Epoch: 0024 train_loss= 1.71531 val_loss= 1.75920 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.67500\n",
      "Epoch: 0025 train_loss= 1.71033 val_loss= 1.75720 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.67500\n",
      "Epoch: 0026 train_loss= 1.70525 val_loss= 1.75515 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.67500\n",
      "Epoch: 0027 train_loss= 1.70006 val_loss= 1.75307 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.67500\n",
      "Epoch: 0028 train_loss= 1.69476 val_loss= 1.75095 train_acc= 0.69400 val_acc= 0.69400 test_acc= 0.67500\n",
      "Epoch: 0029 train_loss= 1.68936 val_loss= 1.74879 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67500\n",
      "Epoch: 0030 train_loss= 1.68386 val_loss= 1.74659 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67500\n",
      "Epoch: 0031 train_loss= 1.67826 val_loss= 1.74436 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.67500\n",
      "Epoch: 0032 train_loss= 1.67257 val_loss= 1.74208 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.67500\n",
      "Epoch: 0033 train_loss= 1.66677 val_loss= 1.73977 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.67500\n",
      "Epoch: 0034 train_loss= 1.66089 val_loss= 1.73742 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.67500\n",
      "Epoch: 0035 train_loss= 1.65492 val_loss= 1.73503 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.67500\n",
      "Epoch: 0036 train_loss= 1.64887 val_loss= 1.73261 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.67500\n",
      "Epoch: 0037 train_loss= 1.64273 val_loss= 1.73015 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67500\n",
      "Epoch: 0038 train_loss= 1.63650 val_loss= 1.72764 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67500\n",
      "Epoch: 0039 train_loss= 1.63019 val_loss= 1.72510 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.67500\n",
      "Epoch: 0040 train_loss= 1.62379 val_loss= 1.72252 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.67500\n",
      "Epoch: 0041 train_loss= 1.61732 val_loss= 1.71989 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.67500\n",
      "Epoch: 0042 train_loss= 1.61076 val_loss= 1.71723 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.67500\n",
      "Epoch: 0043 train_loss= 1.60412 val_loss= 1.71453 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.66500\n",
      "Epoch: 0044 train_loss= 1.59741 val_loss= 1.71178 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.66500\n",
      "Epoch: 0045 train_loss= 1.59062 val_loss= 1.70899 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66500\n",
      "Epoch: 0046 train_loss= 1.58376 val_loss= 1.70617 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66500\n",
      "Epoch: 0047 train_loss= 1.57682 val_loss= 1.70330 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66500\n",
      "Epoch: 0048 train_loss= 1.56980 val_loss= 1.70040 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66500\n",
      "Epoch: 0049 train_loss= 1.56271 val_loss= 1.69746 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66500\n",
      "Epoch: 0050 train_loss= 1.55556 val_loss= 1.69449 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66500\n",
      "Epoch: 0051 train_loss= 1.54833 val_loss= 1.69147 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.66500\n",
      "Epoch: 0052 train_loss= 1.54103 val_loss= 1.68842 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.66500\n",
      "Epoch: 0053 train_loss= 1.53366 val_loss= 1.68532 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66500\n",
      "Epoch: 0054 train_loss= 1.52623 val_loss= 1.68218 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66500\n",
      "Epoch: 0055 train_loss= 1.51873 val_loss= 1.67900 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66500\n",
      "Epoch: 0056 train_loss= 1.51117 val_loss= 1.67581 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66500\n",
      "Epoch: 0057 train_loss= 1.50356 val_loss= 1.67257 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66500\n",
      "Epoch: 0058 train_loss= 1.49587 val_loss= 1.66930 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66500\n",
      "Epoch: 0059 train_loss= 1.48814 val_loss= 1.66599 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66500\n",
      "Epoch: 0060 train_loss= 1.48035 val_loss= 1.66264 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66500\n",
      "Epoch: 0061 train_loss= 1.47250 val_loss= 1.65926 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66500\n",
      "Epoch: 0062 train_loss= 1.46461 val_loss= 1.65584 train_acc= 0.69600 val_acc= 0.69600 test_acc= 0.66500\n",
      "Epoch: 0063 train_loss= 1.45666 val_loss= 1.65240 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66500\n",
      "Epoch: 0064 train_loss= 1.44867 val_loss= 1.64893 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66500\n",
      "Epoch: 0065 train_loss= 1.44064 val_loss= 1.64542 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66500\n",
      "Epoch: 0066 train_loss= 1.43256 val_loss= 1.64188 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66500\n",
      "Epoch: 0067 train_loss= 1.42444 val_loss= 1.63832 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66500\n",
      "Epoch: 0068 train_loss= 1.41629 val_loss= 1.63471 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66500\n",
      "Epoch: 0069 train_loss= 1.40810 val_loss= 1.63110 train_acc= 0.69800 val_acc= 0.69800 test_acc= 0.66500\n",
      "Epoch: 0070 train_loss= 1.39989 val_loss= 1.62746 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.66500\n",
      "Epoch: 0071 train_loss= 1.39165 val_loss= 1.62379 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67200\n",
      "Epoch: 0072 train_loss= 1.38338 val_loss= 1.62008 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67200\n",
      "Epoch: 0073 train_loss= 1.37509 val_loss= 1.61636 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.67100\n",
      "Epoch: 0074 train_loss= 1.36677 val_loss= 1.61262 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67100\n",
      "Epoch: 0075 train_loss= 1.35844 val_loss= 1.60886 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.67100\n",
      "Epoch: 0076 train_loss= 1.35010 val_loss= 1.60508 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.67100\n",
      "Epoch: 0077 train_loss= 1.34175 val_loss= 1.60128 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.67100\n",
      "Epoch: 0078 train_loss= 1.33338 val_loss= 1.59746 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.67100\n",
      "Epoch: 0079 train_loss= 1.32501 val_loss= 1.59363 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.67100\n",
      "Epoch: 0080 train_loss= 1.31665 val_loss= 1.58977 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.67100\n",
      "Epoch: 0081 train_loss= 1.30828 val_loss= 1.58591 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67100\n",
      "Epoch: 0082 train_loss= 1.29991 val_loss= 1.58203 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.67100\n",
      "Epoch: 0083 train_loss= 1.29154 val_loss= 1.57814 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.67100\n",
      "Epoch: 0084 train_loss= 1.28320 val_loss= 1.57425 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67100\n",
      "Epoch: 0085 train_loss= 1.27486 val_loss= 1.57034 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67100\n",
      "Epoch: 0086 train_loss= 1.26653 val_loss= 1.56642 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67100\n",
      "Epoch: 0087 train_loss= 1.25823 val_loss= 1.56248 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67100\n",
      "Epoch: 0088 train_loss= 1.24994 val_loss= 1.55854 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.67100\n",
      "Epoch: 0089 train_loss= 1.24167 val_loss= 1.55461 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.67100\n",
      "Epoch: 0090 train_loss= 1.23344 val_loss= 1.55067 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.67100\n",
      "Epoch: 0091 train_loss= 1.22523 val_loss= 1.54672 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67100\n",
      "Epoch: 0092 train_loss= 1.21705 val_loss= 1.54278 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67100\n",
      "Epoch: 0093 train_loss= 1.20890 val_loss= 1.53884 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67100\n",
      "Epoch: 0094 train_loss= 1.20079 val_loss= 1.53489 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.67200\n",
      "Epoch: 0095 train_loss= 1.19271 val_loss= 1.53094 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.67200\n",
      "Epoch: 0096 train_loss= 1.18467 val_loss= 1.52701 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.67200\n",
      "Epoch: 0097 train_loss= 1.17668 val_loss= 1.52308 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67200\n",
      "Epoch: 0098 train_loss= 1.16872 val_loss= 1.51915 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67200\n",
      "Epoch: 0099 train_loss= 1.16082 val_loss= 1.51523 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67200\n",
      "Epoch: 0100 train_loss= 1.15297 val_loss= 1.51131 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67200\n",
      "Epoch: 0101 train_loss= 1.14516 val_loss= 1.50741 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67200\n",
      "Epoch: 0102 train_loss= 1.13739 val_loss= 1.50350 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67200\n",
      "Epoch: 0103 train_loss= 1.12968 val_loss= 1.49961 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.67500\n",
      "Epoch: 0104 train_loss= 1.12204 val_loss= 1.49573 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.67500\n",
      "Epoch: 0105 train_loss= 1.11443 val_loss= 1.49187 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.67500\n",
      "Epoch: 0106 train_loss= 1.10690 val_loss= 1.48802 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.67500\n",
      "Epoch: 0107 train_loss= 1.09941 val_loss= 1.48419 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.67500\n",
      "Epoch: 0108 train_loss= 1.09199 val_loss= 1.48037 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.67500\n",
      "Epoch: 0109 train_loss= 1.08463 val_loss= 1.47656 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.67500\n",
      "Epoch: 0110 train_loss= 1.07732 val_loss= 1.47277 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67500\n",
      "Epoch: 0111 train_loss= 1.07008 val_loss= 1.46901 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67500\n",
      "Epoch: 0112 train_loss= 1.06289 val_loss= 1.46526 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67500\n",
      "Epoch: 0113 train_loss= 1.05579 val_loss= 1.46152 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.67500\n",
      "Epoch: 0114 train_loss= 1.04873 val_loss= 1.45780 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.67500\n",
      "Epoch: 0115 train_loss= 1.04175 val_loss= 1.45409 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.67500\n",
      "Epoch: 0116 train_loss= 1.03481 val_loss= 1.45042 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.67500\n",
      "Epoch: 0117 train_loss= 1.02796 val_loss= 1.44678 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.67500\n",
      "Epoch: 0118 train_loss= 1.02116 val_loss= 1.44315 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67500\n",
      "Epoch: 0119 train_loss= 1.01444 val_loss= 1.43955 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67500\n",
      "Epoch: 0120 train_loss= 1.00778 val_loss= 1.43599 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67500\n",
      "Epoch: 0121 train_loss= 1.00119 val_loss= 1.43243 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67500\n",
      "Epoch: 0122 train_loss= 0.99467 val_loss= 1.42889 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67500\n",
      "Epoch: 0123 train_loss= 0.98820 val_loss= 1.42538 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.67500\n",
      "Epoch: 0124 train_loss= 0.98182 val_loss= 1.42189 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.67500\n",
      "Epoch: 0125 train_loss= 0.97549 val_loss= 1.41843 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.67500\n",
      "Epoch: 0126 train_loss= 0.96923 val_loss= 1.41500 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.67500\n",
      "Epoch: 0127 train_loss= 0.96305 val_loss= 1.41159 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67500\n",
      "Epoch: 0128 train_loss= 0.95692 val_loss= 1.40820 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67500\n",
      "Epoch: 0129 train_loss= 0.95086 val_loss= 1.40485 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.67500\n",
      "Epoch: 0130 train_loss= 0.94488 val_loss= 1.40151 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.67500\n",
      "Epoch: 0131 train_loss= 0.93894 val_loss= 1.39822 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.67500\n",
      "Epoch: 0132 train_loss= 0.93308 val_loss= 1.39494 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.67500\n",
      "Epoch: 0133 train_loss= 0.92730 val_loss= 1.39167 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.67500\n",
      "Epoch: 0134 train_loss= 0.92156 val_loss= 1.38845 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.67500\n",
      "Epoch: 0135 train_loss= 0.91590 val_loss= 1.38525 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.67500\n",
      "Epoch: 0136 train_loss= 0.91028 val_loss= 1.38209 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.67500\n",
      "Epoch: 0137 train_loss= 0.90475 val_loss= 1.37894 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.67500\n",
      "Epoch: 0138 train_loss= 0.89927 val_loss= 1.37582 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.67500\n",
      "Epoch: 0139 train_loss= 0.89386 val_loss= 1.37273 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.67500\n",
      "Epoch: 0140 train_loss= 0.88852 val_loss= 1.36967 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.67500\n",
      "Epoch: 0141 train_loss= 0.88322 val_loss= 1.36664 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.67500\n",
      "Epoch: 0142 train_loss= 0.87800 val_loss= 1.36364 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.67500\n",
      "Epoch: 0143 train_loss= 0.87283 val_loss= 1.36067 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.67500\n",
      "Epoch: 0144 train_loss= 0.86772 val_loss= 1.35770 train_acc= 0.71400 val_acc= 0.71400 test_acc= 0.67700\n",
      "Epoch: 0145 train_loss= 0.86266 val_loss= 1.35478 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.67700\n",
      "Epoch: 0146 train_loss= 0.85768 val_loss= 1.35187 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.67700\n",
      "Epoch: 0147 train_loss= 0.85275 val_loss= 1.34899 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.67700\n",
      "Epoch: 0148 train_loss= 0.84787 val_loss= 1.34616 train_acc= 0.71400 val_acc= 0.71400 test_acc= 0.67700\n",
      "Epoch: 0149 train_loss= 0.84305 val_loss= 1.34335 train_acc= 0.71400 val_acc= 0.71400 test_acc= 0.67700\n",
      "Epoch: 0150 train_loss= 0.83829 val_loss= 1.34055 train_acc= 0.71400 val_acc= 0.71400 test_acc= 0.67700\n",
      "Epoch: 0151 train_loss= 0.83359 val_loss= 1.33778 train_acc= 0.71400 val_acc= 0.71400 test_acc= 0.67700\n",
      "Epoch: 0152 train_loss= 0.82895 val_loss= 1.33503 train_acc= 0.71400 val_acc= 0.71400 test_acc= 0.67700\n",
      "Epoch: 0153 train_loss= 0.82435 val_loss= 1.33232 train_acc= 0.71400 val_acc= 0.71400 test_acc= 0.67700\n",
      "Epoch: 0154 train_loss= 0.81980 val_loss= 1.32964 train_acc= 0.71400 val_acc= 0.71400 test_acc= 0.67700\n",
      "Epoch: 0155 train_loss= 0.81531 val_loss= 1.32696 train_acc= 0.71400 val_acc= 0.71400 test_acc= 0.67700\n",
      "Epoch: 0156 train_loss= 0.81087 val_loss= 1.32434 train_acc= 0.71400 val_acc= 0.71400 test_acc= 0.67700\n",
      "Epoch: 0157 train_loss= 0.80650 val_loss= 1.32172 train_acc= 0.71600 val_acc= 0.71600 test_acc= 0.68100\n",
      "Epoch: 0158 train_loss= 0.80216 val_loss= 1.31914 train_acc= 0.71600 val_acc= 0.71600 test_acc= 0.68100\n",
      "Epoch: 0159 train_loss= 0.79788 val_loss= 1.31659 train_acc= 0.71600 val_acc= 0.71600 test_acc= 0.68100\n",
      "Epoch: 0160 train_loss= 0.79364 val_loss= 1.31405 train_acc= 0.71400 val_acc= 0.71400 test_acc= 0.68100\n",
      "Epoch: 0161 train_loss= 0.78946 val_loss= 1.31153 train_acc= 0.71400 val_acc= 0.71400 test_acc= 0.68100\n",
      "Epoch: 0162 train_loss= 0.78532 val_loss= 1.30904 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.68100\n",
      "Epoch: 0163 train_loss= 0.78123 val_loss= 1.30656 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.68100\n",
      "Epoch: 0164 train_loss= 0.77719 val_loss= 1.30412 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.68100\n",
      "Epoch: 0165 train_loss= 0.77320 val_loss= 1.30170 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.68100\n",
      "Epoch: 0166 train_loss= 0.76924 val_loss= 1.29932 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.68100\n",
      "Epoch: 0167 train_loss= 0.76534 val_loss= 1.29696 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.68100\n",
      "Epoch: 0168 train_loss= 0.76148 val_loss= 1.29461 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.68100\n",
      "Epoch: 0169 train_loss= 0.75767 val_loss= 1.29228 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.68100\n",
      "Epoch: 0170 train_loss= 0.75388 val_loss= 1.28999 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.68100\n",
      "Epoch: 0171 train_loss= 0.75016 val_loss= 1.28770 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.68100\n",
      "Epoch: 0172 train_loss= 0.74647 val_loss= 1.28544 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.68100\n",
      "Epoch: 0173 train_loss= 0.74282 val_loss= 1.28321 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0174 train_loss= 0.73921 val_loss= 1.28100 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0175 train_loss= 0.73565 val_loss= 1.27880 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0176 train_loss= 0.73212 val_loss= 1.27663 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0177 train_loss= 0.72864 val_loss= 1.27448 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0178 train_loss= 0.72519 val_loss= 1.27235 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0179 train_loss= 0.72177 val_loss= 1.27025 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0180 train_loss= 0.71840 val_loss= 1.26816 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0181 train_loss= 0.71506 val_loss= 1.26609 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0182 train_loss= 0.71175 val_loss= 1.26404 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.68100\n",
      "Epoch: 0183 train_loss= 0.70849 val_loss= 1.26202 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.68100\n",
      "Epoch: 0184 train_loss= 0.70526 val_loss= 1.26001 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.68100\n",
      "Epoch: 0185 train_loss= 0.70207 val_loss= 1.25803 train_acc= 0.70000 val_acc= 0.70000 test_acc= 0.68100\n",
      "Epoch: 0186 train_loss= 0.69890 val_loss= 1.25606 train_acc= 0.70200 val_acc= 0.70200 test_acc= 0.68100\n",
      "Epoch: 0187 train_loss= 0.69578 val_loss= 1.25410 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68100\n",
      "Epoch: 0188 train_loss= 0.69269 val_loss= 1.25218 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68100\n",
      "Epoch: 0189 train_loss= 0.68963 val_loss= 1.25026 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68100\n",
      "Epoch: 0190 train_loss= 0.68661 val_loss= 1.24837 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68100\n",
      "Epoch: 0191 train_loss= 0.68361 val_loss= 1.24649 train_acc= 0.70400 val_acc= 0.70400 test_acc= 0.68100\n",
      "Epoch: 0192 train_loss= 0.68064 val_loss= 1.24463 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0193 train_loss= 0.67771 val_loss= 1.24278 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0194 train_loss= 0.67480 val_loss= 1.24095 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0195 train_loss= 0.67193 val_loss= 1.23915 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0196 train_loss= 0.66908 val_loss= 1.23735 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0197 train_loss= 0.66627 val_loss= 1.23558 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0198 train_loss= 0.66350 val_loss= 1.23382 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0199 train_loss= 0.66074 val_loss= 1.23209 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0200 train_loss= 0.65800 val_loss= 1.23036 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0201 train_loss= 0.65530 val_loss= 1.22866 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0202 train_loss= 0.65263 val_loss= 1.22697 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0203 train_loss= 0.64998 val_loss= 1.22528 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0204 train_loss= 0.64735 val_loss= 1.22362 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0205 train_loss= 0.64477 val_loss= 1.22197 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0206 train_loss= 0.64221 val_loss= 1.22033 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0207 train_loss= 0.63965 val_loss= 1.21871 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0208 train_loss= 0.63713 val_loss= 1.21711 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0209 train_loss= 0.63464 val_loss= 1.21551 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0210 train_loss= 0.63216 val_loss= 1.21396 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0211 train_loss= 0.62972 val_loss= 1.21241 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0212 train_loss= 0.62729 val_loss= 1.21086 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0213 train_loss= 0.62490 val_loss= 1.20932 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0214 train_loss= 0.62253 val_loss= 1.20779 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.68100\n",
      "Epoch: 0215 train_loss= 0.62017 val_loss= 1.20628 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.68100\n",
      "Epoch: 0216 train_loss= 0.61785 val_loss= 1.20479 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.68100\n",
      "Epoch: 0217 train_loss= 0.61552 val_loss= 1.20332 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0218 train_loss= 0.61324 val_loss= 1.20186 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0219 train_loss= 0.61098 val_loss= 1.20043 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0220 train_loss= 0.60874 val_loss= 1.19900 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0221 train_loss= 0.60652 val_loss= 1.19755 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0222 train_loss= 0.60431 val_loss= 1.19613 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0223 train_loss= 0.60212 val_loss= 1.19476 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0224 train_loss= 0.59997 val_loss= 1.19338 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0225 train_loss= 0.59782 val_loss= 1.19201 train_acc= 0.71000 val_acc= 0.71000 test_acc= 0.68100\n",
      "Epoch: 0226 train_loss= 0.59571 val_loss= 1.19062 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.68100\n",
      "Epoch: 0227 train_loss= 0.59360 val_loss= 1.18926 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.68100\n",
      "Epoch: 0228 train_loss= 0.59151 val_loss= 1.18792 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.68100\n",
      "Epoch: 0229 train_loss= 0.58944 val_loss= 1.18659 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.68100\n",
      "Epoch: 0230 train_loss= 0.58739 val_loss= 1.18527 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.68100\n",
      "Epoch: 0231 train_loss= 0.58536 val_loss= 1.18398 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.68100\n",
      "Epoch: 0232 train_loss= 0.58335 val_loss= 1.18269 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.68100\n",
      "Epoch: 0233 train_loss= 0.58136 val_loss= 1.18140 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.68100\n",
      "Epoch: 0234 train_loss= 0.57938 val_loss= 1.18012 train_acc= 0.71200 val_acc= 0.71200 test_acc= 0.68100\n",
      "Epoch: 0235 train_loss= 0.57743 val_loss= 1.17884 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0236 train_loss= 0.57548 val_loss= 1.17761 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0237 train_loss= 0.57355 val_loss= 1.17637 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0238 train_loss= 0.57165 val_loss= 1.17514 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0239 train_loss= 0.56975 val_loss= 1.17393 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0240 train_loss= 0.56788 val_loss= 1.17272 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0241 train_loss= 0.56602 val_loss= 1.17153 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0242 train_loss= 0.56418 val_loss= 1.17032 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0243 train_loss= 0.56234 val_loss= 1.16914 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0244 train_loss= 0.56053 val_loss= 1.16796 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0245 train_loss= 0.55872 val_loss= 1.16679 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0246 train_loss= 0.55694 val_loss= 1.16565 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0247 train_loss= 0.55518 val_loss= 1.16451 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0248 train_loss= 0.55342 val_loss= 1.16338 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0249 train_loss= 0.55167 val_loss= 1.16224 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0250 train_loss= 0.54995 val_loss= 1.16112 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0251 train_loss= 0.54823 val_loss= 1.16003 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0252 train_loss= 0.54654 val_loss= 1.15895 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0253 train_loss= 0.54486 val_loss= 1.15786 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0254 train_loss= 0.54318 val_loss= 1.15677 train_acc= 0.70800 val_acc= 0.70800 test_acc= 0.68100\n",
      "Epoch: 0255 train_loss= 0.54153 val_loss= 1.15571 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0256 train_loss= 0.53988 val_loss= 1.15466 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Epoch: 0257 train_loss= 0.53825 val_loss= 1.15361 train_acc= 0.70600 val_acc= 0.70600 test_acc= 0.68100\n",
      "Early stopping...\n"
     ]
    }
   ],
   "source": [
    "from config import args\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from utils import *\n",
    "from models import GCN_dropedge\n",
    "from metrics import *\n",
    "\n",
    "# Settings\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "args.dataset=dataset_name\n",
    "\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(args.dataset)\n",
    "adj=modified_adj\n",
    "\n",
    "tuple_adj = sparse_to_tuple(adj.tocoo())\n",
    "adj_tensor = tf.SparseTensor(*tuple_adj)\n",
    "\n",
    "features = preprocess_features(features)\n",
    "\n",
    "model = GCN_dropedge(input_dim=features.shape[1], output_dim=y_train.shape[1], adj=adj_tensor)\n",
    "\n",
    "\n",
    "features_tensor = tf.convert_to_tensor(features,dtype=tf.float32)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train,dtype=tf.float32)\n",
    "train_mask_tensor = tf.convert_to_tensor(train_mask)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test,dtype=tf.float32)\n",
    "test_mask_tensor = tf.convert_to_tensor(test_mask)\n",
    "y_val_tensor = tf.convert_to_tensor(y_val,dtype=tf.float32)\n",
    "val_mask_tensor = tf.convert_to_tensor(val_mask)\n",
    "\n",
    "best_test_acc = 0\n",
    "best_val_acc = 0\n",
    "best_val_loss = 10000\n",
    "\n",
    "\n",
    "curr_step = 0\n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        output = model.call((features_tensor),training=True)\n",
    "        cross_loss = masked_softmax_cross_entropy(output, y_train_tensor,train_mask_tensor)\n",
    "        lossL2 = tf.add_n([tf.nn.l2_loss(v) for v in model.trainable_variables])\n",
    "        loss = cross_loss + args.weight_decay*lossL2\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    output = model.call((features_tensor), training=False)\n",
    "    train_acc = masked_accuracy(output, y_train_tensor,train_mask_tensor)\n",
    "    val_acc  = masked_accuracy(output, y_val_tensor,val_mask_tensor)\n",
    "    val_loss = masked_softmax_cross_entropy(output, y_val_tensor, val_mask_tensor)\n",
    "    test_acc  = masked_accuracy(output, y_test_tensor,test_mask_tensor)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        curr_step = 0\n",
    "        best_test_acc = test_acc\n",
    "        best_val_acc = val_acc\n",
    "        best_val_loss= val_loss\n",
    "        # Print results\n",
    "\n",
    "    else:\n",
    "        curr_step +=1\n",
    "    if curr_step > args.early_stop:\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cross_loss),\"val_loss=\", \"{:.5f}\".format(val_loss),\n",
    "      \"train_acc=\", \"{:.5f}\".format(val_acc), \"val_acc=\", \"{:.5f}\".format(val_acc),\n",
    "      \"test_acc=\", \"{:.5f}\".format(best_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
